<?xml version="1.0" ?>

<!DOCTYPE article SYSTEM "/usr/share/sgml/docbook/dtd/xml/4.5/docbookx.dtd">


<article status="draft" class="specification"> <title>Enhanced Discrete Events System framework (multiagents based). Design.</title>

    <articleinfo>
	<author><personname><firstname>Yuri</firstname><surname>Borisov</surname></personname>
	    <email>yuri.borisov.v@gmail.com</email></author> 

	<releaseinfo>Ver.0.11 at 08-Mar-2015</releaseinfo>

	<abstract>
	    <simpara>This document collects use-cases and software desing for Discrete Events System framework ver 2.</simpara>
	</abstract>

	<revhistory>
	    <revision> <revnumber>0.01</revnumber> <date>03-Mar-2013</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Initial version</revremark> </revision>
	    <revision> <revnumber>0.02</revnumber> <date>21-Mar-2013</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_conn_01"/></revremark> </revision>
	    <revision> <revnumber>0.03</revnumber> <date>06-Jul-2013</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_ifcache"/></revremark> </revision>
	    <revision> <revnumber>0.04</revnumber> <date>14-Jul-2013</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_base_02"/>. Updated <xref linkend="ds_ifcache_01"/></revremark> </revision>
	    <revision> <revnumber>0.05</revnumber> <date>18-Jan-2014</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_base_03"/></revremark> </revision>
	    <revision> <revnumber>0.06</revnumber> <date>10-Feb-2014</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_mut"/></revremark> </revision>
	    <revision> <revnumber>0.07</revnumber> <date>08-Aug-2014</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_nat_agent_hier"/></revremark> </revision>
	    <revision> <revnumber>0.08</revnumber> <date>09-Sep-2014</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_mut_dis_pheno"/>, <xref linkend="ds_mut_pheno"/></revremark> </revision>
	    <revision> <revnumber>0.09</revnumber> <date>29-Sep-2014</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_transp"/></revremark> </revision>
	    <revision> <revnumber>0.10</revnumber> <date>26-Oct-2014</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_agt_data"/></revremark> </revision>
	    <revision> <revnumber>0.11</revnumber> <date>08-Mar-2015</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_ifnegot"/></revremark> </revision>
	    <revision> <revnumber>0.12</revnumber> <date>14-Apr-2015</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_mod"/></revremark> </revision>
	    <revision> <revnumber>0.13</revnumber> <date>07-May-2016</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_cplx_cont_strc"/></revremark> </revision>
	    <revision> <revnumber>0.14</revnumber> <date>07-Jun-2016</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_daa_ttm"/>, updated <xref linkend="ds_cplx_cont_strc"/></revremark> </revision>
	    <revision> <revnumber>0.14</revnumber> <date>07-Jun-2016</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_cplx_cont_cdac"/>, updated <xref linkend="ds_cplx_cont_strcimpr"/></revremark> </revision>
	    <revision> <revnumber>0.15</revnumber> <date>06-Dec-2016</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_mmc_br"/>, <xref linkend="ds_mmc_ipcm"/></revremark> </revision>
	    <revision> <revnumber>0.16</revnumber> <date>04-Mar-2017</date> <authorinitials>Yuri Borisov</authorinitials>
		<revremark>Added <xref linkend="ds_mv_local_nm"/>, <xref linkend="ds_mv_local_wkc"/></revremark> </revision>
	</revhistory>

    </articleinfo>

    <bibliolist>
	<title>References</title>

	<biblioentry id="ref_incr_mut"> <abbrev>INCR_MUT</abbrev>
	    <productname><ulink url="../../../fap-doc/doc_incr_syst_creation/index.html "/></productname>
	    <title>Y.Borisov. Using incremental mutation process for systems modeling</title> </biblioentry>

	<biblioentry id="ref_rfc_3986"> <abbrev>RFC_3986_URI</abbrev>
	    <productname><ulink url="httpss://www.ietf.org/rfc/rfc3986.txt"/></productname>
	    <title>RFC 3986: Uniform Resource Identifier (URI): Generic Syntax</title> </biblioentry>
    </bibliolist>

    <glossary> <title>Glossary</title> 
	<glossentry id="gls_cp"><glossterm>CP</glossterm> <acronym>CP</acronym>
	    <glossdef> <para>Connection Point</para> <para>
		    Element that is used as endpoint of connections between systems.  
	</para></glossdef> </glossentry>
	<glossentry id="gls_daa"><glossterm>DAA</glossterm> <acronym>DAA</acronym>
	    <glossdef> <para>Distributed Agents Approach</para> <para>
		    Approach of multi-agent system that assumes that the modes is distributed among several environments that 
		    can be running on undependent executable enviromnents.
		    Ref <xref linkend="ds_daa"/> </para></glossdef> </glossentry>
	<glossentry id="gls_dhc"><glossterm>DHC</glossterm> <acronym>DHC</acronym>
	    <glossdef> <para>Direct Hierarchical Chromosome</para> <para>
		    Approach of multi-agent system definition that describes the model's structure directly. 
		    Ref <xref linkend="ds_smc"/> </para></glossdef> </glossentry>
	<glossentry id="gls_cpa"><glossterm>CPA</glossterm> <acronym>CPA</acronym>
	    <glossdef> <para>Connecting Proxy Agent.
		    The approach of agents design where dedicated embedded agents play the role of 
		    connection points of agent, i.e. doing all connecting relative work instead of agent.
		    In contrast of <xref linkend="gls_pia"/> connecting proxy agent provides interface
		    resolution mechanism for the client, so the mechanism is distributed between multiple
		    connecting agents in the model.
	</para></glossdef> </glossentry>
	<glossentry id="gls_osm"><glossterm>OSM</glossterm> <acronym>OSM</acronym>
	    <glossdef> <para>Original Sequence of Mutations - 
		    The approach of models creation where the same mutation order is
		    used for model creation as on construction phase, ref
		    <xref linkend="ds_mut_osm"/>
	</para></glossdef> </glossentry>
	<glossentry id="gls_mae"><glossterm>MAE</glossterm>
	    <glossdef> <para>Using monodilic agent instead of embedded.
		    Optimization approach, where monolitic native agents instead of constructed agents.
		    <xref linkend="ds_mae"/>
	</para></glossdef> </glossentry>
	<glossentry id="gls_pia"><glossterm>PIA</glossterm> <acronym>PIA</acronym>
	    <glossdef> <para>Properties Instead of embedded auxiliary Agents
		    The approach of agents design where properties are using instead of auxiliary agents
		    in order to minimize the agents number, ref
		    <xref linkend="ds_pia"/>. Ref <xref linkend="gls_cpa"/> for another connecting solution.
	</para></glossdef> </glossentry>
	<glossentry id="gls_scc"><glossterm>SCC</glossterm> <acronym>SCC</acronym>
	    <glossdef> <para>State with Combined Chains. DES state design where data and observing chains are same.
		    <xref linkend="ds_mae_scc"/>. Ref <xref linkend="gls_ssc"/> for another design solution.
	</para></glossdef> </glossentry>
	<glossentry id="gls_ssc"><glossterm>SSC</glossterm> <acronym>SSC</acronym>
	    <glossdef> <para>State with Separate Chains. DES state design where data and observing chains are separated.
		    <xref linkend="ds_mae_scc"/>. Ref <xref linkend="gls_scc"/> for another design solution.
	</para></glossdef> </glossentry>
	<glossentry id="gls_uac"><glossterm>UAC</glossterm> <acronym>UAC</acronym>
	    <glossdef> <para>Units for Auxiliary Components
		    The approach of agents design where "passive" units are used instead of agnents as
		    auxiliary components, ref
		    <xref linkend="ds_uac"/>. Ref <xref linkend="gls_cpa"/>, <xref linkend="gls_pia"/> for other connecting solutions.
	</para></glossdef> </glossentry>

    </glossary>

    <sect1><title>Intro</title>
	<sect2><title>Desing items status</title>
	    <simpara>Desing items status is designated by specific tags in square brackets. The tag prefix is DS_. The status values are:</simpara>
	    <itemizedlist>
		<listitem>DS_P - proposal, the item that needs to be considered</listitem>
		<listitem>DS_I - implemented</listitem>
	    </itemizedlist>
	</sect2>
    </sect1>

    <sect1 id="ds_base"> <title>Base</title>
	<sect2 id="ds_base_01"><title>DS_BASE_01 Getting iface</title>
	    <sect3><title>Description</title>
		<simpara>
		    In DES iface can be considered as atomic behavior. Getting iface is contained in base CPP APIs - GetObj. 
		    Many of components customize  that APIs. For instance the connection point is customizing the APIs to redirect
		    the request to real provider of the iface, for connpoint is a proxy only.
		</simpara>
		<simpara>Thus the redirection chain can be complex, so getting iface APIs should avoid looping. There could be several 
		    design approach:</simpara>
		<itemizedlist>
		    <listitem>Using agents extention mechanism. Redirect request to higher level of native hierarchy if the current level
			cannot handle the request.	
		    </listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_base_02"><title>DS_BASE_02 Native behaviour. Agents.</title>
	    <sect3><title>Description</title>
		<simpara>The current implementation of elements extention for adding native bahavior is not consistent.</simpara>
	    </sect3>
	    <sect3><title>Discussion</title>
		<sect4><title>What are agents: component or internals of element.</title>
		    <simpara>Currently agents are implemented as components of element. Making them specific is done via collecting them in one
			specific part of element - "Agents" container. This solution foolows general approach of "cooperation" when the required complexity
			of system is secured via cooperation between elements. So extending of native behavior of element is done via cooperation of base
			element to embedded agents. But consequences of that is that agents are "regular" elements.</simpara>
		</sect4>
	    </sect3>
	</sect2>
	<sect2 id="ds_base_03"><title>DS_BASE_03 URI</title>
	    <sect3><title>Intro</title>
		<simpara>URI is a node or node primary interface identification via its path in the models native hierarchy.</simpara>
	    </sect3>
	    <sect3><title>Syntax</title>
		<simpara>The node unified URI can be considered as path to node from the given node in hierarchy. The path is the sequence of nodes, where
		    node is specified relatively to the previous node in the path. Uri is conformed with <xref linkend="ref_rfc_3986"/>
		    The general form is as:</simpara>
		<programlisting>
		    uri = scheme ":" hier_part [ "?" query ] [ "#" fragment ]
		    hier_part   = "//" authority path-abempty | path-absolute | path-rootless | path-empty
		    fragment = node_uri | iface_uri
		    iface_uri = node_uri,iface
		    iface = implementation_relation,iface_name
		    implementation_relation = "%"
		    iface_name = name
		    node_uri = {node}
		    node = [relation_to_predecessor]["(",extra_relation,")"],node_name
		    node_name = name | current_node | upper_level
		    current_node = "."
		    upper_level = ".."
		    parent
		    relation_to_predecessor = owning_relation | inheritance_relation
		    owning_relation = "/"
		    inheritance_relation = ":"
		    extra_relation = 
		</programlisting>
		<simpara>Notes:</simpara>
		<itemizedlist>
		    <listitem>hier_part specifies DES server</listitem>
		    <listitem>If relation_to_predecessor is missing it means that the node is native one.
		    </listitem>
		</itemizedlist>
		<simpara>Examples:</simpara>
		<itemizedlist>
		    <listitem>Models root
			<programlisting> /root </programlisting>
		    </listitem>
		    <listitem>Native node
			<programlisting>Prop</programlisting>
		    </listitem>
		    <listitem>Simple owning path
			<programlisting> /Root/Node_1/Node_1_1 </programlisting>
		    </listitem>
		    <listitem>Nodes iface
			<programlisting> /Root/Node_1/Node_1_1%MElem </programlisting>
		    </listitem>
		    <listitem>Root on local host port 235 server Env_1
			<programlisting>socks://localhost:234/Env_1#/root</programlisting>
		    </listitem>

		</itemizedlist>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_conn"><title>Connections</title>
	<sect2 id="ds_conn_01"><title>DS_CONN_01 Connection points</title>
	    <sect3><title>Description</title>
		<simpara>
		    Connection points (CP) are endpoints of connections. System contains CPs and exhibits system's interfaces via CPs.
		</simpara>
		<itemizedlist>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_conn_03"><title>DS_CONN_03 CP interface</title>
	    <sect3><title>Description</title>
		<simpara>It is required for CPs to provide specific iface. One of the case where it can be used is
		    finding out "pair" of connection especially if sockets with deep hier are connected (also via extenders).
		    The problem when complex sockets is that some component within this hier is "virtually" connected
		    to some pair, but there is no simple mechanism to find the "pair".</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_conn_02"><title>DS_CONN_02 Sockets</title>
	    <sect3><title>Description</title>
		<simpara>
		    Socket is the complex CP - element that collects some CPs, EPs, and sockets. 
		    Like simple CP Socket is located in system or capsula of Incaps.
		    When connecting two sockets the observed hier element, normally Incapsulated system (Incaps)
		</simpara>
		<itemizedlist>
		</itemizedlist>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_ifcache"><title>Interfaces provider. Interfaces cache</title>
	<sect2 id="ds_ifcache_01"><title>DS_IFCACHE_01 Key scheme for cache</title>
	    <sect3><title>Description</title>
		<simpara>Current solution [6d15a3f2] uses key [Name, Requestor, Provider] where Requestor and Provider are pointers. This makes some limitation in
		    requests to cache. For instance the cases cannot be distinquished when agent is requested for iface from one and another conn points, 
		    because for agents cache the direct Requestor is agents host but not conn points. Refer to unit test ut_func_seq4.xml, agent of "Conv"
		    needs to distinquish requests from CP "Out" and CP "Out_WFarg" but it's not possible. Is is the indication of the current mechanism not
		    consistent? Do we need improvement of cache mechanism?</simpara>
	    </sect3>
	    <sect3 id="ds_ifcache_01_disc"><title>Discussion</title>
		<itemizedlist>
		    <listitem>A: No it is not. We simply need to adjust Conv to the scheme. The current implementation of Conv is not correct. </listitem>
		    <listitem>14Jul2013 Yes, the scheme is incorrect. It doesn't provide correct iface instance in case of request thru socket pin, 
			especially if pins are for the same iface, ref Ut_conn::test_Sock():58 [7618b16c5199]. The first step ut requested iface 
			MDIntGet from Cp1, socket "Out" updates cache with MDIntGet iface from Cp1. The second step ut requests iface
			from Cp2, but Out returns the previously cached iface because it cannot distinquish requestor.</listitem>
		</itemizedlist>
	    </sect3>
	    <sect3><title>Solution: refuse ifaces caching approach at all, but use pseudo connections for all connpoints.</title>
		<simpara>Do we need caching really? Architecturally, caching is just establishing direct pseudo connections, that simplify an access
		    to iface instances. It is not confirmed that the overhead will be resonable for the case when we have the pseudo connections for 
		    totally all elements of system. Isn't better to use some intermediate scheme, where only some elements have it, for instance
		    only connpoints as they conduct most of communications.</simpara>
		<simpara>To implement this some specific iface for CP needs to be introduced: to get cp pair, to get iface from this pair host,
		    probably something else.</simpara>
		<simpara>Pros of this solution is that it is a bit simpler for understanding. Cons for the solution is that two steps needs for 
		    getting iface: step_1 is to get cp pair, step_2 is to get iface from this pair host.</simpara>
	    </sect3>
	    <sect3><title>Solution: extending of scheme by using full path from requestor.</title>
		<simpara></simpara> 
	    </sect3>
	    <sect3><title>Solution: to avoid having cache in agent (doesn't solve the problem actually)</title>
		<simpara>Original scheme seems resonable, the requests should be distinquish with even only level of requestor specified. 
		    The problem we faced is because of having agent as extra layer. Look at example we refeered in <xref linkend="ds_ifcache_01_disc"/>
		    Ut_conn::test_Sock():58. Ideally the "path" should be: Cp2 - L1 - Out - Cp2 - Data_2. But in reality we have:
		    Cp2 - L1 - Sock (agent) - Out - Sock (agent) .... So the link L1 - Sock (agent) eliminates the request distinquishness from Cp2. The 
		    question is "Can we avoid this cashe in agents?". This solution is also related to solution for agents, ref <xref linkend="ds_base_02"/></simpara>
		<simpara>No, it cannot solve the problem. Theer still will be sutuation where the one level requestor is not enough to correctly resolve
		    iface in cache. </simpara>
	    </sect3>
	    <sect3><title>Solution: using specific CP iface to get pair of socket's pin</title>
		<simpara>The idea is to fit CP with specific iface that provides getting "virtual" pair in case if CP is socket's pin.
		    Socket's pin requested for this iface, gets pair and redirect iface request to it. </simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_ifcache_refr"><title>Refreshing cache on node change. Cache invalidation.</title>
	    <sect3><title>Introduction</title>
		<simpara>Ref to <ulink url="../requirements/index.html#uc_010"/> for use-case related.</simpara>
		<simpara>Ifaces cache needs to be updated properly if some new ifaces got appeared or disappeared in result of mutations. 
		    Currently this functionality is not implemented properly.
		    The only cache invalidation is doing when vertex gets connected or disconnected.</simpara>
		<simpara>The initial idea is that the mutated node needs to know all its iface requestors and to notify all of them 
		    about nodes change that can affect iface providing. 
		    There are forward relations from requester to servece nodes (such nodes that provide the ifaces): 
		    each agent knows to what node of hier to redirect the request. But currently
		    there is no back relations from service node to requesters. 
		    This is because unsuccessful request doesn't go to chache so the node doesn't know of the requester further.</simpara>
	    </sect3>
	    <sect3 id="ds_ifcache_refr_fpt"><title>Proposed solution: having full provders topology in cache.</title>
		<itemizedlist>
		    <listitem>To register requests anycase (i.e. even provider returns null) in order to keep all relations requestor-provider even if
			provider couldn't resolve the request this time. This will "register" provider in the cache, so if "not successul" provider
			changes to be sucessful it can invalidate requestor's cache. This will allow to subsequently invalidate caches by the
			chain from provider to all requestors. So the requestor will re-request iface.</listitem>
		    <listitem>To implement mechanism of unregistering of requests. This is required to keep the relations
			acutal, for instance if some node is deleted, all the corresponding requests needs to be unregistered.</listitem>
		    <listitem>To invalidate the cache of the given node we need to unregister the requests from this node cache, propagating
			this process in both directions: to requestor and to providers. The simplest mechanism seems to be unregister in some
			node of this propagation chain not only requests corresponding to given provider but all the requests with that context.
			In this case we simply unregister the whole request that depends on the initial invalidated provider.  </listitem>
		</itemizedlist>
		<para id="ds_u_20180408">[u_20180408] "all the requests with that context" below is incorrect. In when propagating from provider to requestors
		    we need to invalidate the cache for given interface. This means that if some node gets request "Unregister me as provider from your cache,
		    and yes, I'd actually do it for invalidation" then it's not enough just to unregister the provider. We need also to cleanup cache for 
		    given interface, otherwise the cache will not invalidated. It is important that this "cleanup" means that for each cache record
		    corresponding to given iface we need to unregister the node upward and downward, i.e. as provider and as requestor. This needs to
		    keep the caches consistency.
		</para>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_mut"><title>Mutations</title>
	<sect2><title>Mutations identification, UID</title>
	    <sect3 id="ds_mut_uid"><title>Intro</title>
		<simpara>In the DES engine mutations are considered as object of change so needs to be identified. The identification is used in many use-cases,
		    for instance:</simpara>
		<itemizedlist>
		    <listitem>In mutations rollback to identify the last mutation to be applied
		    </listitem>
		    <listitem>In decoupled chromo to link the chromos part, ref <xref linkend="ds_daa_chrc_rm"/></listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_unappr"><title>Avoidng unappropriate mutations</title>
	    <sect3><title>Rank</title>
		<simpara>We define rank as a vector the i-th element of which is the order of elements owner of i-th level.</simpara>
		<itemizedlist>
		    <listitem>Rank A is greater that rank B if A[i] > B[i] for some i. </listitem>
		    <listitem>We call the number of elements of rank tuple as depth of rank</listitem>
		    <listitem>We are saying that rank R is the rank of level N if N is R depth - 1. The lower level we call "higher" </listitem>
		</itemizedlist>
	    </sect3>
	    <sect3 id="ds_mut_unappr_intro"><title>Introduction</title>
		<simpara>Ref <ulink url="../requirements/index.html#uc_028"/> for use-case.</simpara>
		<simpara>Two structures are under operation when creating system: mutations tree and system native run-time hierarchy.
		    Mutations are the specification of the changes but native hier is the result of applying the mutaions sequence.
		    The mutations are applied in the order that is determined by the structures of mutations tree.
		    The number of step when particular mutation will be applied is the mutations rank.</simpara>
		<simpara>Almost are mutations includes reference to some node of current native hier.
		    These relations can be considered as dependencies network. 
		    Applying mutation Mn can brake the system if the mutaions is placed in unappropriate position within mutation tree.
		    The brackage happens for instance if the mutation related to node NN is placed in the position with the rank 
		    lower that rank of another mutation related to NN and "not knowing" of the first mutation.</simpara>
		<simpara>Below is the example of mutation braking system consistency:
		    <figure id="fig_mut_uappr_intro_ex1"><imageobject> <imagedata fileref="pics/pic_mut_uc1.png"/> </imageobject></figure>
		</simpara>
		<simpara>Mutation tree has the node. The nodes that has leaves (non-terminal node) produces native hier node. 
		    Ref to mutation spec DTD to confirm that. Terminal nodes can be both node creation mutation and change mutations.</simpara>
		<simpara>What relations from mutation to hier node can be? They are almost directly related to mutation
		    attribures specified in DTD: 
		    <orderedlist>
			<listitem> creation (attr ENa_Id in mut "node") </listitem>
			<listitem> parent (attr ENa_Parent in mut "node") </listitem>
			<listitem id="ds_mut_unappr_intro_dep_obj"> object of change (attr ENa_Node in mut "node, rm, change, cont") </listitem>
			<listitem id="ds_mut_unappr_intro_dep_ref"> reference (arrt ENa_Ref in mut "cont") </listitem>
		    </orderedlist>
		</simpara>
		<simpara>So one way of preventing unappropriate mutation is to place it into the position with rank greater than 
		    the maximum rank of all related to given node mutations. But how to get this maximum rank? The problem is 
		    that mutations are not run-time object that can be armed with run-time relation. Mutations are just elements of chromo. 
		    So it is doubtful to create effective scheme of creating that relation network.</simpara>
		<simpara>The simplest solution (Biggest_rank) would be to add mutation to the biggest rank position in chromo,
		    i.e at the end of roots chromo.  In addition the mechainsm of mutations merging (squeezing or compacting of chromo) 
		    can be prepared that removes some mutation and replaces others to lower rank place.</simpara>
		<simpara>Another solution (Run_time_deps) is to collect all dependencies in run-time hier model: to mark the current node 
		    as dependent on some node if the current node chromo includes mutation referred to the node. Basing on this 
		    data it is getting possible to find the max rank dependent chromo, so the current mutation is to go to this chromo. 
		    The problem here is that creating of this dependencies network is complicated even
		    on run-time model level. The dependency is produced by any reference to the node, for instance by referring to node 
		    in URI extention part. </simpara>
	    </sect3>
	    <sect3 id="ds_mut_unappr_rt"><title>Run_time_deps</title>
		<simpara>We need to clarify the term "relation" used earlier. We will say that run-time node Na depends on mutation Mb. 
		    This make sense in terms that run-time node is "object" of change but mutation is "subject" of change.</simpara>
		<simpara>Theses</simpara>
		<orderedlist>
		    <listitem id="ds_mut_unappr_rt_ths1"> If node Na depends on mut Mb then also owners and parents of Na depends on mut Mb. 
			<simpara>
			    Prove for owner:  if there is owner No and it's comp Nc and mut Mc of Nc, then for instance mut of removing
			    No should go after Mc.
			    Prove for parent: There is parent Np and it's child Nc, and there is mut Mc of Nc containgin URI including parent,
			    then for instance mut Mp of renaming Np should go after Mc otherwise Mc will be broken.
			</simpara>
			<simpara>There are different "nature" of these deps. Some of them are created because of referencing via
			    URI, and that uri "trace" include the node. If the trace is going thru inheritance tree that deps parents via
			    childs created as mentioned above.</simpara>
		    </listitem>
		    <listitem id="ds_mut_unappr_rt_ths2"> If node Na depends on mut Mb then all children and components of Na also depend on Mb. 
			<simpara> Proving case for parent: mut Mp changing parent or owner changes URI ref to it, so changes ref to childs
			    and comps. So any mut of childs and comps should go after Mp, i.e with bigger rank. Example: node No contains it's
			    copnonent Nc. There is mut Mo of No of renaming No. So any mut of Nc that ident Nc via URI including Nc name should
			    go after Mo.
			</simpara>
		    </listitem>
		    <listitem>Basing on theses [<xref linkend="ds_mut_unappr_rt_ths1"/>] and [<xref linkend="ds_mut_unappr_rt_ths2"/>] 
			we see that to check dependencies of any node N in native hier we
			need to check it's whole comp and inher branches in the hier.</listitem>
		    <listitem>We can consider mutation as harmless if the mutation supplements run-time model. The following mutation are harmless: 
			node, add. We can consider a mutation as unsafe if the mutation change or reduces run-time model. 
			Unsafe mutations are: rm, change, cont.</listitem>
		    <listitem>The register of deps in node Na contains all mutations (plus nodes containing that mutation) that depends 
			on node Na. So the client is able to get the max rank of nodes that are dependent on the current node.</listitem>
		    <listitem>The dependant is actually the mutation, but only mutation within run-time node (there can be mutaion in 
			some node but it is possible that it doesn't reflect any node in run-time model, for instance if some root node 
			is mutated first by adding component node and than by removing it - all mutation within adding component node part 
			of chromo will not be in run-time.  Mutations are not reflecing directly to run-time model even -node-.
			So the dependency can be defined as the node which chromo containg mutation plus mutation itself in chromo.</listitem>
		    <listitem>There are deps "model-on-chromo" and "chromo-on-model". We can consider the type of dep as the type 
			of mut argument</listitem>
		    <listitem>We need to consider not only simple deps but chain of deps. The example of chain is inheritance chain, node3 on node1:
			<programlisting>
			    mut1 on node1 as -parent-
			    node2 on mut1 as -id-
			    mut2 on node2 as -parent-
			    node3 on mut2 as -id-
			</programlisting>
		    </listitem>
		</orderedlist>
		<simpara>So the algorithm of taking into account dependencies for mutation of type -rm- is as:</simpara>
		<itemizedlist>
		    <listitem>Get the node being removed </listitem>
		    <listitem>From this node get the major dependent node - the dependent node with biggest rank. The depencend node is 
			run-time node containing dependent mutation, or child of this node (ref Theses) or child of node being removed.</listitem>
		    <listitem>Mutate the dependency instead of initial node.</listitem>
		</itemizedlist>
		<simpara>Below is shown the example of using dependencies</simpara>
		<figure id="fig_mut_uappr_intro_ex2"><imageobject> <imagedata fileref="pics/pic_mut_uc2.png"/> </imageobject></figure>
	    </sect3>
	    <sect3><title>Restrictions of mutations</title>
		<simpara>We introduce the restriction of mutations that can simplify the validation of mutations</simpara>
		<orderedlist>
		    <listitem>Rank depth of mutations of dependency type "object" and "parameter" (ref <xref linkend="ds_mut_unappr_intro_dep_obj"/>, 
			<xref linkend="ds_mut_unappr_intro_dep_ref"/>) must be less or equal of rank depth of mutated node. 
			In other words the object of mutation must be owned of node that contains the mutations. </listitem>
		    <listitem>It is not allowed to remove a node if the node has childs. This restriction can be removed in the future. 
			Currently it is not supporting of creating child when some parent in parents chain is missed. Potentially
			there is no fundamental problem with removing parent. But even in this case we need to take into account the childs 
			as the deps.</listitem>
		</orderedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_rm_prnt"><title>Deleting of parent- how to keep system consistency [uc_029]</title>
	    <sect3><title>Criticizm</title>
		<simpara>Seems the current scheme of creation node is totally inconsistent with principles of incremental creation. The scheme
		    is working but the problem is that it is based on run-time parents that is not always real case. More correct scheme would be that
		    basing on non-run-time parents, i.e. on chromos. This would be working for all the cases.</simpara>
	    </sect3>
	    <sect3><title>Possible solutions</title>
		<sect4><title>To check the parent - if run-time parent doesn't exist then get its chromo from system chromo.</title>
		    <simpara>This approach goes to using parent's chromo instead of run-time nodes as is in current solution.
			Can we use chromo? The doubts are
			because of the incremental mutation scheme principle "Chromosome as subject and system as object of creation". 
			This means that the references in chromo (to object node, to parent etc.) are the references within system but 
			not within chromo itserf.</simpara>
		    <simpara>Usecase is: root node N_R, its comp N_A contains N_A_1, then N_A gets removed, creator makes mutation in 
			N_R to create N_B for that this N_A_1 is in parents chain. 
			The problem here is that even we get N_A_1 chromo to mutate, the mutation has to be done in context of N_A 
			that is also removed. So the references from
			mutations within N_A_1 chromo to internals of N_A are broken. How the mutaion with chromo N_A_1 can be done? 
			It shuldn't be a problem if we take into 
			account the principle "Mutations references of types other than -parent- can point only to onwned node". 
			This means that the mutation within N_A_1 can 
			contains references only inside of N_A_1. The only parent reference can be to outside of local conext, 
			but as was discussed parents relation is safe in root chromo.</simpara>
		    <simpara>The weaknes of this solution is that it requires that parents chromo node can be found from the 
			node being mutated with -node- mutation. So 
			we need to have ChromoNode methods like GetNode, the analogue of such method in run-time Elem. 
			But chromo has only one explicit relations net - native hierarchy of
			ownership. Chromo doesn't support hierarchy of inheritance. This makes the problem to use this approach 
			because inheritance based URIs cannot be resolved in chromo. </simpara>
		</sect4>
		<sect4><title>To not actually remove run-time node but mark it as removed</title>
		    <simpara>Node having this mark shall deny any mutations. The clients should ignore and hide "removed" nodes.</simpara>
		    <simpara>Weaknesses?</simpara>
		    <itemizedlist>
			<listitem> Seems just workaround. </listitem>
			<listitem>Comp is not deleted actually, so it is kept in owner comps register. This can cause problem with 
			    multiple choice when resolving component. 
			    Currently the following mutation is quite popular, in Extender for instance: to remove default Int 
			    and to create custom Int. But in this case there will be two Ints.</listitem>
		    </itemizedlist>
		</sect4>
	    </sect3>
	    <sect3><title>QnA</title>
	    </sect3>
	</sect2>
	<sect2 id="ds_rn_prnt"><title>Renaming of parent - how to keep system consistency [uc_031]</title>
	    <sect3><title>Intro</title>
		<simpara>Ref <ulink url="../requirements/index.html#uc_031"/> for use-case</simpara>
	    </sect3>
	    <sect3><title>Analysis</title>
		<simpara>Current implementation is just notify the owner of renaming, so owner makes the correction into components register. UC_031 is not considered currently.
		    But it seems there is no fundamental limitation as for removing of parent, ref <xref linkend="ds_rm_prnt"/>. This is because the parent is accessible from child
		    node in runtime. The only problem is that currently the child refers to parent via chromo data on creation heir, ref Elem::CreateHeir.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mv_local"><title>Local Moving of node.</title>
	    <sect3 id="ds_mv_local_intro"><title>Intro</title>
		<simpara>Actually local moving of node is not single mutation but two mutations: 
		    re-creating node in new context and removing initial node.</simpara>
	    </sect3>
	    <sect3 id="ds_mv_local_tch"><title>How to transform chromo for new context</title>
		<simpara>One of the problem when re-creating node in new context is transformation node's chromo to be 
		    sutable for new context. </simpara>
		<simpara>There can be some solution considered. One of them is to transform source node chromo to destination node context. 
		    This approach is rather complicated for
		    implementation. Another approach is to use currently implemented mechanism of creatng heir. 
		    So we can create heir from source node (this is done by source node 
		    in original context, so doesn't cause any troubles. Then we can re-adopt the heir from source node to its parent.</simpara>
	    </sect3>
	    <sect3><title>Is operation of local movement useful?</title>
		<simpara>The problem here is that the current implementation [ff62b4f15279edfbe4baf36161d3dcad6973725f] 
		    the result of local movement is run-time only. It is 
		    clear, we just need to remember that local movement is specified by simple mutation within the chromo.
		    So there are doubts that local movement is actually useful. There
		    were no occurances at the moment of using this local movement operation.
		</simpara>
		<simpara>There is alternative approach, ref <xref linkend="ds_mut_cutncopy"/></simpara>
	    </sect3>
	    <sect3 id="ds_mv_local_nm"><title>Local movng and node mounting</title>
		<simpara>There is tight relation between moving of node and mounting some remote node to local node. Mounting of remote node can be
		    considered as one approach of distributed systems, ref <xref linkend="ds_daa"/>. Mounting remote node seems similar to moving - 
		    it is in fact de-attaching some node from remote model and attach it to some local node - so the context is changed in this case.
		</simpara>
	    </sect3>
	    <sect3 id="ds_mv_local_wkc"><title>Anoter way to keep consistency when moving node - using mutation context.</title>
		<simpara>The main problem with moving node is to keep all the "references" correct in chromo, ref <xref linkend="ds_mv_local_tch"/> for
		    details and current solution description. Anoter possible solution can be as follow:
		    <itemizedlist>
			<listitem>Special attribute is introduced in base agent - mutation context. (It's interesting how this mutation context
			    corresponds to mutation context introduced in <xref linkend="ds_daa_itn_sfo"/>?).</listitem>
			<listitem>All mutations are executed on base on this attribute.</listitem>
			<listitem>Specia mutaion is added - "Change of mutation context". This mutation adds new element to mutation context.</listitem>
			<listitem>When node A is moved to node B, not only node B mutation of moving is applied but node B also mutates
			    node A with mutation "Change of mutation context"</listitem>
			<listitem>When node A creates heir, the A mutations are subsequentely applied to its heir. As soon as mutation
			    "Change context" occurs the attribute "mutation context" is set from the mutation.</listitem>
		    </itemizedlist>
		</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_rm"><title>Removing of node</title>
	    <sect3 id="ds_mut_rm_appr"><title>Real deletions vs marking as removed</title>
		<simpara>There are two approaches considered of how to implement removing mutation:</simpara>
		<itemizedlist>
		    <listitem>#1 - to really remove node from model</listitem>
		    <listitem>#2 - to mark node in model as removed but keep it in model</listitem>
		</itemizedlist>
		<simpara>Removing node allows save resources, but there is serious problem with that approach. The matter is
		    that models node keeps register of dependencies. These registers are required for instanse for
		    squeezing chromo, ref <xref linkend="ds_mut_squeezing"/>. So approach#2 is to be applied. </simpara>
	    </sect3>
	    <sect3 id="ds_mut_rm_appr2"><title>Approach#2 details (marking node as deleted, no real removal)</title>
		<itemizedlist>
		    <listitem>Owner has to keep removed component in owners register. We can distinguish 
			bottom-up notification from component in case of mutation of removing (soft removing acc to
			approach#2), and real removing. This means that in this notification handler the owner should 
			behave differently: don't de-register component if soft removal, and de-register if real removal.
		    </listitem>
		</itemizedlist>
	    </sect3>
	    <sect3 id="ds_mut_rm_deps"><title>Refusing removing if deps presents</title>
		<simpara>Node removing mutation has to be refused if there are critical dependencies on this node.
		    Missing the node in this case will cause model creation errors. The reason of this
		    policy is that event if the node is not really removed from the model (i.e approach#2 from 
		    <xref linkend="ds_mut_rm_appr"/> is used) the further chromo squeezing will lead to the node
		    completely removing from the model.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_transp"><title>Nodes (mutations) transposition (reordering)</title>
	    <sect3><title>Intro</title>
		<simpara> Nodes transposition, or nodes shifting is just changing the order the nodes in the 
		    owner node. The order is inportant for model creation because actually the model creation "machine" is single-pass. 
		    So the mutation that use reference to some node must be applied AFTER the referenced node is created.</simpara>
		<simpara>There was the discussion around this operation, 
		    ref <ulink url="../../../fap-doc/doc_incr_syst_creation/index.html#sec_lim_transp"/>. There was conclusion
		    that transposition is not allowed in the scope of incremental mutations approach.</simpara>
	    </sect3>
	    <sect3><title>Approached</title>
		<simpara>There are potential solution for the problem of changing order:</simpara>
		<orderedlist>
		    <listitem>Not consider changing order as chromo mutaion, ref <xref linkend="ds_transp_nochange"/></listitem>
		    <listitem>Add specific mutation, improve ordering mechanism, ref <xref linkend="ds_transp_mut"/></listitem>
		</orderedlist>
	    </sect3>
	    <sect3 id="ds_transp_nochange"><title>Approach: Not consider changing order as chromo mutaion </title>
		<simpara>The disadvantage here is that there will not be the history of change.</simpara>
	    </sect3>
	    <sect3 id="ds_transp_mut"><title>Mutation for transposition instead of direct changing of chromo</title>
		<simpara>The decision that transposition is not allowed in incremental mutation scheme is based on the assumption that
		    the transposition is done via direct chromo changing. But it is still possible to change the order without 
		    direct changing of chromo. The idea is that the mutation can be used, that specifies the change of order.  </simpara>
		<simpara>In this case we still follow the incremental mutaions approach and the same time can change the order. 
		    Another point is that the mutaion mechanism needs to be improved to support the change order mutation. This is 
		    because the mechanism should operate not only with the current mutation as usual but take into account all nodes
		    in the current upper level node and "create" the order before adding the nodes. There is also the option of 
		    inserting the order change mutation at the beginning of the upper level node.</simpara>
		<simpara>One of the solution could be as following. The -node- mutation includes specific element - container of reordering mutations. This element should be the first
		    within -node-. Reordering mutation is like: 'order' object_order target_order, where object order is the initial order of reordered mutation and target order is initial order of 
		    mutation before that the reordered mutation is shifted. The initial order is id of native order of mutation in owned node, i.e the order of mutation in local chromo. When -node- mutation
		    gets applied, the mutated agent first calculate the order of mutations using reodreding mutations and then applies the mutaion according to new order. In result the chromo of 
		    agent will be reordered. To keep chromo original this reordered chromo needs to be transformed back to unordered state on chromo saving.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_dis_pheno"><title>Disabling/Enabling phenotypic modificaions</title>
	    <sect3><title>Intro</title>
		<simpara>Last time there was decision made to introduce new options - disabling pheno modificaions</simpara>
	    </sect3>
	    <sect3 id="ds_mut_dis_pheno_cs"><title>Cause of the problem</title>
		<simpara>The root-cause of the problem is contradiction between the sequence of changing model and 
		    option of inheritance of childs from the structural part of system native hier. If we didn't require 
		    such an inheritance then we can use flat chromo where the order of mutations completelly corresponds to
		    the order the changes applied to the system on construction phase.</simpara>
		<simpara>However native hier (structure) is very important part of system creation and cannot be
		    avoided or ignored. This approach is to create the system via a set of components, which are
		    improved via inheritance and local mutations. According to this approach the mutation in parent must
		    be applied before the childs creation. But this mutation applying sequence differs from native secuence 
		    (the sequence of how the mutation were introduced)</simpara>
		<simpara>Actually to keep original sequence is not a problem. For instance flat chromo can be used.</simpara>
		<simpara>There is another option of keeping the original sequence of mutation - mutation order. 
		    Currently it is possible to set order value for each mutation. So if the "chromo machine" could to
		    apply the muts according to the order it would be equivalent to flat chromo. Equivelency means that these
		    forms of chromos can be explicitly transformed one to another.</simpara>
		<simpara>But again the real problem is that approach of creating system via inherited sybsystems requires that
		    the sequence of applying differs the original sequence.</simpara>
	    </sect3>
	    <sect3><title>Inheritance based approach: solving the problems.</title>
		<simpara>Currently inherirance based approach is the primary mechanism for creation system. The problem of 
		    not keeping the original sequence in this case can be mitigated by disabling phenotypic modification. What
		    are the theats of breaking chromo safety:
		    <itemizedlist>
			<listitem>Changing ref: dependencies on the local owner component with the bigger rank.
			    This problem can be fixed by shifting mutated node root mutation over to dependency mutation. This will
			    not affect the model because this shifting is local, ref also <xref linkend="ds_indp_mutord"/></listitem>
			<listitem>Renaming subnode that is referenced. No solution here, required change of ref.</listitem>
		    </itemizedlist>
		</simpara>
	    </sect3>
	    <sect3><title>Flat chromo approach</title>
		<simpara>Issues</simpara>
		<orderedlist>
		    <listitem>What if we create child from a node and then apply some mutation to the node. Then we d like to
			have this mutaion in child also.</listitem>
		</orderedlist>
	    </sect3>
	    <sect3 id="ds_mut_dis_pheno_rebase"><title>Hibrid approach: pheno modif not hampering inheritance. Reparent mutation.</title>
		<simpara>As mentioned in <xref linkend="ds_mut_dis_pheno_cs"/> the approach of creating system via inherited 
		    subsystems are explicit and convenient. Subsystem_B that inherites Subsystem_A is "improvement" of Subystem_A. 
		    The whole system normally "grows up" by adding new improvements to the current chaing: Subystem_C, or branching. 
		    But it is also possible that system creation requires to change initial subsystem in the chain. This can happen 
		    for instance in case when there already is big three of inherited subsystem and then error in some base subsystem gets
		    discovered.</simpara>
		<simpara>The "traditional" approach works here: we can mutate the base subsystem and there regenerate the system. This 
		    is how "disabled pheno modif" is working. As discussed there is problem with that approach - we introduce break in native
		    sequence of mutations. There is one approach that potentially allows to make change in base subsystems and same time
		    keep native sequence of mutation. This approach is not to mutate base subsystem, but create inherited subsystem, 
		    mutate it properly and then "rebase" the upper tree part to it.</simpara>
	    </sect3>
	    <sect3><title>Issues</title>
		<orderedlist>
		    <listitem>In case of pheno disabled it will not be possible to change parents but keep childs out of this change. 
			Currently (enabled pheno) it
			is possible to change parent even after there was children created. Then potentially we have an option to 
			"rebase" children via moving pheno to mutation. In case of pheno disabled we need to refuse any mutations in 
			parent or enable the mut, so do "rebasing" immediatelly. In fact this "immediate" rebasing is exact 
			approach of system creation using inheritance.</listitem>
		</orderedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_pheno"><title>Controlling of Phenotypic modification mode</title>
	    <sect3><title>Introduction</title>
		<simpara>Initially phenotypic modification was enabled by default. On practice this mode was rather
		    inconvenient because of pheno modifs created a lot of dependencies. To keep chromo safe we transform many changes 
		    to pheno modif and put them after corresponding deps. In result the constructed system chromo
		    become mess. Also this hardened inheritance - the changes that should be real mutations were transformed to
		    pheno modif that were not involved in inheritance process.</simpara>
		<simpara>After this problem analysis it was decided that we need to restrict the pheno modif mode and have
		    pheno modif disabled by default. Only for inherited nodes the pheno modif would be enabled in this case	.</simpara>
		<simpara>But this decision also resulted in problem. For instance it got not possible to simply change 
		    ref in Edges connpoint. So if some edge was created with low rank and then it became required to make connection
		    to node with greated rank then it result in critical dependency. There were two approached considered: 
		    <itemizedlist>
			<listitem>to move edge locally in order to increase edges rank, ref <xref linkend="ds_indp_mutord"/></listitem>
			<listitem>to introduce the ability to set pheno mode for particular agent.</listitem>
		    </itemizedlist>
		</simpara>
	    </sect3>
	    <sect3><title>Shifting node to increase its rank</title>
		<simpara> This approach cons is that actually it is not possible to do it via simple mutation. It was discussed 
		    many times, ref <xref linkend="ref_incr_mut"/> for the discusstion, specifically the section
		    "Transposition of nodes within chromo is not allowed". Also ref <xref linkend="ds_transp"/> for the design 
		    related discussion. The short explanation is that the initial mutaion anytime goes first so to change nodes rank we
		    need to edit chromo but not mutation it additivelly.</simpara>
		<simpara>So to shift the node we need to recreate the node, remove initial one and then squeeze the chromo to 
		    avoid errors reporting because of initial mut is failed. Not simple approach really.</simpara>
		<simpara>The update here is that "chromo invariance with regards to node order" principle can be applied,
		    ref <xref linkend="ds_indp_mutord"/>. This will solve the problem mentioned above because shifting of the node
		    is not mutation anymore (nodes position just doesn't affect the model at all).</simpara>
	    </sect3>
	    <sect3><title>How to set pheno mode for an agent</title>
		<simpara>The most realistic approach is to add specific new attribute of node and to add specific Elem API, like
		    IsPhenoEnabled(). Agent will be able have its own default value for this attribute. For instance Edge agent
		    could set this attribute as enabled.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_squeezing"><title>Squeezing of mutations (Optimization of chromo).</title>
	    <sect3><title>Intro</title>
		<simpara>Squeezing of mutation seems at the first glance obvious and simple. 
		    Indeed, if there are two adjacent renamings the same node then we can
		    remove the first one because its effect is completelly eliminated by the mutation following.
		    So generalizing this particular case to all the mutations we
		    can go to the simple idea that all mutations can be checked for being excessive and removed or maybe 
		    merged.  But this simple idea became not realistic on detailed analysis. </simpara>
	    </sect3>
	    <sect3><title>Approaches: reverse engineering</title>
		<simpara>One of the approach for squeezing the mutaions is: as the result of all mutations is the created 
		    system, then all what we need is to get the system,
		    and "regenerate" the mutatation from the system, i.e. to do kind of "reverse engineering". 
		    The problem here is that is is not possible to do it by using some
		    simple algorithm. First of all there is no possibility to "eliminate" any mutation applied to part of 
		    node that comes from parent, so called detached chromo. 
		    But these mutations can have references to node that then changed by further muatinons.
		    Let's look at the example:</simpara>
		<programlisting>
		    add node="node_1" {
		    node id=node_1_0 parent="some_node"
		    }
		    rename node="some_node" val="some_node_renamed"
		</programlisting>
		<simpara>So there is no way to restore the -add- mutation from model. In other words the "outer" mutations 
		    aka "phenotype" are ambuguous, so we cannot say from what they 
		    were applied. So no possibility to recreate them from the model.</simpara>
	    </sect3>
	    <sect3 id="ds_mut_sqeezing_mrg"><title>Approaches: Direct merging.</title>
		<simpara>Let's assume that we have all relations between the model and mutaions in chromo. 
		    There are relations of two directions: 
		    rt node to mutations and mutations to node. This allows getting relations quickly from both parts.
		    The relations includes the reference to muation, and the type, 
		    ref <xref linkend="ds_mut_unappr_intro"/> </simpara>
		<simpara>The algorithm of squeezing chromo of the given RT node would be like outlined below. 
		    For clarity aim let's consider the particular mutation, -rn-:</simpara>
		<orderedlist>
		    <listitem>Start from the second mutation (remember the first is -node- itself)</listitem>
		    <listitem>Check if the mutation can be squeezed. For -rn NODE_X NEW_NAME- the checking passes by 
			default because there must be mutation -node- with lower rank.</listitem>
		    <listitem>Rename NODE_X within initial mutation -node NODE_X_name"</listitem>
		    <listitem>Keep chromo consistent - Go thru all mutations  depending on NODE_X and which rank lies 
			between initial -node- and given -rn-: correct the reference to NODE_X according to -rn- 
			paramenter.</listitem>
		</orderedlist>
	    </sect3>
	    <sect3 id="ds_mut_squeezing_hist"><title>How to save chromo "history" on squeezing ?</title>
		<simpara>All approaches discussed above assume that excessive mutations are to be removed from chromo. This
		    means that mutations rollback gets not correct because the part of chromos "history" lost.</simpara>
		<simpara>To keep the history we could use marking excessive mutations as "deleted" instead of them real 
		    deleting. This solution looks simple and obvious but it will not work. This is because any of 
		    squeezing approaces assumes that chromo is changed in result of squeezing procedure. And these changes
		    are not "regular", i.e. they are not introduced via adding of mutations. 
		    Instead mutations themselves are being changed, ref to example in <xref linkend="ds_mut_sqeezing_mrg"/>. 
		    This makes rollback inapplicable for squeezed chromos.  </simpara>
		<simpara>Is it real limitation for keeping history? Probably not. We can try to avoid changing of mutations 
		    themselves. To be more exact, we can use those changes that can be reverted. For instanse we can use 
		    mutation attribure showing that the mutations is inactive. This attribute can be simply removed if we 
		    want to revert squeezing. Let's call this approach "soft optimization".
		    What about -rn- mutation?  How can we avoid mutations change in this case? 
		    This -rename- mutation is quite specific. This is separate subject of consideration of it because this 
		    mutation changes reference to the renamed node. Some alternative approaches were already 
		    discussed, e.g using aliases.</simpara>
		<simpara>Another approach to keep chromo history is to introduce one more level on model - model of 
		    changing of chromo, <xref linkend="ds_mmc"/>. This makes chromo itself just intermediate
		    model being generated from upper layer model. "Chromo of chromo" or chromo2 can include all operations
		    of changing chromo, not only elementary but also operations like "squeeze chromo" etc.</simpara>
	    </sect3>
	    <sect3 id="ds_mut_sqeezing_so_prnc"><title>Soft optimization: principles</title>
		<sect4 id="ds_mut_sqeezing_so_prnc_att"><title>To optimize only attached mutations</title>
		    <simpara>The reasoning of this principle is that optimizing out de-attached mutations is not
			permanent. There are a lot of use-cases causes to errors if this is not followed. For example
			ref to uint test Ut_mod::test_ImpsMgrOpt().</simpara>
		</sect4>
		<sect4 id="ds_mut_sqeezing_so_prnc_cnd"><title>To omit optimization if opt conditions aren't met.</title>
		    <simpara>Example is: </simpara>
		    <programlisting>
			00 node A1
			01 cont some_node ref=A1
			03 rm A1
		    </programlisting>
		    <simpara>Mutation 03 is wrong, it was denied because A1 has dep of type -ref-. Of course
			in normal surcumstances the mut -rm- couldn't be included to the chromo, but what is it
			already happened? In this case -rm- mutation will not be applied, so optimization procedure
			will not find original mut -node-. Let's consider this as not meeting optimization 
			condition. In other words, we say that only chain of correct mutations has to be 
			optimized, but not wrong mutations.</simpara>
		    <simpara>There is another approach. We can say that any mutations that are "ecessive" in
			chromo are to be optimized out. According to that, wrong mutations are to be optimized out too.
			There is problem with this approach. If it is applied to the example above we will miss the
			error messages in the log.
		    </simpara>
		    <simpara>Select approach#1 as working.</simpara>
		</sect4>
		<sect4 id="ds_mut_sqeezing_so_prnc_mp"><title>Optimization to be multy-pass procedure</title>
		    <simpara>In result of first pass of optimization some mutations gets optimized out, this change
			the chromo thus changes the conditions of optimization. So optimization has to be repeated
			several times until the chromo gets unchanges.</simpara>
		</sect4>
	    </sect3>
	    <sect3 id="ds_mut_sqeezing_rm"><title>Soft optimization: -rm- mutation</title>
		<sect4><title>Procedure of optimization</title>
		    <simpara>Optimization rules are:</simpara>
		    <orderedlist>
			<listitem>Optimize out original -node- mutations (that is removed via -rm-) if there
			    are not critical dependencies (-parent- and -ref-). So there will be creator responsibility 
			    to release these deps first. There is alternative approach when deps of some type
			    (e.g. -ref-) are not blocking -rm- so optimized out automatically.</listitem>
			<listitem>Optimize out all remaining mutations dependent on removed node
			    (e.g. with -node- dep type)</listitem>
		    </orderedlist>
		    <simpara>Regarding approach of considering some deps not blocking. Does it make sense to 
			consider -parent- deps also not blocking. What would be the criteria of not blocking deps?
			The criteria would be that optimization out such dependence doesnt cause further propagation of
			optimization. For instance optimizing out -parent- dep leads to such propagation (optimizing out
			the child node equivalent to removing the node, this causes in turn necessity to optimize out
			the child of this node and so on. So -parent- dep doesn't satisfy the criteria of non-propagation.
			Probably it make sense to introduce new option "Removal policy: strict/soft" where strict
			policy assumes the critical deps are to be resolved by the user first but soft policy allowes
			automatically optimize out all the deps.
		    </simpara>
		</sect4>
	    </sect3>
	    <sect3 id="ds_mut_sqeezing_cont"><title>Soft optimization: -cont- mutaion</title>
		<simpara>Let's verify the soft optimization approach via considering chromo optimization for
		    -cont- mutation. The general method of optimization is marking as optimized those mutations that
		    gets redundant after some futrher mutations introduced. Criteria of mutation getting redundant is
		    in general that the given mutations is overriden by further mutations and there is no dependencies on
		    the model from the given mutation (i.e. optimizing mutaion out doesn't affect the model).</simpara>
		<simpara>So depencencies are the important part of optimization limitations. The picture below illustrates
		    example of limitation:</simpara>
		<figure id="fig_chromo_opt_cont">
		    <imageobject> <imagedata fileref="pics/pic_chromo_opt_cont.png"/> </imageobject></figure>
		<simpara>First mutation -cont- changes content of run-time node, then next mutation creates new node
		    using this node as parent. Next mutations again changes content of the node. First -cont- mutation
		    cannot be optimized out because of critical depencency on mutation -node-: if -cont- is optimized out
		    then the child creaded via -node- will miss content change done in the first -cont-.</simpara>
		<simpara>The problem here is that user cannot avoid this limitation even he knows that this dependency is
		    not really critical, i.e. it is not possible to eliminate this dependency via additional mutations.
		    In some cases thou there are ways to optimize. In the case above for instance it is possible 
		    to eliminate dependency: user can remove node creaded via second (-node-) mutation and then
		    optimize chromo. -node- mutations will be optimized off, so the dependency will be removed and 
		    the first -cont- mutation can be then optimized off too. This requires at least two passages of 
		    optimization.
		</simpara>
		<sect4><title>Case: removed reference</title>
		    <programlisting>
			cont N_1, _REF(N_2)
			rm N_2
			cont N_1, _new_value
		    </programlisting>
		</sect4>
		<sect4><title>Taking optimized off muts into account when adding new mut</title>
		    <simpara>Optimized off mutations are to be taken into account when adding new mutations.
			The reason of that is that chromo machine can move nodes locally in case the deps are
			not broken. Optimized off mutations are to be used in deps analsys. Otherwise deps 
			broken can occurs after optimization undo.</simpara>
		</sect4>
	    </sect3>
	    <sect3 id="ds_mut_sqeezing_sft_lim"><title>Soft optimization: deficiencies and limitations</title>
	    </sect3>
	    <sect3 id="ds_mut_sqeezing_smautm"><title>Soft optimization: automatic optimization</title>
		<sect4><title>Introduction</title>
		    <simpara>There was the idea (ref. <xref linkend="ds_mut_sqeezing_rm"/> that the optimization 
			can be done automatically each time the user adds new mutation. 
			Then on new mutation being introduced (mutation introduction is 
			done using "triage" mutation mode) the chromo machine runs optimization procedure.</simpara>
		</sect4>
		<sect4><title>Processing mut opt attribute when analyzing deps</title>
		    <simpara>After each optimization the model reloading would be required. This happens not always
			but in principle we will need to reload the model. This is for instance because mutations to
			be optimized out are blocking deps for mutation creator is going to add. Example is:</simpara>
		    <programlisting>
			01  node A1 ...
			02  cont node=NN ref A1
			...
			03  cont node=NN ref NONE
			04  rm node A1
		    </programlisting>
		    <simpara>Creator edits initial chromo {01, 02}, then he is going to remove A1. But A1 has 
			critical dep 03 of -ref- type, ref <xref linkend="ds_mut_sqeezing_rm"/>.
			To remove this dep creator change the ref to NONE. The ref
			is removed from the model but there is still mutation in chromo, so chromo machine still
			denies removal A1. To continue removing A1 creator needs to optimize the chromo (it will
			optimize out 02) first and then reload model. After that the dep 02 will not exist anymore and
			chromo machine allow removal A1. To avoid reloading another solution can be used - to analyze 
			optimization attribute of mutation when analyzing the deps.</simpara>
		</sect4>
	    </sect3>
	</sect2>
	<sect2 id="ds_drv_int"><title>How to derive from component of heirs</title>
	    <sect3><title>Introduction</title>
		<simpara>Currently the following mechanism is used for derivation. Node [N] that is adding component [(CP:)C]  gets components parent [CP], requests it to produce the child in its own context,
		    relocate the created child to nodes hier, and then applies the mutations [CM] to the components. Note that the mutation applied to the component are being done in
		    node [N] context. It causes the following problem: when some system [S] uses node [N] as parent for derivation new node [N~1] then [N~1] will have another component [C] 
		    (it is also named [C] but it is not the same [C] as [N] has). This component [C] chromo [CM] is related to node [N] context. </simpara>
		<simpara>Ref to diagram below.</simpara>
		<figure id="fig_mut_drv_int1"><imageobject> <imagedata fileref="pics/pic_ds_mut_drv_from_comp.png"/> </imageobject></figure>
		<simpara>So it happens that CM/C is not suited for derivation because its chromo is for another context. To generalize: the components that were came to child from parent in derivation process are
		    not sutable for inheritance if the childs context differs from parents context. How to deal with this case?</simpara>
		<simpara>There could be the following approaches suggested:</simpara>
		<itemizedlist>
		    <listitem>To detect if the components is suitable for inheritance, i.e. if some of its owners were moved from original context.</listitem>
		    <listitem>To modify of creating of new node: to truly relocate the heir, not only change the owner. Ref <xref linkend="ds_drv_int_rel"/> for details</listitem>
		</itemizedlist>
	    </sect3>
	    <sect3 id="ds_drv_int_rel"><title>Approaches: To modify of creating of new node</title>
		<simpara>Currently to relocation of created heir to new hier is being done quite simple, ref. elem.cpp/Elem::CreateHeir()/Relocate heir to hier ... The only 
		    new owner is set for created heir, no any corrections in mutations referred to original context.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_cutncopy"><title>Chromo cutncopy: do we need it?</title>
	    <sect3><title>Intro</title>
		<simpara>There are some usecases clearly indicated that copy of chromo is useful operation. One of cases is:
		    USER has some complex model and he wants to separate some part of this model as independent model.</simpara>
	    </sect3>
	    <sect3><title>Cons</title>
		<itemizedlist>
		    <listitem>Doesn't support of simple undo. This is because copy operation is not single mutaion but series of mutations.</listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_indp_mutord"><title>Independence on local mutations order (chromo invariance with respect to nodes order)</title>
	    <sect3><title>Refs</title>
		<itemizedlist>
		    <listitem>Use case: <ulink url="../requirements/index.html#uc_046"/></listitem>
		    <listitem>Use case: <ulink url="../requirements/index.html#uc_050"/></listitem>
		</itemizedlist>
	    </sect3>
	    <sect3><title>Extra UC: Refusing of mut with non-resolvable unsafety</title>
		<simpara>Main usecase is that new mutation is checked for safety and SYSTEM repositions the mutations
		    in case if unsafety is detected. But what if mutation introduces unsafety that cannot be fixed?
		    This can be the case of cyclic dependencies for instance.</simpara>
		<simpara>Assuming that initially there is no cycles in the node. So the procedure would be as:
		    Checking if new mutation introduce a cycle into the node, is so then refuse it.</simpara>
		<simpara>To prove: If there are no cycles in the node then it is not possible to creaty any cycle via
		    re-positioning the node components.</simpara>
		<simpara>To prove: If there are no cycles int the node then the node components can be ordered to have 
		    only backword dependencies.</simpara>
	    </sect3>
	    <sect3 id="ds_indp_mutord_impl"><title>Taking in consideration implicit dependencies</title>
		<simpara>Refer to use case <ulink url="../requirements/index.html#uc_050"/> for details.</simpara>
		<simpara>The base approach of shifting mutation is as:</simpara>
		<itemizedlist>
		    <listitem>System founds the dependency for given mutation</listitem>
		    <listitem>System get common owner for given mutation and the dependency</listitem>
		    <listitem>System shift in the common owner the node containing given mutation over the node containing the dep.</listitem>
		</itemizedlist>
		<simpara>The first step here is most important. According to use-case not only the explicit dependencies are to be taken into
		    account but also implicit. These implicit dependencies are specific of agent and cannot be resolved by default.</simpara>
		<simpara>Let's look at the agent "Edge" (the scenario is exactly described in use-case ref). The agent itself doesn't expose
		    some specific dependencies, because of being just almost "passive" owner of pair of references. But real "creator" the
		    implicit dependencies here is the system owning the edge. This is because the connection point compatibility checking is being done
		    by onwning system but not the edge itself. Exaclty on the checking the dependency is become apparent.</simpara>
		<simpara>How would be the approach of checking the implicit dependency in this case ? The approach would be like this:</simpara>
		<itemizedlist>
		    <itemizedlist>Supposing the base agent (Elem) has the virtual method "GetImplicitDeps", which default implementation
			is just run "GetMajorDep" and if no dep found, just redirect it to its owner.</itemizedlist>
		    <listitem>Edge gets mutation. Edge runs GetImplicitDeps, that just is redirected to edges owner - the system.</listitem>
		    <listitem>The system analyses the request, understands that the initial mutation is the change of edges point, so 
			asks the points ref to get the deps</listitem>
		</itemizedlist>
		<simpara>This approach has one defect: just having virtual agent method will not work. The reason is that the deps are not determine 
		    by agent itself but by the role the agent plays in its owner. For instance, ConnectionPoint agent can be referenced within vertes 
		    as just vertex but not Connectable. So as a vertex ConnectionPoint doesn't have some specifics for deps. But if it is referenced
		    within system, then it becomes specific deps as Connectable. So Connectable has to have its own method for deps.
		</simpara>
		<simpara>Also it needs to be considered if all mutation require asking owner to find implicit deps. As we see the implicit deps are 
		    generated by run-time behaviour, i.e by agents specific. Let's look at what parts of mutation require knowledge of deps. As we 
		    already discussed the dep is actually dep runtime node on another dep. So saying "what are the deps for the given mutation" we
		    have to say "what are the deps for all runtime nodes referenced by this mutation". There are three kinds of runtime nodes 
		    references in mutations: object, parent, and ref. What refs can generate implicit deps in agents? To answer this question we
		    need to look at which references are specifically handled by agents. All such handling is initiated via MCompsObserver iface. The
		    review of the current handling implementation is as: </simpara>
		<programlisting>
		    Syst::OnCompDeleting - object
		    OnCompAdding - default handling only
		    OnCompChanged - many agents hadnling change of ref in content. So - ref
		    OnCompRenamed - default handling only
		</programlisting>
		<simpara>So at the moment the only specific deps for mutation nodes referenced via ref attribute have to be taken into account.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_attach"><title>Concept of nodes chromo attaching</title>
	    <sect3 id="ds_mut_attach_calc"><title>Attaching sign calculation</title>
		<simpara>Currently the concept of nodes chromo attaching is actively used. There is base agents proper APIs for that: IsChromoAttached.
		    We say that nodes chromo is attached if there is path from nodes chromo to system chromo root node. But currently the attaching sign
		    is calculated a bit incorrectly. In result the nodes not directly attached but placed to component are not considered as attached, example is: 
		    [node node=some_component parent=some_parent name=some_name]. This causes problem when pheno modification disabled: on one hand such node 
		    is detected as not attached so its attached owner is selected as the mutation point,
		    on another hand the error "attempt of pheno modif, disabled" occurs because the node isn't inherited.</simpara>
	    </sect3>
	    <sect3><title>Attaching node and ownining node</title>
		<simpara>It makes sense to consider also relation of attaching. So the let's call "attaching node" the node that chromo is attaching of 
		    given node chromo. This attaching node also is some level owner of given node but not necessary direct owner. For direct mutation of 
		    type "node" (i.e. the mutation that doesn't have argument "node") the attaching owner is direct owner. To simplify the referring, let's
		    use to following abbreviation:
		    <itemizedlist>
			<listitem> Acomp - component attached to the given node.
			    <simpara>Acomp is also component but not necessary direct.</simpara> </listitem>
			<listitem>Aowner - near owner attaching the given node.
			    <simpara>Aowner is owner but not necessary direct owner.  </simpara></listitem>
		    </itemizedlist>
		</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_refs"><title>References: rules and limitations</title>
	    <simpara>References are important part of relation in systems native topology (hier + inher). Establishing rules and limitations for
		referencing can significantly affects the topology. Currently the only limitation is that rank of referenced node has to be less than the 
		referencing one. What rules and llimitation can be applied?</simpara>
	</sect2>
	<sect2 id="ds_mut_pmf"><title>Mechanism for polimorphism in model</title>
	    <sect3><title>Intro</title>
		<simpara>One of important mechanism on creation of model is polimorphism. This means that it is possible to use different implementation
		    of interface for some agent. For instance agent A in model has component A_1 that expose some interface, i.e connection points. In polimorphic
		    model it should be possible to change the implementation of A_1 by A_2 (implemented same interface) in the manner that owner A "doesn't note" this
		    change. Currently there is possibility of mutation A_1 keeping the interface unchanged. But there is no possibility at the moment to 
		    seamlessly replace A_1 by A_2.</simpara>
		<simpara>Actually this replacement could be implemented vis re-parenting A_1. This means that creator prepares implementation AI_1 and then
		    "light" (i.e. without mutations) child (clone) A_1 of AI_1. Then the creator can create alternative implementation AI_2. To "replace" A_1 creator
		    just needs to re-parent A_1 from AI_1 to AI_2. This also could be achieved by removing AI_1:A_1 and create AI_2:A_1 instead, this will
		    work only if "not unique naming" feature is enabled, ref <xref linkend="ds_mut_nm"/>.</simpara>
		<simpara>Two kind of polimorphism can be considered:</simpara>
		<orderedlist>
		    <listitem>"Cold-switching", when the implementation is replaced before connecting within the owner.</listitem>
		    <listitem>"Hot-plug" where replacement is performed after all connections are established.</listitem>
		</orderedlist>
		<simpara>Currently the only cold-switching polymorphism is supported with usage of the feature that the same name can be applied for 
		    different compoents, ref <xref linkend="ds_mut_nm_sn"/>. So single reference (for instance from edge) can point to different agents.</simpara>
	    </sect3>
	    <sect3><title>Cold-switching</title>
		<simpara>Cold-switching polymorphism approach is activelly using at the moment</simpara>
	    </sect3>
	    <sect3><title>Hot-plug</title>
		<simpara>Even the idea of hot-plugging is clear the design approaches are not obvious. The possible approach would be to support automatic
		    connecting/disconnecting to components. Owner doesn't modify connection to the component being removed but the connections are going to 
		    state "invalid" or "incative", then the owner monitors of creation new component and if it happens initiates refreshing of connections state.
		    Some kind of this mechanism was used on earlier version of DES engine, but not in the latest.
		</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_nm"><title>Components name uniquiness</title>
	    <sect3><title>Intro</title>
		<simpara>Current implementation of DES engine allows for agent to have components with the same name. The only limitation is to have 
		    a pair (parents_name, name) unique. But even this restriction is not applied in case if component (parents_name, name) pair is the same as this
		    in some removed component. Removed component is considered as invisible via navigation so this lack of uniquiness doesn't trouble selecting
		    component by parents and name. Howewer this approach causes problems with navigation when we enable removed components lookup during navigation.
		    This mode is required for decoupled chromo approach, ref <xref linkend="ds_daa_chrc_rm"/>.</simpara>
		<simpara>So the question is if we can request strong restriction of components name to be unique?</simpara>
		<simpara>Actually the ability of components to have the same name is activelly used to support cold-switching polymorphism, ref 
		    <xref linkend="ds_mut_pmf"/>. For instance in [syst] module Extender agent has component "Connpoint:Int" for internal connection point.
		    In many cases it is removed and re-created with the same name but another parent. This keeps interface but change implementation.</simpara>
		<simpara>It also needs to be taken into account that not-unique name approach causes performance degradation. Ref <xref linkend="ds_prfopt_un"/>
		for analysis of such affect.</simpara>
	    </sect3>
	    <sect3><title>Unique name: how to check uniqueness in case of chromo optimization.</title>
		<simpara>The use-case is: node A has component A_1, that is removed then, chromo is optimized further, i.e. A_1 is not created in mode.
		    How to ensure the name uniqueness if A_1 doesn't present in model. The potential threat is that another node with name A_1 can be created, so
		    after de-optimization the model will get broken.</simpara>
		<simpara>The solution would be to check not only components name in model but also in optimized [node] mutation.</simpara>
	    </sect3>
	    <sect3 id="ds_mut_nm_sn"><title>Same name component as potential approach of polimorphism in model</title>
		<simpara>Initially there wan an idea to use the feature of name not-uniqueness as part of mechanism of polymorphism in model, ref
		    <xref linkend="ds_mut_pmf"/>, by removing some component A_1 and creating new implementation with same name A_1 instead. But the 
		    latest DES engine implementation requires full "disconnecting" of component before deleting. Earlier engine variant supported kind of 
		    "hot-plug" replacement via automatic disconnection/reconnection, but it was not implemented completelly.
		    Now it makes sense to use re-parenting mechanism instead.</simpara>
	    </sect3>
	    <sect3 id="ds_mut_nm_pnc"><title>Problem: name uniquiness approach can cause to names clash when creating heir or moving node.</title>
		<simpara>The problem was discovered in the scope of working on the problem with resolving temporal nodes UIDs in distributed models.
		    Ref <xref linkend="ds_di_cnfr_susl_pnae"/> for details. Note that this problem becomes apparent only if temporal heir full
		    registering is applied, ref <xref linkend="ds_di_cnfr_susl"/> for details.</simpara>
	    </sect3>
	    <sect3 id="ds_mut_nm_cfl"><title>How to resolve same names conflict in unique name approach.</title>
		<simpara>It would be effective if we have solution for automatic names resolution. In that case user can assign to newly created 
		    components the name, that already exists (there could be cases when using same name is quite reasoned and correspond to real semantic of
		    the model.</simpara>
		<simpara>One approach is to automatically add unique suffix to the name. This approach is already partially applied for agent that 
		    is not named by user, edge for instance. With this approach the name gets just generated.
		    We can avoid displaying the suffix in studio.</simpara>
	    </sect3>
	    <sect3><title>Diary</title>
		<itemizedlist>
		    <listitem>20160131 Approach was implemented, ref 79b545db</listitem>
		    <listitem>20170122 Problem <xref linkend="ds_mut_nm_pnc"/> was found.</listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_rn"><title>Renaming of node</title>
	    <sect3><title>Intro</title>
		<simpara>Renaming is one of sensitive parts of model mutating. There are some reasons of this sensitivity.</simpara>
		<itemizedlist>
		    <listitem> One of them is that renaming breaks relation between chromo [node] mutation and corresponding model node, 
			ref <xref linkend="ds_daa_chrc_rn"/>.
		    </listitem>
		    <listitem>Another area of sensitivity is dependency that this mutation creates. Disabling of regular pheno modif minimised
			the amount of dependencies. Now the only refs and renaming are deps causes. </listitem>
		</itemizedlist>
		<simpara>Currently the direct renaming approach is implemented: component is re-registered with new name in its owner. Alternative
		    approach is to use additional name (pseudo-name) instead.</simpara>
	    </sect3>
	    <sect3><title>Node renaming: pseudo-names approach</title>
		<simpara>The idea of this approach is to allow models node to have more then one name. All the names are equivalent: any of names
		    can be used for locating node. The rationale of this approach is that the name is just compact designation of nodes functionality and can
		    have more that one meaning.</simpara>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_smc"><title>Securing of model consistency</title>
	<sect2><title>Intro</title>
	    <simpara>Model's consistency is the key part of multi-agent systems creation. There are many approaches and technique of achieving it.
		Initially this aspect of modelling was not be considered as key one, so the one most evident approach was applied, so called direct hierarchical
		chromosome (<xref linkend="gls_dhc"/>). This approach design is described (a bit chaotic) in <xref linkend="ds_mut"/>. Many troubles
		with keeping model consistent impel to analysis and consideration this aspect more thoroughly. In result the design of alternative approaches
		was introdused. This chapter is mostly dedicated for outlining and comprition of approaches. The genaralization of this aspect of 
		mutli-agents systems is also the aim of the chapter.</simpara>
	</sect2>
	<sect2><title>Outlne of approaches</title>
	</sect2>
	<sect2><title>Direct Hiearchical Chromosome (<xref linkend="gls_dhc"/>)</title>
	    <sect3><title>Intro</title>
		<simpara>This is direct approach of defining the system - the chomo structure just reflect the structure of the model. Initial 
		    sequence of mutations are not kept and is not considered as means of keeping systems consistensy. Instead, the model's internal
		    dependencies are analyzing and the chromo is corrected to keep the dependencies correct. Also some mutations are rejected in result as 
		    "inconsistent". In fact this approach is a standard one. The same approach is used in object oriented languages like C++ - 
		    the model's creator doesn't bother regarding the sequence of changes he is introducing - the compiler verifies the dependencies and
		    shows the errors in case of model's definition dependencies get incorrect. The creator then corrects the definition.</simpara>
	    </sect3>
	    <orderedlist>
		<listitem></listitem>
	    </orderedlist>
	</sect2>
    </sect1>

    <sect1 id="ds_mut_osm"><title>Original Sequence Mutation (<xref linkend="gls_osm"/>) approach</title>
	<sect2 id="ds_mut_osm_intro"><title>Intro</title>
	    <simpara>The current implementation of DES multiagent environment is based on the approach where the chromo structure reflects the structure
		of model, i.e is hierarchical. Each model tree node has it's own chromosome, so the root node chromosome (i.e. chromo of the system) is 
		combined from the nodes chromos. Normally the chromo is created on construction phase and then model is assembled from the chromo.
		The mutations order on assembling phase differs from the order on creation phase. It was discussed in <xref linkend="ds_mut"/> that this
		cause many problems with the model consistency. So to ensure the final model consistency the specific verification has to be done on
		construction phase. This makes the implementation cumbersome and slow.</simpara>
	    <simpara>Howewer there is alternative approach: to use the same sequence for model assembling as on creation phase. There are some variants
		of implementation of this approach.</simpara>
	</sect2>
	<sect2 id="ds_mut_osm_imp"><title>How to import external modules?</title>
	</sect2>
	<sect2><title>What mutation scheme can we considered</title>
	    <orderedlist>
		<listitem>Hierarchical chromo, mutation in hierarchy order
		    <para>This is what is implemented currently. This scheme doesn't natively secure the assembling order equivalent to constructing order.
			Model's consistency is secured by the series of mechanism. The key mechanism is detection of order breaking and then correction of
			chromo. This mechanism is very complicated and doesn't work well actually.</para>
		</listitem>
		<listitem>Using mutation order attributes, ref <xref linkend="ds_mut_osm_iop_ord"/></listitem>
		<listitem>Using linear chromo in root agent, ref <xref linkend="ds_mut_osm_linchr"/></listitem>
	    </orderedlist>
	</sect2>
	<sect2 id="ds_mut_osm_iop_ord"><title>Implementation option: using mutation order attributes</title>
	    <simpara>Currently there is attribute "ord" that keeps the original order of mutation. So to follow <xref linkend="gls_osm"/> approach
		we just need to apply the mutations according this order data. The problem here is that we need to perform mutation search on each step of
		assembling. This causes significant overhead.</simpara>
	    <simpara>Can additional linear list of mutations be used in order to have quick access to the next mutation? Not actually, because the 
		current implementation does full mutation with all the mutations of nodes chromo. It cannot stop on the given mutation and then return 
		to continue.</simpara>
	    <para id="ds_mut_osm_iop_ord_20180421">[20180421] There is specific algorithm of how to search next mutation.
		Mutating node needs to call back "Mutate item #N+1" to owner if
		the node completed mutation #N and founds that next mutation's order is not N+1 but say M. The node indicates same time that it is ready
		to mutate item M. The owner traverses all it's components to check if some is ready to mutate N+1. If the owner cannot find one than it
		in turn calls back to it's owner. So each time of breaking linear sequence we do native hier tree traverse in orider to find node ready
		for next mutation.
	    not follow order</para>
	</sect2>
	<sect2 id="ds_mut_osm_linchr"><title>Implementation option: linear chromo of root agent</title>
	    <sect3 id="ds_mut_osm_linchr_bc"><title>The base concept</title>
		<orderedlist>
		    <listitem>Only root of system is the agent that contains system chromo.</listitem>
		    <listitem>Only root of system applies mutations</listitem>
		    <listitem>All other (non-root) agents are "passive" in terms of mutations.</listitem>
		    <listitem>The chromo is linear, the ref to model nodes is stated via mutation attribute using URI</listitem>
		    <listitem>Updating the model on creation phase is done via appending mutation to the chromo</listitem>
		    <listitem>Applying mutation on assembling phase is node by applying mutations from start of chromo till the end, i.e. in the
			same order as on creation phase.</listitem>
		    <listitem>To keep inheritance mechanism, the mutation to parent is propagated to all children.</listitem>
		</orderedlist>
	    </sect3>
	    <sect3 id="ds_mut_osm_linchr_inh"><title>How to implement creating heir ?</title>
		<simpara>To follow the base concept the root should create heir of the given node. This is because the node doesn't keep
		    its mutation but the root keeps. Howewer this cause overhead because root has to search the mutations related to the node's
		    inheritance chain elements. Also the algorithm is not distributed. Is it possible to perform creation of heir by the node itself?
		    This can be done by collecting node mutation within the node itself. These mutations are just copy of root mutations. They are 
		    not included into the root chromo but are used for creating heir only. So, summarising, there are the following options:
		</simpara>
		<orderedlist>
		    <listitem>Base concept: creation heir by the root</listitem>
		    <listitem>Base concept: creation heir by the parent</listitem>
		</orderedlist>
	    </sect3>
	    <sect3 id="ds_mut_osm_linchr_cmpt"><title>Implementng OSM with full compatibility to hierarchical chromo approach.</title>
		<simpara>Discussion in <xref linkend="ds_mut_osm_linchr_inh"/> shows that OSM with keeping root components muations is very
		    similar to the current implementation (hierarchical chromo). OSM root linear chromo can be implemented compatible to the 
		    current implementation. We need to:</simpara>
		<orderedlist>
		    <listitem>Introduce new muts attribure "target", that is the reference to the node this mutations related to. So, any mutation
			in the hierarchical chrmoo node A will be equivalent root chromo mutation with [target=uri_to_A]. We will call such mutations as
			"targered".</listitem>
		    <listitem>Keep the current mechansm of creating node, where mutating node creates mutated node via inheriting parent,
			sets the mutated node chromo (i.e. hierarchical chromo) and then mutate it. So both hierarchical chromo and targeted chromo
			will be supported. This allow to use "old" hierarchical chromo to be used for assembling model by OSM env. This also guarantee
			that current inheritance mechanism works properly.</listitem>
		    <listitem>Implement mechanism of transforming any hierarchical mut into root linear chromo mut. This can be done via notifying
			root on applying new mutation to chromo of internal node: root needs to add corresponding mut with the proper target to the roots chromo.
			This allows simple transforming heirarchical chromo to OSM linear chromo - we just need to "load" hier chromo and then save it.
			<simpara>[20180421] This approach implies mutation propagation from mutated node to root, that can cause overhead,
			    ref <xref linkend="ds_mut_osm_crit_upr"/></simpara>
		    </listitem>
		</orderedlist>
	    </sect3>
	    <sect3 id="ds_mut_osm_linchr_lce"><title>Linear chromo on each model's level of hierarcy</title>
		<simpara>In fact, the linear chromo is required not only on root level, but on each level. This is because we need to have chromo with
		    right mutations order even for some "internal" node to ensure the node can be inherited correctly. </simpara>
		<simpara>There was false idea that we can get the chromo of internal node just as traditional hierarchical chromo. Yes, we could, but
		    the problem is that such chromo doesn't secure correct order of mutations.</simpara>
		<simpara>So the mutation of the comp has to be propagated to owners chromo, so that all owners keep the mutation and can be inherited
		    properly. Ref <xref linkend="ds_mut_osm_linchr_comdp_mp"/> for some materials of mutations propagation. It has to be higilighted that
		    even mutations from parent applied on creating heir have to be propagated in order to make nodes came from parent ability of 
		    inheritance. This propagation needs to be limited only by nodes came from parent and has to not affect the created child chromo.
		    Looking at the current implementatin we can see that the current mechanism of managing mutation doesn't meet this use-case.
		    This is because parent uses mutation method "runtime" option to control such "inherited" mutations. This option is active on the 
		    first step of mutation, it instructs heir to avoid storing the mutation in it's chromo. Then the "runtime" option is disabled on
		    the next step so "internal" nodes stores the muts in their chromos. The problem here is that for linear chromo approach the parent's 
		    chromo mutations relate to all internal node and still applies with run-time mode. But "runtime" means that it is
		    not mutation actually, just modification, so it doesn't need to save this modification at all. So parent's mutations are not
		    propagated at all.</simpara>
		<simpara>Again, using "runtime" option for inheritance seems to be wrong way. So we need to introduce specific mutation option for
		    that, e.g "attach": if the option is set then the mutation has to go to initially mutated node's chromo. In this case the parent
		    creating heir unsets this option when applies parent's chromo the heir. The heir in turn sets this option when propagate the 
		    mutations to target. The only question is how to implement back propagation muts upward. The mechanism of such propagation was introduced
		    in order to support OSM linear chromo approach to the initial hier chromo approach, ref <xref linkend="ds_mut_osm_linchr_cmpt"/>.
		    Unfortunatelly back propagation mechanism is not quite suitable for implementing the approach with "attach" option scheme 
		    described above.  For this approach it would be more convenient to use direct propagation from initially mutated node downward to 
		    target and upward from initially mutated node to root.
		    The problem with back propagation is that we need to make decistion of handling the propagation notification 
		    directly in propagation notification handler, but there is no context in the handler for such analysis. 
		</simpara>
		<simpara>There is another solution for the design: to use two way propagation. The idea is than initially mutated node propagates
		    the mutation down to the target via all target's owner's chain (of course if target is defined) and then upward to the root. This solution
		    avoids the loop where initially mutated node first redirect mutation to target and then get propagation notification from the target. The only
		    complication with this approach is that we need to pass to mutation method one more attribute- the sign of propagation downward. If this 
		    attr is set than the node doesn't propagate mutation upward but continue redirect the mutation to the target. Initial mutation resets this
		    attr, so initially mutated node is free to propagate mutation upward.</simpara>
		<simpara>Also the key aspect of design here is to propagate mutations even within deattached node but only till the deattached node, not upper.
		    This is required to be compatible with DHC chromo, ref <xref linkend="ds_mut_osm_linchr_cmpt"/>.</simpara>
		<simpara>Use-cases to be considered:</simpara>
		<orderedlist>
		    <listitem id="ds_mut_osm_linchr_lce_uc1">Importing node
			<para>Import manages selects the required node in remote chromo and mutate the proper Modules node. Mutation's options should
			    runtime because we don't need to attach the node's chromo. But we need to propagate bottom nodes mutations to the 
			    impotring node chromo in order to have full chromo of imported node.</para>
		    </listitem>
		    <listitem id="ds_mut_osm_linchr_lce_uc2">DHC chromo, pheno modif of inherited node
			<para>This mutation needs to be transformed in OSM linear mutation</para>
		    </listitem>
		    <listitem id="ds_mut_osm_linchr_lce_uc3">Manually mutating some deattached node, i.e inherited
			<para>We need to propagate the mutation till the root. The idea was (ref. <xref linkend="ds_mut_osm_linchr_comdp_mp"/>) to
			    use options combination [runtime=false, attach=true] for this case.</para>
		    </listitem>
		</orderedlist>
		<simpara>So the use-cases can be classified as:</simpara>
		<orderedlist>
		    <listitem>OMS mutation</listitem>
		    <listitem>DHC No-RT Mutation of attached node</listitem>
		    <listitem>DHC Mutation of deattached node from attached node</listitem>
		    <listitem id="ds_mut_osm_linchr_lce_ucdd">DHC Mutation of deattached node from deattached node
			<para>The scheme is as (- attached, -- deattached): M0--M1-M2-M3--M4. M2 is mutated with target set as M4. Mutation needs to be 
			    propagated from M4 upward to M2 (this is because M2 is mutated in DHC) and then from M2 till M1 (this is because the mut is to
			    be propagated upward to the deattached node).</para>
		    </listitem>
		</orderedlist>
		<simpara>What would be the rules of propagating to cover all the use-cases? They are:</simpara>
		<orderedlist>
		    <listitem>If it is No-RT mutation and not propagation to downward then to propagate upward till upper node in attaching chain.</listitem>
		</orderedlist>
		<simpara>This rule is not covering the case <xref linkend="ds_mut_osm_linchr_lce_uc3"/></simpara>
		<simpara>[ATTENTION]. Two way propagation design actually has a fault. It assumes that upward propagation is performed in DoMutation
		    after mutation redirection to target. But in this case the order of propagated mutation gets incorrect - nodes internal mutations goes
		    first, then the node mut itself. Potentially we could to add mut to bottom nodes chromo before mutation is done, but the important principle
		    will be broken then: first try to mutate then add the mut to the chromo in case of success.</simpara>
		<sect4 id="ds_mut_osm_linchr_lce_upmc"><title>Returning to upward propagation: using mutation context</title>
		    <simpara>As two way propagation approach becomes wrong way, it makes sense to return to propagation upward. We need just 
			modify the algorithm of propagation: to solve the problem when the base algorithm in case of targeted mutation is whthin deattached node
			and target is in this deattached node deattached comp, ref <xref linkend="ds_mut_osm_linchr_lce_ucdd"/>. The modification
			is that we pass the pointer to mutated node as attr of mutation method. Targeted node in turn passes this attr to propagation 
			method. To in the propagation method it gets possible to propagate to mutated node mandatory. </simpara>
		</sect4>
	    </sect3>
	    <sect3 id="ds_mut_osm_linchr_es"><title>Breaking chromo consistency in case of embedded subsystem</title>
		<simpara>Embedded subsystem, or subsystem with independent chromo are useful way of reusing the chromos. One of the examples of
		    such subsystems are modules. Howewer using independent subsystems contradicts to the "linear chromo of root" option. This is
		    because the independent subsystems is mutated separately, but not via the linear root chromo. So all the problems pecular to 
		    "hierarchical chromo" are here, ref <xref linkend="ds_mut_osm_intro"/>. So the only "pure" linear chromo needs to be used
		    to secure chromo consistently. This fact makes the option less usable for systems development.</simpara>
	    </sect3>
	    <sect3 id="ds_mut_osm_linchr_comdp"><title>Copying modification from the parent</title>
		<sect4><title>Intro</title>
		    <simpara>The current implementation (hier chromo) supports the feature to copy modification from the parent. The idea is to provide
			the models creator with the ability of inherit all changes from parent in case if the parent is inherited component. The matter is
			that the current implementation doens't mutate the inherited component but uses pheno modif instead. This is because with heir chromo
			it is not possible to attach chromo of inherited component, so to save the change in some inherited component we need to apply
			the mutation in the component attached owner (i.e owner which chromo is attached).</simpara>
		    <simpara>OSM linear root chromo allows stores all the mutations irrespectivelly of whether mutated comp is inherited or not. So
			potentially the feature "Copying modification from the parent" is not needed anymore. But the question is if the model with
			direct mutation of inherited comps be equivalent the model of currently implemented? NO, they are not. The problem here is that actually
			OSM approach doesn't solves the problem with incomplete chromo of inherited node. This is because even includeing chromo to mutated
			inherited node doesn't mean that the chromo of node's owner also includes this mutation. In fact it's not because inherited node's chromo
			is deattached from the owner's chromo.</simpara>
		</sect4>
		<sect4 id="ds_mut_osm_linchr_comdp_mp"><title>Solution: to propagate the mutation</title>
		    <para>One solution here is to propagate the mutation to some the mutated inherited node owners.
			The algorithm of propagation has to consider mutation attaching. Let's consider the following model ("-" designates component chromo attached,
			while "--" deattached) with component A5 mutated:
			<programlisting> A0-A1--A2-A3--A4-A5 </programlisting>
			Apparently we don't need to propagate mutation to A4 because A4 attaches A5 so A5 mutation "exists" in A4 chromo. We need to propagate the
			mutation to A3 because A3 doesn't attach A5 so A5 mutation is not "available" in A3 chromo. According to this logic: A2 - no propagation,
			A1- to propagate. As for A0, A0 is root so even it attaches A1 but it newer uses this attachment (because it doesn't collect full chromo
			from its components) but uses its own chromo instead (its chromo is complete linear chromo of the model).
			This approach seems consistent to the main OSM approach where mutation into some node is copied to 
			root chromo.</para>
		    <simpara>To implement mutations included to the inherited node chromo we need to modify the options of mutation. Currently there is
			only one option "Runtime" that means that if option is true the mutation shall not be included to the node's chromo i.e. that the
			mutation is acutally modificaton on runtime. Now we need to add one more option "Attach" that enables attaching the mutation to the 
			whole system's chromo. So the combinations of these two options are as:</simpara>
		    <table frame="all">
			<tgroup cols='3' align='left' colsep='1' rowsep='1'> <colspec colname="c1" /> <colspec colname="c2" />
			    <thead> <row> <entry>Runtime</entry> <entry>Attach</entry> <entry>Use-case</entry> </row> </thead>
			    <tbody>
				<row> <entry>False</entry> <entry>False</entry> <entry>Mutation of inherited part, included into the inherited node's chromo but not attached to 
					the system's chromo. The inherited node's chromo is neede to supportd inheritance from such a nodes.</entry> </row>
				<row> <entry>False</entry> <entry>True</entry> <entry>Regular mutation that included to node's chromo and attached to system's chromo</entry>
				</row>
				<row> <entry>True</entry> <entry>Any</entry> <entry>Modification</entry> </row>
			    </tbody>
			</tgroup>
		    </table>
		    <simpara>NOTE: The propagation rules described above were revised in consideration of generic rules of propagation. So ref  
			<xref linkend="ds_mut_osm_linchr_lce"/> for the final solution</simpara>
		</sect4>
	    </sect3>
	    <sect3><title>Parent's mutations</title>
		<simpara>Ref <xref linkend="ds_mut_osmlc_pm"/> for the material</simpara>
	    </sect3>
	    <sect3 id="ds_mut_osm_linchr_notif"><title>Issue: notification scheme gets broken with OSM approach.</title>
		<simpara>Current notification scheme is used mutation run-time sign to give information to observer about change persistence (to be
		    exact this was implemented implicitly, specific notif OnContentChanged was used in case of run-time. Last changes introduced 
		    dedicated arg "run-time" to all notifications. In Hier chromo approach "run-time" designates two cases: true run-time modification and
		    "inherited" mutation on creation hier (such mutations are not go to model chromo).</simpara>
		<simpara>But in OSM "run-time" sign meaning differs from that in heirarchical chromo. In OSM run-time means just true run-time modif.
		In case of "inherited" mutation "run-time" sign gets false in order to add all the changes to node's local chromo.</simpara>

	    </sect3>
	</sect2>
	<sect2 id="ds_mut_osmlc_pm"><title>OSM linear chromo: parent's mutation</title>
	    <sect3><title>Intro</title>
		<simpara>Mutating of parent and propagating parent's mutation to the children is one of key part of OSM approach. The following use-cases need
		    to be considered:</simpara>
		<orderedlist>
		    <listitem>Parent is mutating directly</listitem>
		    <listitem>Component of parent is mutating directly</listitem>
		</orderedlist>
		<simpara> Note that we need to propagate mutation as run-time modification. This is because the changes are included to the parent's chromo.
		</simpara>
	    </sect3>
	    <sect3><title>Parent's component mutating</title>
		<simpara>In order to propagate the mutation of parent's component we need to notify the owner's chain, so that each owner then propagates the 
		    mutation to its children.</simpara>
	    </sect3>
	    <sect3 id="ds_mut_osmlc_pm_vpf"><title>Verifying that the propagation fulfilled OK.</title>
		<simpara>There is the possibility that the propagation of parent's mutation fails. This could happen for instance when the mutation 
		    introduces ref to some parent's component that is removed from child. To avoid such failures we need to verify the propagation in the
		    scope of parent's mutation. If the propagation fails the mutation has to be considered as incorrect. In this case the creator can
		    modify childs properly and makes new attempt of mutation.</simpara>
		<simpara>The key problem here is that we need to roll-back the mutation in case of failure. Currently the engine itself doesn't support
		    rollback. The only way at the moment to roll-back is to set mutations limit to env and re-assemble the model. We need to 
		    consider solid design for such mutation roll-back.</simpara>
	    </sect3>
	    <sect3 id="ds_mut_osmlc_impl"><title>OSM linear chromo implementation.</title>
		<simpara>OSM linear chromo approach assumes that chromo can be just flat data - the sequence of mutations. For the first look this 
		    can be implemented simply: to use current (tree-type) chromo but avoid creating hierarchical nodes. But in fact even root chromo
		    remans at the moment hierarchical: there is root node, containing root node mutations.</simpara>
		<simpara>The chromo implementation supports such structure - it requires that chromo has root of type ENt_Node. To implement true linear
		    chromo these restriction should be removed. In this case the model creation scheme should also be slightly changed: env should create
		    root of type Elem by default. So the chromo will be mutations of the root node.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_osmlc_cmp"><title>OSM linear chromo: chromo compacting</title>
	</sect2>
	<sect2 id="ds_mut_osmlc_rns"><title>OSM linear chromo: References native support</title>
	    <sect3><title>Intro</title>
		<simpara>OSMLH doesn't require to collect model-chromo an chromo-model dependencies, so they will be removed from the engine when
		    migrating to OSM. But this dependencies are used also to keep consistency of references. Currently there is no references support on
		    the level of native hierarchy, so it's not possible to check if the mutation will break references without extra means (deps for instance).</simpara>
		<simpara>Do we need to support refs consistency at all in this case. On earlier implementations there was no such verification.</simpara>
		<simpara>Currently the relation support is implemented via specific agents (Vert, Edge). Introducing refs support on native level will
		    change this approach. On the other hand there is some obvious discordance in the current approach: there is [ref] attribute of mutation,
		    that assumes this "ref" in the native agent to which the mutation is applied. But as we mentioned there is no "ref" supported
		    natively. Actually currently [ref] mutation attribute is just kind of content. It is assumed that specific agents interpret this
		    content properly when implementing relations: for instance Edge keeps refs to related vertexes. That is ok but it is possble to apply
		    mutation [cont ref=...] to any agent, not specific only.</simpara>
	    </sect3>
	    <sect3><title>Use-cases outline</title>
	    </sect3>
	    <sect3><title>Native support of refs: Cons</title>
		<orderedlist>
		    <listitem>The relation "ref" on native level does make sense only in case if there is some functionality of this relation. 
			For instance parent-child relation is used to construct model via inheritance - there are specific handling of this relation. But
			what handling would be for "ref"? Seems there is no such specific handling on native level.
			<para>The argument is that agent's content is also not supported by all native agent but base agent has API for content. Same way
			    we can have APIs for ref (interfaces Referring and Referred).</para>
		    </listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>Native support of refs: Pros</title>
		<orderedlist>
		    <listitem>Currently there are no mechanism of node removing consistency verification on native layer. Native support of refs can
			provide base of such mechanism.</listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>Points</title>
		<orderedlist>
		    <listitem>It has to be avoided to ref to agent that is not "referrable".</listitem>
		</orderedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_osm_mrk"><title>Implementation option: hierarchical chromo with markers</title>
	    <sect3><title>Intro</title>
		<simpara>As was discussed in <xref linkend="ds_mut_osm_linchr_es"/> linear chromo doesn't allow using of independent subsystem. There 
		    is another option that combines the benefits of "linear chromo" and "mutations order" options. To explain the new option let's 
		    consider the use-case:</simpara>
		<orderedlist>
		    <listitem>Sysem A gets created, some initial portion m_1 of mutations added</listitem>
		    <listitem>Mutation is applied to insert independent subsystem S (for instance from external chromo)</listitem>
		    <listitem>Next portion m_2 of mutations are added to A chromo</listitem>
		    <listitem id="ds_mut_osm_mrk_i_p1">Mutation ms_1 is applied to S chromo</listitem>
		    <listitem>Next portion m_3 of mutation are added to A chromo</listitem>
		</orderedlist>
		<simpara>Note that step <xref linkend="ds_mut_osm_mrk_i_p1"/> breaks consistency of A chromo. Let's look at of how this is 
		    resolved with "markers" option. On step <xref linkend="ds_mut_osm_mrk_i_p1"/> we mark mutation ms_1 with specific marker _MS_V2_ (V2 means
		    version#2), also we add the same marker to so called "dependence mark" of the first mut of m_3 portion. On applying phase we apply  not whole
		    subsystem S mutation but till the mark only, then return to the "mainstream" chromo, apply m_2, then before applying m_3 we
		    note that m_3 depends on mark _MS_V2_, so return to S and apply _MS_V2_ and then return to m_3.</simpara>
		<simpara>We can see that this schema keeps chromo applying sequence equal to construction sequence. Same time we still able to 
		    save subsystem S whole chromo (including mutations related to version#2).</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_osm_gnu"><title>Support of "gettin node by URI" in OSM chromo</title>
	    <sect3><title>Intro</title>
		<simpara>Currently the non-OSM chromo supports getting chromo node by URI, ref 
		    <programlisting> void* MChromoMdl::Find(const void* aHandle, const string&amp; aUri) </programlisting>
		    bun in OSM chromo this feature seems doesn't make sense because OSM chromo not having dedicated node for given model node.</simpara>
		<simpara>Nevertheless the "getting node by URI" feature is important for instance when importing some submodel from module.</simpara>
	    </sect3>
	    <sect3><title>Solution: applying filter to the chromo</title>
		<simpara>It is not possible to find dedicated node for given URI but it is possible to filter out all mutations related to the node.
		    This filter can be applied to attribute "target" of the mutations in given chromo. So in result we can have chromo containing all the
		mutation for the given node.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mut_osm_crit"><title>[20180421] Criticizm</title>
	    <sect3 id="ds_mut_osm_crit_upr"><title>OSM causes mutation upward propagation to root</title>
		<simpara>Ref <xref linkend="ds_prfopt_osmlp"/></simpara>. This is actually against currently approach <xref linkend="ds_mut_osm_linchr"/>
		plus mechanism that allows propagate local mutation to root chromo (aka mechanism supporting ability for OSM to handle hier chromo as well),
		ref <xref linkend="ds_mut_osm_linchr_cmpt"/>. Also propagation to children is used.
		Probably we need to consider the option <xref linkend="ds_mut_osm_iop_ord_20180421"/>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_visrepr"><title>Visual representation</title>
	<sect2><title>Introduction</title>
	    <simpara>Visual representation here is not visualization of model like falling ball pictures for the ball model.
		The representation is of how to show the structure of model for the user, so it can be described as structure visual representation.</simpara>
	    <itemizedlist>
		<listitem>Ref <ulink url="../requirements/index.html#uc_036"/> for use-case</listitem>
	    </itemizedlist>
	</sect2>
	<sect2 id="ds_visrepr_emb"><title>Approaches: embedded into agent base</title>
	    <simpara>This approach is to extend agent base to support visial representation hint. This can be done by adding specific attribute to agent specification.</simpara>
	    <simpara>Pros:</simpara>
	    <itemizedlist>
		<listitem>Doesn't increase the complexity of the system. Any agent will keep it's representation data.</listitem>
		<listitem>Base mechanism of mutation will be used for modification, so rollback will be supported simply.</listitem>
	    </itemizedlist>
	    <simpara>Cons:</simpara>
	    <itemizedlist>
		<listitem>The value of the dedicated attribute can be quite long, so the mutations can become ineffective. </listitem>
	    </itemizedlist>
	</sect2>
	<sect2 id="ds_visrepr_dea"><title>Approaches: using dedicated agent for the representation</title>
	    <simpara>The dedicated agent is created to keep the parameters of visual representation. This approach doesn't differ much from 
		<xref linkend="ds_visrepr_emb"/>, the only change is that instead of having the support of representation in base agent (i.e. 
		in each agent), we add specific representation agent into nodes that requires custom visualization.</simpara>
	</sect2>
	<sect2 id="ds_visrepr_mdl"><title>Approaches: representation to be described by means of model itself</title>
	    <sect3><title>Intro</title>
		<simpara>When we talking of representation we mean some relations between part of system. For instance the visual order of
		    system components actually the ordered relation of these components set. So the question is why these relations are not part of the
		    model? We can also refer to visualization of the model, when we create specific model for visual part, e.g. specific widged for 
		    ball moving area. We can do thame thing for structure visual representation.</simpara>
		<simpara>There can be objections here that these specific relations are valuable for some clients that use visual representation but for some not.
		    These relations doesn't affect "functional", behavioural aspects of system at all. But the same question is actual for the other approaches
		    also: all the information kept by specific attribute of agent base in <xref linkend="ds_visrepr_emb"/> or in dedicated agent for
		    <xref linkend="ds_visrepr_dea"/> is not needed for system behavior.</simpara>
	    </sect3>
	    <sect3><title>How to mix agents for general behaviour and representation</title>
		<simpara>So the proposal here can be to have mechanism of "switching off" those part of the model that we are not interested in at the
		    moment. For instance if we just running the system and looking just at some local part of the model (e.g. visualization part) so
		    we don't need the part related to structure visual representation. This separation can be implemented by having one base element for 
		    all representation agents, plus env option to not create those, plus support of creation masking on agent base level.</simpara>
		<simpara>How to avoid dependencies beween general and representational agents? The idea is to keep all representational agents
		    together, e.g in one agent. This would allow to simplify the structure of the whole system.</simpara>
	    </sect3>
	    <sect3><title>Representational agents</title>
		<simpara>The following agents could be used for visual representation:</simpara>
		<itemizedlist>
		    <listitem>Low-level ordering relationship. It could be used to order components within a node.</listitem>
		    <listitem>Reference. This can be used for compact representation for displaying the data of node. 
			This is already used, but not reference, just uri of data node.</listitem>
		</itemizedlist>
	    </sect3>
	    <sect3><title>Ordered relationalship agent. How to implement.</title>
		<simpara>Currently there is already scheme of how to create ordered relationalship. For this the general approach is used:
		    "relation is neutral, the relation specific goes thru system role". So there is agent "Edge" for neutral relation, specific
		    agent "Vert" for object of relation, and 
		    system agent that supports roles can be used for 
		    ordering relationship: system should have roles "lower" and "bigger". This approach allows effective requesting for 
		    relation: client can as any system for "all nodes bigger than you". System just gives to client the request 
		    for iface set of "bigger".</simpara>
		<simpara>The disadvantage of this approach is that only system can be used but not lower layer agents, like vertex.</simpara>
		<simpara>One of the alternative approach is to use specific relation agent, not neutral. In this case simple vertex agent
		    can be the object of specific relation.
		</simpara>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_refl_idir"><title>Reflecting of direction of information</title>
	<sect2><title>Intro</title>
	    <simpara>Ref <ulink url="../requirements/index.html#uc_040"/> for the use-case.</simpara>
	</sect2>
	<sect2 id="sec_refl_idir_whatdiris"><title>What CP direction is?</title>
	    <simpara>For the first glance CP direcition is the only hint of how to represent system to clear show information handling stages. But actually
		not only this. The direction also create the limitations of connections. For connecting systems: output to input, input to output.
		For connecting system boundary to internal nodes: boundary input to internal input, internal output to boundary output.  </simpara>
	    <simpara>So CP direction is the paremeter of CP that needs to be used to check CP compatibility.</simpara>
	</sect2>
	<sect2><title>Approaches</title>
	    <orderedlist>
		<listitem>To introduce fake customized agents for CPs.
		    <simpara>Here we are saying: "Any CP can be used for getting info or passing it out. Even CP itself doesn't know of that and is not customizing to 
			to it specifically, we "marking" them so the system using it can indicate this CP specialization.</simpara>
		</listitem>
		<listitem>To customize systems boundary: to introduce specific parts "Input" and "Output" in capsule.
		    <simpara>The idea is that system is responsible for moving data thru, so the system can customize its structure to indicate the CPs 
			specialization.  </simpara>
		</listitem>
		<listitem>To consider <xref linkend="sec_refl_idir_whatdiris"/>:  To have all CPs base implementing MCompatChecker (by the way why not rename 
		    this iface to something like "MConn"?). To add to this iface method GetDir().</listitem>
	    </orderedlist>
	</sect2>
    </sect1>

    <sect1 id="ds_nat_agent_hier"><title>How to embed native agents into agents hierarchy</title>
	<sect2><title>Refs</title>
	    <itemizedlist>
		<listitem>Use case: <ulink url="../requirements/index.html#uc_045"/></listitem>
	    </itemizedlist>
	</sect2>
	<sect2><title>Intro</title>
	    <simpara>All the agents are to have their place in agents hierarhy, so can be pointed to via
		hierarchy coordinate (uri). Currently there are two hierarchies defined: structural, induced by relation
		"component-container" and inheritance hierarchy, induced by relation "parent-child". Both heirarchies are 
		supported by capability of base agent "Elem" to establish relations of both types. Each hierarchy has 
		initial point - root. So there are structural root, agent that doesn't have container to be related to, and
		inheritance root - element that doesn't have parent.</simpara>
	    <simpara>It is obvious that inheritance root is the base agent - Elem. As for structural hierarchy, currently any 
		derived agent can be root. The problem here is that native agents, those that are delivered by environment, are
		not embedded into structural hierarchy, but has no structural root, so logically are considered as structural
		roots theirself. So we got multiple structural root that makes troubles when referencing to the agents via 
		structural coordinates.
	    </simpara>
	    <simpara>We need to take into account specifics of native agents as parent. Normally we specify ref to parent assuming
		the parent exists and can be reached via ref in the proper hierarchy. But for native agent it is not true. It is 
		possible that the agent doesn't exist yet, in this case it will be created by the environment. Currently we even
		use specific form of uri, w/o hier relation symbol when referencing to native agent. Also there is dedicated
		mechanism of gettng the native agent unregarding from hierarchies - from environment native agents cache.</simpara>
	</sect2>
	<sect2><title>Approach: To allow mutlitpe structural roots</title>
	    <simpara>This is what currently exists. To support this we need to update Elem method of gettng structural node.
		But this is not simple. This is because algorithm of gettng node is based on single root. In other words root is
		entry point for getting node.</simpara>
	</sect2>
	<sect2><title>Approach: To have specific node for native agents in structural hierarchy.</title>
	    <simpara>There is the problem with this approach: to create root we already should have base agent available.
		But according to the approach this agent should be part of root. This causes logical contradiction.</simpara>
	</sect2>
	<sect2><title>Approach: To have base agents as both structural and inheritance hierarchies.</title>
	    <simpara>This options does't seem to have some contradictions. The only problem is that we need to have
		additional node. Morover this node needs to be deattached. Also we need to support ref to this node on
		environment level to be able of adding newly created native agents (ref Elem::AddElem) to this node.
	    </simpara>
	</sect2>
	<sect2><title>Approach: don't have native agents in structural hierarchy</title>
	    <simpara>This is mainly how it works now. We are saying that native agents are not in structural hierarchy but
		can be obtained via inherirance hierarchy uri or simple native agents uri. It should work, we just need to
		ensure clear distinction of native agents ref (uri). Currently native agents uri form doesn't distinct from
		form of default structural uri (for it also no relation symbol is used in uri, ref GUri::Parse)</simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_agt_data"><title>Agents for data</title>
	<sect2 id="ds_agt_data_repr"><title>Data string representation scheme</title>
	    <programlisting>
		data_repr = type , ":" value
		type = type_signature , "," , type_parameters
	    </programlisting>
	    <itemizedlist>
		<listitem>type_signature is primarily type identifier. It assosiates to type implementation where type_parameters are served as paremeters of 
		    type implementation.</listitem>
	    </itemizedlist>
	</sect2>
    </sect1>

    <sect1 id="ds_visdbg"><title>Visual debugging support</title>
	<sect2><title>Intro</title>
	    <simpara>
		For the debugging purpose it is required to see some "internal" data of the agent. For instance for agent-function
		it could be the value of its arguments. Currently this feature is implemented only partially: visual representation
		of function has some parameter that defines content of which agent to display. What could be the approaches
		of support the full visual debugging functionality.
	    </simpara>
	</sect2>
	<sect2><title>Approach: special iface for debugging</title>
	    <simpara>This iface can include the following methods:</simpara>
	    <itemizedlist>
		<listitem>Getting  data that agent assosiates to selected connection point (input, output, etc). Use-case here is:
		    debugging some function, there is an error within
		    some internal function, user move mouse pointer to input, tooltip gets displayed showing the value.</listitem>
	    </itemizedlist>
	    <simpara>What is difference between using debugging iface and complex content for keeping debug info
		(ref. <xref linkend="ds_cplx_cont"/>) ?.
		Using content assumes that agent constantly updates content part that aims for debug info.
		This results in overhead. Of course we can "switch" agent to "debug mode" via dedicated content,
		but it seems quite complex. ARGUING: It is not nececcary that object constantly
		refreshes debugging content. It depends on object. It can refresh the content only on demand via content getter.</simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_cplx_cont"><title>Complex content (multi-content) of agent: pros and cons</title>
	<sect2><title>Intro</title>
	    <simpara>There is proposal to add support of complex content of agent. Currently agents content is simple - just single string. 
		The complex data can be implemented as set of named data, like map[string, string] where the key is data name,
		and the value is the data.
		So the complex data can be considered as set of named fields.
		In many cases having complex content seems convenient and preferrable.
		The example is visual debugging of complex system. 
		For the debugging purpose it is required to see some "internal" data of the agent.
		For agent-function it could be the value of its 
		arguments. Currently this feature is implemented only partially: visual representation of function has some parameter that
		defines content of which agent to display. So to support debugging data there are two ways: 
		<orderedlist>
		    <listitem>To extend the current approach by adding some agents-paremeters
			(agent-function can set their content by debug data)</listitem>
		    <listitem>To add support of complex data.
			Agent function can set the debug data to the corresponding content fields.</listitem>
		</orderedlist>
	    </simpara>
	</sect2>
	<sect2 id="ds_cplx_cont_cns"><title>Considerations</title>
	    <sect3><title>Simple agent philosophy</title>
		<simpara>The simple content correspond to the multy-agent philosophy "agent is simple". Complex content makes agent more comples. Does it
		    break the philosophy?</simpara>
	    </sect3>
	    <sect3 id="ds_cplx_cont_cns_if"><title>Agent exposes its behaviour via interfaces</title>
		<simpara>So why we need content access methods in base agent interface at all? Why not have specific interfaces for access to 
		    agents content? Like it is imlpemented for property? For instance we can add the extended Prop interface, that supports named
		    property, read-only for instance or changeable. 
		    This depends on how base is this functionality, have the base agent support named properties as default? Initially the
		    idea of base agent was that it only supports native and inheritance hier.  </simpara>
		<simpara>The point here is that for changeable property also observation interface have to be defined. So the agent that
		    uses anothers agent extended Prop iface can register itself as observer. In case of embedding extd Prop iface into the base
		    agent with usage of notification to owner, this notif can create overhead.</simpara>
	    </sect3>
	    <sect3><title>Why the content update iface is required in base agent?</title>
		<simpara>It is required to support change agent via mutation. The mutation scheme is applicable to base agent only, so we
		    need some mechanism for changing agent. The subject of changing was defined as much base as possible: just some abstract content. 
		    To have complex content the agent needs to include some specific owning agents, like it is done for Edge.
		</simpara>
		<simpara>This approach differs from extended Prop iface, ref <xref linkend="ds_cplx_cont_cns_if"/> - actually there isn't 
		    mechanism to change these props via mutations. Let's have short comparition of these approaches:</simpara>
		<itemizedlist>
		    <listitem>Extended Prop iface:
			<programlisting>
			    Supports only non-persistent properties (cannot change them via mutation)
			    Supports specific observation of props, but not to owner by default
			</programlisting>
		    </listitem>
		    <listitem>Named content in base agent:
			<programlisting>
			    Supports persistent content (can be changed via mutation)
			    Supports base observation only, to owner
			</programlisting>
		    </listitem>
		</itemizedlist>
		<simpara>So it makes sense to use these approach for different aims: Complex content - to enrich the base agent, but extended prop - to
		    support specific debugging feature.</simpara>
		<simpara>Again, content is <emphasis>universal</emphasis> mechanism of changing agent via mutations and exposing agents data.
		    Exposing agents data in univirsal form is especially suitable in case when the data is for debugging purpose or if 
		    the data itself is of string form (i.e. refs to points in edge).
		    This universal mechanism is implemented in base agent. Inherited agent can also implement specific ifaces (i.e. MDVarGet implemented by DVar agent)
		    for getting content.  This allows agent to expose content in native form instead of unified (string).</simpara>
	    </sect3>
	    <sect3><title>Agents for just keeping data</title>
		<simpara>Currently the agent-property for just keeping data is used widely. This seems too wasteful.</simpara>
	    </sect3>
	    <sect3><title>Simple agent as subject of random mutation</title>
		<simpara>There was also idea to apply random mutation approach for system adaptation. For random approach it is important to have 
		    mutations without variable parameters. Complex content introduces mutation of type "Change content" with such variable 
		    parameter "Content name".</simpara>
		<simpara>Not sure the idea is fruitful. Even simple content agents have such kind of mutation. For instance "Change content" has
		    variable parameter "Content value"</simpara>
	    </sect3>
	    <sect3><title>Content as parameters</title>
		<simpara>The content can be considered as mechanism of parametrization of agent, like it is done in OOP languages. The difference is
		    that in OOP any object can have paremeters, both primitive (like Int in Scala) and derivated. By the way, primitive object in Scala
		    has single parameter, and this paremeter is literals - "super-primitive", i.e. not object. Derivated object can be paremetrizied by
		    other objects. For our mutli-agent environment these paremeter that passed via constructor in OOP don't have sense: there is no 
		    classes in agent env, but all agent is created via inheritance. So such paremetrization in agents env can be done via mutation or 
		    view phenotypic modification. Pheno modif is more corresponding to parametrization in OOP because of OOP parametrization is the way to
		    create different instance avoiding inheritance (i.e mutation).</simpara>
		<simpara>So an agent can be parametrized via "inserting" another agents-parameters to it. The given agent has to "know" of agent-parameters 
		    capabilities in order to use them. This is the same as parameters-argument of constructor in OOP. But what if we just need primitive
		    parameter, like text data.</simpara>
	    </sect3>
	</sect2>
	<sect2><title>Comparition the apporaches in case of visual debugging</title>
	    <simpara>We will use abbreviation SC and CC for simple content and complex content correspondingly.</simpara>
	    <orderedlist>
		<listitem>Simplicity for agent-function: SD - to get the agent-prop and set its content; CC - to set the field. CC wins.
		</listitem>
		<listitem>For visual representation: SD - simply add new props for config of displaying; CC - same,
		    but to interpret the props as field name. Win-win.</listitem>
	    </orderedlist>
	</sect2> 
	<sect2 id="ds_cplx_cont_strc"><title>Continuation. Structured content</title>
	    <sect3><title>Intro</title>
		<simpara>There already was the proposal to introduce multi-content design solution for simpifying the model.
		    Multicontent should ensure keeping several content elements including debug data. Howewer this 
		    solution implementation was postponed till thorough design consideration.</simpara>
		<simpara>There is proposals of improvement of structured content approach, ref 
		    <xref linkend="ds_cplx_cont_strcimpr"/></simpara>
	    </sect3>
	    <sect3><title>Requirements</title>
		<orderedlist>
		    <listitem>Getting string representation of the whole value (inluding hier of contained content)</listitem>
		    <listitem>Support of categories
			<para>The categories help the client to select the only required content.
			    The categories could be for instance: read_only, debug, hidden etc. We need to consider predefined and
			    settable categories.</para>
		    </listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>From multi-content to structured content.</title>
		<simpara>We can consider more common context model then multicontent. The need of complex content happens
		    because in reality the content of agent can be complex. Of course the universal content used currently 
		    (just string) doesn't creates any limitation itself for the content interpretation by agent.
		    But the matter here is that content is also interface of agent to the world. If the content required 
		    non-trivial interpretation than the interpretation rules/methods have also to be includen to the interface.
		    This "inclusion" potentially can be avoided if we simplify the interpretation. This simplification should
		    ensure that most common operation with content on client side can be done without scecific methods.
		</simpara>
		<simpara>Multi-content approach solves this task by straightforward way - it just separate the parts of 
		    content. This allow client avoid such interpretation task as separation. This approach exploit the
		    assumption that content consists of some parts that doesn't relate one to another. But in reality, there 
		    can be relation within the content, i.e. the content can be structured in complex manner.</simpara>
		<simpara>Why not use universal mechanism, like hipertext, to describe the structure (composition and relations)
		    of content? Currently this seems to be superfluous. We need simpler but effective solution. In fact
		    even multi-content solution is good enough. Whe just need to generalize this approach in order to
		    cover as many use-cases as possible. So the proposal is to extend mutli-content solution with 
		    support of some types of relations.</simpara>
		<simpara>There could be several approaches here:</simpara>
		<orderedlist>
		    <listitem>Typified content.</listitem>
		    <listitem>Universal content</listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>Typified content.</title>
		<simpara>The idea is to introduce content of some predefined type. Generally the type from content point
		    of view means relation. For instance we can introduce the type "tree node" that is the content part that
		    relates to another content parts (leafs). Another example is array: content part has relation of type
		    "owning" of other parts that also has relation to predefined set (for instance integer numeric set).</simpara>
	    </sect3>
	    <sect3><title>Universal content</title>
		<simpara>The idea of universal content is to introduce specific single iface for content. The conent has its 
		    own value but also is a container of contents instances. The container API is as: </simpara>
		<itemizedlist>
		    <listitem>Size - get size, 0 if no containment</listitem>
		    <listitem>At(int aInd) - get by index</listitem>
		    <listitem>At(const string&amp; aKey) - get by key</listitem>
		    <listitem>Get(const string&amp; aHKey) - get by hierarhical key</listitem>
		    <listitem>IsReadOnly()</listitem>
		    <listitem>Value()</listitem>
		</itemizedlist>
		<simpara>Container allows getting component using hierarhical key (kind of uri in agents hier tree). The 
		    step in hkey separates by "." symbol. Hkey example is: vector.end.x - x coordinate of vector end point.</simpara>
		<simpara>Container iface covers the following containment types: array (map from natural numbers set to contents),
		    map (from string key to content), tree.</simpara>
		<simpara>Is it possible to avoid having dedicated iface for content and keep content APIs on base agent level?
		    The matter is that having content iface increases the model complexity. To avoid dedicated iface we can use
		    hkey. In order to get size of content container and content by index  we can use pre-defined key,
		    for instance number sign ("#"). Example would be:
		    <programlisting>
			directions.# - size of directions array
			directions.#2 - second direction
			directions.#2.x - x coordinate of second direction
		    </programlisting>
		</simpara>
		<simpara>The full string notation of containers value also could be assosiated with some pre-defined hkey,
		    for instance "*". Or we can define that. The problem whit this approach (not using Content iface) is that
		    it is inconvenient for native clients. This is because it returns only string values. So the client will need to
		    convert size "directions.#" to int.</simpara>
		<simpara>As for support of settable categories there are some desing problems here:</simpara>
		<simpara>Settable categories are in fact content itself. To "bind" some content with category we just
		    need to establish relation category-content. This is "relation model" point of view. But this 
		    approach complicates the solution even being "right solution".</simpara>
		<simpara>Another solution would be simply add support of property "category" to content.</simpara>
		<simpara>Looking again at "relation model" approach we can see that in fact the relations are 
		    already supported in content - the hier is just relation. So we can enable relation of content to more
		    than one "owner". Then the category can be considered as "owner" in "category" hier. </simpara>
		<simpara>Summary of approaches for category:</simpara>
		<orderedlist>
		    <listitem>To use only predefined categories.
			<para>The matter is that the category mostly makes sense as interface, i.e. it should be well known
			    by the clients, i.e. published. Predefined category is such published interface.</para>
		    </listitem>
		    <listitem>To use settable property of content</listitem>
		    <listitem>To use upper-level content with key equals category and component as keys to content related
			to this category.</listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>Notation of content value</title>
		<simpara>The notation is the string representatin of the value of the content. </simpara>
		<simpara>Notation ABNF:</simpara>
		<programlisting>
		    content_value = simple_content_value / combined_content_value
		    simple_content_value = text_value / numeric_value
		    text_value = text
		    combined_content_value = "{" 1*(component_value) "}"
		    component_value = simple_conmponent_value / combined_component_value
		    simple_component_value = "{" component_key ":" "'" simple_content_value "'" "}"
		    combined_component_value = "{" component_key ":" combined_content_value "}"
		</programlisting>
		<simpara>Another variant:</simpara>
		<programlisting>
		    content_value = simple_content_value / combined_content_value
		    simple_content_value = text_value / numeric_value
		    text_value = text
		    combined_content_value = "{" component_value 0*("," component_value) "}"
		    component_value = simple_conmponent_value / combined_component_value
		    simple_component_value = component_key ":" "'" simple_content_value "'" 
		    combined_component_value = component_key ":" "{" combined_content_value "}"
		</programlisting>
		<simpara>Examples:</simpara>
		<itemizedlist>
		    <listitem>Mutlicontent edge:
			<programlisting> { { P1 : "./../v_1"} { P2 : "./../v_2"} } </programlisting>
		    </listitem>
		    <listitem>Array of texts
			<programlisting> { { #0 : "bla-bla 1"} { #1 : "bla-bla 2"} } </programlisting>
		    </listitem>
		</itemizedlist>
	    </sect3>
	    <sect3><title>Extending URI via adding content name</title>
		<simpara>With single content there is no problem to point to content - the content unambiguously pointed by agent's URI.
		    But for complex content we need to specify not only agent owning the content but also content name. We can just
		    add content name to agent's URI to have URI for content.</simpara>
	    </sect3>
	    <sect3><title>Structured content implementation: use-cases</title>
		<orderedlist>
		    <listitem>Agent needs to manipulate the context content
			<para>For instance AData agent: it uses content in its context. This means context content should be rw.</para>
		    </listitem>
		    <listitem>Using content as interface instead of MProp
			<para>In single content model special agent Prop is used for keeping data. So the client (i.e. Studio App) can
			    use this Prop URI to get access to data (maybe it is not effective way - better would be to use specific iface of 
			    managing agent (i.e. MDVarGet)). In multicontent model the container (incaps) is playing this role.</para>
			<para>The problem here is that this approach doesn't allow to notify managing agent of container content change - this
			    simply because of notification is propagated to owner only.  </para>
		    </listitem>
		    <listitem>Customization of data displaying in Studio SystCrp
			<para>Ref syscrp.cpp SysCrp::AddDataRp(). There the content is used for customization of data displaying.</para>
		    </listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>Structured content dedicated URI</title>
		<simpara>Currently just monolitic name is used to identify content. But in fact the content is the complex
		    tree structure, so it would be good to support navigation thru it. For that we need resource identificator (URI) more
		    complex than simple name. It should be similar to URI used for nodes in native hierarchy.</simpara>
		<simpara>One use-case is when system wants to identify given conn point in the connpoints. Currently the connpoint
		    can be identified by the full name "ConnPoints.[name]" but we woudl line to use just relative name [name].
		    URI would allow us to use operation of getting content by base and relative URI (for instance using URIs concatenation).
		</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_cplx_cont_strcimpr">How to improve the current messy multi-content APIs
	    <sect3><title>Intro</title>
		<simpara>Currently the initial implementation of structured content is in progress, ref
		    <xref linkend="ds_cplx_cont_strc"/> for initial desing. But seems the approach and 
		APIs are not considered thorougly. We need to improve them.</simpara>
	    </sect3>
	    <sect3><title>Proposals of improvement</title>
		<orderedlist>
		    <listitem> To use short Id for content - currently GetCont returns full path instead of Id </listitem>
		    <listitem>To enable content both to keep value and components</listitem>
		    <listitem>To add API to check if content contains value (API to check if it contains comps already exists,
			ref GetContCount, maybe make sense to rename to GetContCompsCount() </listitem>
		    <listitem>To add API to get only content value, only content component,
			whole content data - by content path.</listitem>
		    <listitem>To introduce content properties</listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>Proposed update of syntax of context representation (ABNF)</title>
		<programlisting>
		    content_repr = simple_content / full_content
		    simple_content = content_value 
		    full_content = “{“ [quoted_value / component /(quoted_value " " component)] *(“ ” component) “}”
		    component = component_name  “:”  component_value
		    component_value = quoted_value / content_repr
		    quoted_value = DQUOTE content_value DQUOTE
		</programlisting>

		Example of root content that has value and components:
		<programlisting>
		    { “Just some value”,  About: “This is agent …”, ViewData: { Res: “./../Agents/fun_agent”, Res1:”...”}}
		</programlisting>
	    </sect3>
	    <sect3><title>What should be the content properties</title>
		Read-only - no changes to content components (deletion or addition) are allowed
		Value read-only - no changes to value are allowed.
		Owning content should use components properties (including props of content value),
		so missing read-only prop means just that components cannot be deleted or added.
		For content value missing read-only prop means that the value can be changed.
	    </sect3>
	    <sect3><title>Two types of contents (value or owner) vs single type (value plus owner)</title>
		Existing approach states that there are two kinds of content: value and comps owner.
		New approach states that content is only one type, that can keep both value and comps.
		Consequence: Existing approach doesn’t allow root content to have value - that’s because generic
		agent root content already has comps, so it cannot keep value same time.
	    </sect3>
	    <sect3><title>Empty content value vs not existing content value</title>
		<simpara>There can be two states of value of given existing content:</simpara>
		<itemizedlist>
		    <listitem>Value doesn't exists, i.e. was not set </listitem>
		    <listitem>Value is empty</listitem>
		</itemizedlist>
		<simpara>Are these cases equivalent? Seems not, because empty value is still value but not existing
		    value means that content just doesn't have value (it can have comps instead).</simpara>
		<simpara>
		    So to keep these cases separatelly we need to introduce one more base agent method: DoesContValExist
		</simpara>
	    </sect3>
	    <sect3><title>What should be API for content change?</title>
		<simpara>Simple content approach provides simple API for content change - just ChangeCont() that 
		    changes conent value. In case of structured API we need not only means of changing content
		    value but also content comps and content props.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_cplx_cont_cdac"><title>How to customize displaying of content of agents-containers.</title>
	    <sect3><title>Intro</title>
		<simpara>Current approach of creating new agents is to "embed" agent into some agent that serves as container.
		    The example is system. To enhance system we can add new agent into systems Agent node, the agent-container
		    will redirect notification from its compoanent to agents contained by "Agent" node. 
		    For many clients (e.g. Studio) it is normal to deal with agent-containers and not looking to its 
		    embedded agents.</simpara>
		<simpara> Very often use-case is to display agent related info in agent compact representation.
		    But agent-container itself doesn't contains any important info, the only embedded agents do. So we need
		    to have some mechanism that allows client to obrtain this information.</simpara>
		<simpara>Currently used mechanism is to add special info that gives some hints of where to get this agent
		    related important info from. Current convention is that this should be kept in node "ViewData", or
		    for multi-content agent in content "ViewData". For instance, to get result of function TFAddVarMc
		    displayed properly we need to add the content:</simpara>
		<programlisting> &lt;cont id="ViewData.Res" ref="./Agents/func_agt"/&gt; </programlisting>
		<simpara>We will call this initial approach as "Customizing content" approach.</simpara>
		<simpara>This approach works, but it has overhead because we need to add specific content. There are other solutions:
		    <orderedlist>
			<listitem> Embedded agents adding important data directly to agent-container content.
			    Ref <xref linkend="ds_cplx_cont_cdac_ac"/> for details.  </listitem>
			<listitem>Agent-container redirecting content request to embedded agents.
			    <para>This approach requires that agent-container GetContent method be customized. It seems
			    not to be acceptable at the moment. So this approach is not considered.</para>
			</listitem>
		    </orderedlist>
		</simpara>
	    </sect3>
	    <sect3 id="ds_cplx_cont_cdac_ac"><title>Approach: Embedded agents adding content of agent-container.</title>
		<simpara>We need to emphasize the difference between "Customizing content" approach and "Adding content to approach:
		    "Customizing content" approach is approach of "on demand" where as "Adding content.." approach assumes that
		    agent-containers content is change every time the "master" content is changed. It's clear that this
		    causes to content duplication.</simpara>
		<simpara>The matter is that in many cases embedded agent doesn't update even it's ownt content but returns
		    it on gettng on-demand conent request only.</simpara>
	    </sect3>
	</sect2>
	<sect2><title>Multiple vs simple content: multicontent is not an interface.</title>
	    <simpara>Comparing again multi- and simple conent approaches we can ask the question: why don't just enhance the 
		simple content approach, where content is interpreted accordind with the agent's specific interface. For
		instance Edge agent can introduce and implement specific interface MEdge which specifies the format of content.
		It could be like: "P1:uri_of_point1 P2:uri_of_point2". Any client in that case knows of how content should
		be formed.</simpara>
	    <simpara>In fact the multi-content approach is a part of this approach. Multi-content is not an interface but the
		mechanism of convenient structuring of content. As we can see from example above, any kind of such "enhanced"
		content has some structure (two parts P1 and P2 in the exampe). So multicontent is just method of unifying the
		structure and operations of the content. The exact form of content should be defined by specific agent interface.
	    </simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_transf"><title>Chromo transformations</title>
	<sect2 id="ds_transf_intro"><title>Introduction</title>
	    <simpara>Ref <ulink url="../requirements/index.html#uc_051"/> for use-case.</simpara>
	    <simpara>Chromo transformations are not mutations as change of model, but change of chromo itself.</simpara>
	    <simpara>Below is outline of importants points to be considered when implementing transformations:</simpara>
	    <orderedlist>
		<listitem>How to rollback transf?
		    <simpara>Some transf are just series of new mutations. In this case they can be rolled back. But the problem is that for the 
			developer they are "anonimous" and are not directly assotiated to some developers actions.</simpara>
		</listitem>
		<listitem>Transf as rich mutation
		    <simpara></simpara>
		</listitem>
	    </orderedlist>
	</sect2>
	<sect2 id="ds_transf_prntmodif"><title>Transformation to heir with applying parents pheno modifications to chromo</title>
	    <sect3><title>Introduction</title>
		<simpara>Ref <ulink url="../requirements/index.html#uc_052"/> for use-case.</simpara>
		<simpara>The practic of systems development uncover the serious problem. Let's describe the use-case. There is system A containing component
		    A_1. The system B is derivation of system A. System B also significantly modifies A_1. After that we are going to create child of A_1 assuming
		    that all modification made to A_1 will go to the child also. But this is obviously not the case because the modification are not inherited.</simpara>
		<simpara>This case shows that the following operation would be useful: to create the child with all the modification inherited.</simpara>
	    </sect3>
	    <sect3 id="ds_transf_prntmodif_repl"><title>Approach: replacing inherited component by it's child.</title>
		<simpara>One of approaches would be to replace the inherited component A_1 within B to child of A_1 - B_1. In this case all the 
		    modifications that are needed to be done in the component will be done via mutations but not modifications. This will allow the 
		    further inheritance of B_1.</simpara> 
		<simpara>But what if we already have B with component A_1 modified? How can we achieve the expected outcome? In that case we need to replace A1 with
		    (A_1:)B_1 and transforming all the modif to mutations.</simpara>
	    </sect3>
	    <sect3><title>Approach: leave inherited component but support child chromo transformation to get all parents modifto chromo.</title>
		<simpara>This approach seems more realistic.</simpara>
	    </sect3>
	    <sect3><title>Questions</title>
		<orderedlist>
		    <listitem>Could we just use "copy" of parents modifs to child? This would be naturally understanded by developer.</listitem>
		    <listitem>Why not use mutation of creating child with the option "copy modifs from parent"?
			<simpara>This would be just mutation, so no problems with its rollback. We need to take into account the 
			    inheritance mechanism where the chain of inheriting is performed beginning from root parent. To keep this mechanism we
			    would need also to modify relation to parent by adding relation type ("regular inheritance", "inheritance with modifs adopted"</simpara>
		    </listitem>
		    <listitem>Why don't disable pheno modifs completely?
			<simpara>I.e. if the owner wants to change inherited comp it will need to make the comp non-inherited. This would keep the
			    whole model clear and simple. This approach is discussed in <xref linkend="ds_transf_prntmodif_repl"/>.
			    The quesion remaining - what to do if we already have such inherited comps with modifs. Anycase we need to do transformation,
			    but it will be not regular transformation but repairing. The similar repairing is already implemented for repair chromo when 
			    prohibited pheno modif is disabled. Not sure this approach is correct. </simpara>
		    </listitem>
		    <listitem>How to rollback the tansformation?
			<simpara>The rollback is quite simple because the transformation is implemented via series of mutations. So
			    the initial chromo order can be stored before the transformation and then can be used for rollback.  </simpara>
		    </listitem>
		</orderedlist>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_ifnegot"><title>Agents interaction: interfaces negotiation</title>
	<sect2><title>Introduction</title>
	    <simpara>It isn't rare case that just connection establishing is not enough for agents interaction. This happens when the agent suppots 
		more that one interface to interact and it isn't suitable to specify the particular iface on connection phase. Example is function agent supporting
		variable type data. The agent is capable to handle more that one type of data. Why is such agent needed? This allows to avoid creating
		multiple similar agents, for instance agent for addition function of integer data, agent for addition function of float data etc. All these
		agents would have similar connections points set, so it seems more resonable to have agent that can supports all the types of data. </simpara>
	    <simpara>The same for data. It is excessive to have mutliple agents for keeping data of particular type. Simple is to have agent that 
		can keep data of different types. To support such approach the agent has to provide and request "flexible" interface, that specifies 
		generic methods like put data, get data, etc, but has also methods to preсise the variable parameters like data type etc.
		Such ifaces (MDVarGet, MDVarSet...) were introduced for data mutlitype agents.</simpara>
	    <simpara>Using such variable iface introduces the question of how the agents have to hegotiate to establish variable part of iface.</simpara>
	</sect2>
	<sect2><title>Negotiation of multitype function agents</title>
	    <simpara>The normal negotiation flow stars from the whole function system result point (often result data agent) and spreads to the first layer
		agents (gettng the whole function arguments), i.e. the negotiation is "from root to leafs". The negotiation procedure is as: the "upper" (nearest
		to result) agent requested the "lower" agent for required iface, the lower agent tries to handle the request, configures itself propery
		and provide the requested iface.</simpara>
	    <simpara>Breake of normal flow: the lower agent cannot provide the requested iface. This can happen when the arguments types of lower agent leads
		to result of the type that is incompatible to requested by upper agent. In this case upper agent tries other suitable variant of ifaces, if
		all they are not accepted the negitiation fails. There can be also different strategy. The simplest is that upper agent proposes other 
		ifaces keeping the contract with its upper neighbour unchanged. Another variant is that it can try also those variants that cause to the
		already established contract to upper neighbour broken. This will cause re-negotiation from lower to upper layer. </simpara>
	    <simpara>The latest approach, re-negotiation is the worther one. This is because it complicates the negotiation process.</simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_elem_iact"><title>Native hier: scheme of agents elementary interaction</title>
	<sect2><title>Intro</title>
	    <simpara>Agents in narive hier are related one to another according to two elemetary relation types: comp-owner for structural hier and
		parent-child for inheritance hier. This relations assume some interactions between related agents. We will call this interactions elementary
		interactions for they are induced by elementary relations. Elementary interactions are defined via interface of base object. For 
		structural hier the interface is component observer for component intercting to owner.</simpara>
	    <simpara>Actually we can consider not only single elementary relation but also relation that are induced by chan of relateions. For instance any 
		owner relates to its component, not only to direct components but also to the indirect, i.e. component of deeper layers.
		So there could be different schemes of organizing of interactions between agents related via chain of elementary relations.</simpara>
	</sect2>
	<sect2 id="ds_elem_iact_unl"><title>Unlimited propagation</title>
	    <simpara>Currently (260ee587a) the approach is used to propagate notifications from comp to owner without any limit, to the notifications 
		achieve system root finally. This approach is simple but it causes to system getting not scalable. To have system scalable the principle of 
		isolating any relations needs to be used. Actually the tree structure itself is good example of such isolating of relations: the 
		number of relations is reduced from bottom (comp) to uppper layers.</simpara>
	    <simpara>Ref <xref linkend="ds_prfopt_prp01_dpe"/> for activity in the scope of performance optimization.</simpara>
	    <simpara>How can the propagation be restricted? In fact there is no need to propagate event till the root. The only purpose of that is 
		the need of notify the whole system observer of the system change. For instance studio acts as such observer. But notification of
		system observer can be implemented with another approach - we can introduce observer iface in Env, so any node in native hier will
		directly notify observer. Env in turn can propagate the notifications to observer. Or more simpler, the observer can request env for notification, so
		env can expose observer to the system.</simpara>
	</sect2>
	<sect2 id="ds_elem_iact_rdins"><title>Redesign proposal: improving notifications scheme</title>
	    <sect3><title>Intro</title>
		<simpara>There was the issue <xref linken="ds_i_dpe_wb"/> discovered after offhand redesign. We need to prepare the redesign of notifications
		    carefully.</simpara>
		<simpara>The main aim of redesign is to avoid unnecesary propagation of notification. Also there is the design gap that notifications
		    currently doesn't allow to disable unaccepted mutation, ref <xref linkend="ds_prfopt_pepe"/>.</simpara>
	    </sect3>
	    <sect3><title>Using notification chan with handling confirmation</title>
		<sect4><title>Intro</title>
		    <simpara>The idea is to propagate notification to owner only if the agent cannot handle the event by its own. MACompsObserver API needa to
			be modified for that: HandleCompChanged needs to return not only Accepted/Denied sign but the sign of event handling also.</simpara>
		    <simpara>The problem here is that there can be many MACompsObserver among embedded agents. What should be the rule of decision in that
			case? The solution can be to allow all observers to handle the event: deny if even one observer has denied, consider not-handled if
			all observers hasn't handled. </simpara>
		</sect4>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_mod"><title>Support of modules</title>
	<sect2><title>Refs</title>
	    <orderedlist>
		<listitem>Use-case: <ulink url="../requirements/index.html#uc_53"/></listitem>
	    </orderedlist>
	</sect2>
	<sect2><title>Introduction</title>
	    <simpara>The current implementation of module system is rather limited: it is allowed to use ref to parent within external chromo. Also 
		it is possible to "move" node from external chromo to the model, this creates not the child of the node but the node itself,
		the node in model gets unattached. In the scope of current implementation it is not allowed to ref to external 
		parent if this parent in turn refers to something.</simpara>
	    <simpara>So current approach is as: to move some modules to the model, and then refer to these modules only in scope of the model. The 
		problem here is that there is overhead in case of big modules - not all nodes from module are used in the model.</simpara>
	</sect2>
	<sect2><title>Additional requirements.</title>
	    <sect3><title>What should be the reference?</title>
		<simpara>Currently the ref is based on url that includes uri according to RFC 3986,
		    <xref linkend="ref_rfc_3986"/>: access protocole, authority, path, and
		    native path as uri fragment.  The native path is path in the model within native
		    coordinates. It is not convenient to use such referring approach because of necessity to specify authority and path.
		    This makes model depending on
		    environment.</simpara>
	    </sect3>
	</sect2>
	<sect2><title>Using of native uri only.</title>
	    <simpara>Using of of native uri for referring external nodes assumes that native uri allows us to unambiguously specify the node.
		But currently onwing hier has local model as the root, so cannot be used to specify external node.
		Inher hier is ambiguous, so needs hint form owning heir to resolve the node.
		Nevetheless it can be used for referring - in case if system discovers some ambiguous in
		inher-hier it can extend ref to keep ref correct.</simpara>
	    <simpara>How it works? Assume that there are two modules and referred nodes within them:</simpara>
	    <itemizedlist>
		<listitem>Module 1: name "(Elem:)Mod_A", node "Node_R" within it </listitem>
		<listitem>Module 2: name "(Elem:)Mod_B", node "Node_R" within it </listitem>
	    </itemizedlist>
	    <simpara>In this case we can have the following unambiguous ref to Node_R in Mod_A: (Elem:)Mod_A/Node_R</simpara>
	    <simpara>What if module names are ambiguous?</simpara>
	    <itemizedlist>
		<listitem>Module 1: name "(Elem:)Mod_A", node "Node_R" within it </listitem>
		<listitem>Module 2: name "(Elem:)Mod_A", node "Node_R" within it </listitem>
	    </itemizedlist>
	    <simpara>This is possible only in case if Module 2 is delivered by some authority independent from that delivers Module 1.
		So how to extend ref uri?
		One way is to extend with base rfc url authority/path, having specific authority/path for Module 2 authority.</simpara>
	    <simpara>In fact the authority/path is nothing but one more coordinate in the system space. 
		We can achieve the similar result with explicitly
		adding new specific coordinate, for instance "authority", to strengthen ref safety. To have one more coordinate 
		we need to introduce new type of 
		relations, that generates the coordinate. Of course specific node is required by authority. 
		Looking at this we can propose simpler approach: system can just extend owning-hier by authority node in case if system
		discover ref unambiguousness.</simpara>
	    <itemizedlist>
		<listitem>Module 1: name "(Elem:)Mod_A", node "Node_R" within it </listitem>
		<listitem>Module 2: name "(Elem:)Mod_A", node "Node_R" within it </listitem>
		<listitem>System create module with unambiguous "Module_2_Authority" node and "includes" Module 2 
		    Mod_A into it. So now we refer to Module 2
		    Node_R as: Elem:(Module_2_Authority/Mod_A/)Node_R </listitem>
	    </itemizedlist>
	    <simpara>Looks good, so now we have heir-hier as one "absolute" coordinate, but resolving unambiguousness 
		with onwining-hier. System searches modules
		on local file or specified url according to some rules. But we still haven't avoided explicit stating rfc url, 
		because actually system includes
		Module 2 Mod_A into Module_2_Authority by authority/path. Howewer for our model, we can use only native url.</simpara>
	</sect2>
	<sect2><title>How to include nodes from modules in the model</title>
	    <sect3><title>Intro</title>
		<simpara>First of all system has to provide the hierarchy of the nodes in modules in order to 
		    allow user to select the node required.</simpara>
		<simpara>Then system has to differentiate refs to the models nodes (real nodes) from refs to 
		    modules nodes (actually not real nodes but nodes chromo).</simpara>
	    </sect3>
	    <sect3><title>Considerations</title>
		<orderedlist>
		    <listitem> The main idea for the modules is to support full referencing for modules, i.e. 
			that standard references from models chromo to any “nodes” in modules are to be allowed, as if it is run-time node. 
			The rationale of such ajn approach is that it should be simple for implementation because of modules compacted 
			chromo native space (inducted by coordinates of native hierarchies) is the same as for runtime generated 
			from modules chromo.  </listitem>
		    <listitem> To implement this approach we need to re-implement chromo in order to support inheritance hier also.  
			There is a problem here: actually the chromo itself is not isomorphic to run-time, for instance mutation of adding 
			not to destination has different owner as generated model.  Solution here would be implementing of “enhanced” chromo, 
			where mutations “branching” nodes (i.e. [node]) keeps also run-time relations owner-component.  </listitem>
		    <listitem> Or we could create “intermediate” run-time model, where only structure is evolved but not all mutations applied. 
			But any case is will not the same as currently implemented. Current implementation allows user to reference to any node 
			within module, even the inherited node. Nor chromo neither intermediate model don’t allow to do that. 
			Is this real limitation? Perhaps not. We can apply the restrictions for referencing nodes from modules: 
			to use only direct and attached nodes (direct means that adding node destination is mutation owner. 
			In this case we just need simple extended chromo with support of inher hier.  </listitem>
		    <listitem> There is fundamental problem in referring to modules. In fact the current referring scheme is dedicated for run-time, 
			so any reference is reference to an agent. So even now, referring to the whole module is ambiguous because it’s 
			the reference to chromo. The differentiation between ref to agent and ref to chromo is performed implicitly, look at 
			Elem::AddElem(): uri scheme is used to decide what ref is. Some kind of logic presents here: if we ref inside the model 
			then scheme (or base part of uri) isn’t needed (internal ref), if we referring to external 
			something then it is cpec (chromo) </listitem>
		    <listitem> Note that referring to chromo is required only for referring to parent or to moving source. So maybe it makes sense 
			to keep the current implementation with small improvement: A). introduce specific scheme or base part for modules nodes, 
			for instance fap://modules#....  B). environment to provide the modules tree </listitem>
		    <listitem> Problem: creating from external parent is ambiguous.
			This is because creating two agent from one parent in the same owner 
			will cause an error: second creation parent will filed because of already having such agent in the owner.  
			Solution here would be to disable external parent, so only moving will be allowed for externals.  </listitem>
		    <listitem> In some module it is possible that internal node has ref to another node in this module, 
			for instance Molule/B can have ref to local 
			parent Module/A. In this case moving “B” will cause an error. Solution: consider such nodes as
			dependent and disable moving them.  </listitem>
		    <listitem> One more problem : currently the cyclic resolution of module refs are not supported.
			This means that if model uses module_1 and within module_2 there are refs to 
			module_2 so just moving module_1 to the model will 
			cause the error of refs not resolved. Solution here could be to move dependency to the module.
			The disadvantage here is that the deps can be duplicated in many modules. Another solution would be “importing” deps. 
			Importing means that we have specific node for modules in owning hier and move specified dep to this node in case 
			if it’s not there yet. Such dedicated node is “/Modules” in the current implementation. OR system can do it automatically, 
			enumerating all deps, checking if dep is already “imported” and import if not. This is actually caching the modules: 
			system uses the proper run-time url in the “cache” (/Modules) and moves the external in case the cache is missing for it. 
			Even more: we can create dedicated agent for modules. This agent behavior is to cache externals, i.e to create the proper 
			nodes with externals chromo. Module agent can also provide the tree of module, whereas getting chromo itself needs to 
			be implemented on env level because is platform dependent.  </listitem>
		    <listitem> What if base agent includes specific modules agent for keeping agent related modules?  </listitem>
		</orderedlist>
	    </sect3>
	</sect2>
	<sect2><title>Approach: Explicit importing.</title>
	    <sect3><title>Introduction</title>
		<simpara>The idea is to implicit import modules required for given model. So each module (so also
		    each module because any module is model too) should has dedicated node (e.g. /Modules) for 
		    import. The obvious problem here is that imported agents can be duplicated, especially
		    generic modules. Also to import comp of some module /Modules has to be imported too that 
		    created some overhead.</simpara>
		<simpara>This approach was already used in earlier versions of sysem. Problem of duplication was
		    the reason of refusing to use it.</simpara>
	    </sect3>
	    <sect3><title>How to avoid duplication?</title>
		<simpara>One approach is module to use inher uri referencing models modules container:
		    <programlisting> move node="AModCont:Modules" id="some_module"; </programlisting>
		</simpara>
		<simpara>Module conatiner agent should handle correctly moving module if this module is 
		    already moved in. So modules container acts here as the node with global kind of access.
		    This allows to have "sub-modules" within big module. For that each "sub-module" should include
		    all its imports (even those in scope of big module) to "global" modules container. 
		    Also any module should ref to it's deps in safe manner: using predefined node as "root" for 
		    modules (like /Root/Modules) or inher based uri.</simpara>
		<simpara>In fact this approach almost implemented now. Modules are using safe refs. The
		    only part missing is importing deps.</simpara>
	    </sect3>
	    <sect3><title>Pros and cons</title>
		<sect4><title>Cons</title>
		    <orderedlist>
			<listitem>For modules internal sub-modules it is necessary to add owner that includes
			    import mutation. This causes overheads.</listitem>
			<listitem>Explicit import mutation is not true mutation because it doesn't change the 
			    node itself but dedicated import agent instead. So it doesn't follow the approach
			    "mutation is unambiguously interpret within run-time model"</listitem>
		    </orderedlist>
		</sect4>
	    </sect3>
	</sect2>
	<sect2 id="ds_dyn_res"><title>Approach: Dynamic resolution of the deps via Dedicated Module agent.</title>
	    <sect3><title>Introduction</title>
		<simpara>The idea is to resolve the deps automatically, without explicit importing. </simpara>
	    </sect3>
	    <sect3><title>Import module APIs</title>
		<itemizedlist>
		    <listitem>Get tree of chromo nodes</listitem>
		    <listitem>Import node by given uri, ref <xref linkend="ds_mod_prb_int"/></listitem>
		</itemizedlist>
	    </sect3>
	    <sect3 id="ds_mod_prb"><title>Problems</title>
		<sect4 id="ds_mod_prb_int"><title>How to create node in module if the node is requested from 
			modiles internal node.</title>
		    <simpara>This relates to use-case <xref linkend="ds_mod_uc_crn"/>. This approach assumes that upper
			owner - module agent is involved in handling request. But it's not true in case of request from 
			modules internal comp.</simpara>
		    <simpara>This problem is because this use-case contradicts to concept: "only module provide creating 
			on demand". This request from internal comp actually is not to module but to some regular 
			owner within module. This means that only deps to modules can be resolved automatically, 
			so it's not possible to create some part of module that has internal dep.</simpara>
		    <simpara>If we define imported module, or just "import" as the agent which chromo is sourced with 
			given external module (chromo) then we can say that any component of import is also import. 
			Agent can check if it's import via examining of owners, if some its owner is import. 
			We can define specific iface for import module agent.</simpara>
		    <simpara>Then the mechanism of importin required node can be implemented as:</simpara>
		    <itemizedlist>
			<listitem>Base agent requests some dep (using base agent api GetNode) - GetNode tries 
			    to get requested dep</listitem>
			<listitem>If GetNode cannot find dep requested, then GetNode checks if the dep is contained in 
			    module via getting nearest owner and requesting its owner - module.</listitem>
			<listitem>If there is module for the dep, then GetNode requests the module for importing dep</listitem>
			<listitem>Module imports dep and return it to GetNode, that in turn returns it to requestor</listitem>
		    </itemizedlist>
		</sect4>
		<sect4 id="ds_mod_prb_alldeps"><title>What is import module agent? Holder of one chromo or all external chromos?</title>
		    <simpara>One approach is to create import module agent for each external chromo. 
			This is fearly resonable - the agent can be assigned to particular external chromo and manage it.
			But how to import some models dep in case when the module itself is not created?</simpara>
		    <simpara>Alternative way is to create one agent for all imports on model init phase 
			(e.g "/Modules").</simpara>
		    <simpara>The third way is to have two agent: one for imported module, and second for modules containing. In
			this case modules container will be responsible to create the module for dep requested.
			Container itself can support modules iface but redirect all requests via the 
			iface to its components - modules.</simpara>
		</sect4>
		<sect4><title>What is difference between module and model?</title>
		    <simpara>As discussed the model can include imports, to have specific node for modules container.
			But what about modules? Do they implement imports in the same manner? </simpara>
		    <simpara>One approach is to not use the same way for modules. This is because the module is not
			independent model but some framework that is to be embedded into the model. So module has to 
			resolve its own deps to another modules in the scope of modules of model embedding the module.</simpara>
		    <simpara>Even this approach seems resonable the question is still remaining: 
			"Why they are different?". Potentially it is completelly allowed to create modules container 
			within module and import module to it. The only result will be that there will be another instance of
			import within models import.</simpara>
		</sect4>
		<sect4><title>How to handle missing requested dep?</title>
		    <simpara>The mechanism described in <xref linkend="ds_mod_prb_int"/> for handling of 
			missing requested node event is not generic enough because base agent knows of moudule iface.
			It make sense to implement generic way for handling such case. For instance new method in
			comp observer iface can be introduced, like OnCompNotResolved. This method implementation is
			to help resolving component and returns the comp resolved. Agent can run this handler
			in case if it cannot resolve comp for instance in GetNode().</simpara>
		    <simpara>This is abmiguous actually because not only owning hier can be used in getting node but
			inher hier also. There is response argument that only owning hier can be responsible for 
			handling such exceptions. How about case when model requests comp from module via pure
			inher based uri? In this case the notifications should up to root that has to redirect it 
			to modules.</simpara>
		</sect4>
		<sect4 id="ds_mod_prb_uri_chromo"><title>In some cases models uri cannot be resolved on models chromo</title>
		    <simpara>One of the cases is node mut with destination specified. This causes difference between chomo hier and
			model hier.</simpara>
		    <simpara>Solution here can be to scan the modules against this cases and transform invalid uris to 
			theirs absolute representation.</simpara>
		    <simpara>No, even for absolute model uri there no robust algorithm of finding assosiate chomo uri. Consider
			for example case of node insertion into some inherited node. The chromo itself doesn't contain the node
			corresponding to this inherited node, so it is not possible to find the node when traversing thru chromo.</simpara>
		    <simpara>This problem hardens using explicit import (i.e. dynamic resolution of deps). Solution here would be 
			to improve algorithm of getting chromo node by model hier uri. This can be done by analysing of destination path
			in the chromo nodes with destination specified.</simpara>
		</sect4>
	    </sect3>
	    <sect3><title>How to auto-import dep if it's inher hier referenced?</title>
		<simpara>Currently many deps in modules are based on inher hier in order to make it
		    independent on import owning node. Is it possible to evaluate inher hier in 
		    modules external chromo? Seems no. So this needs to be restricted: the only those 
		    uris to be enabled that ref via module node.</simpara>
	    </sect3>
	    <sect3><title>How to resolve deps from module: specific root in uri ?</title>
		<simpara>When constructing module via studio the absolute owning hier uri is used, with 
		    specific root name, i.e. "Root". This uri can be incorrect when we use the module in some
		    model having another root name, i.e "Root_1". How to handle this?</simpara>
		<simpara>One solution is to use anonymous root in uri, but this requires to significantly modify 
		    studio logic and seems not solid.</simpara>
		<simpara>Another solution is to use inher hier based uri for import agent. After import agent uri should
		    be of onwning hier. This is because imported modules are "mounted" on import agent. "Mounting" means owning 
		    relation so leads to using of owning based uri. Using inher hier for import agent itself allows make the uri
		    insensible against root name.</simpara>
	    </sect3>
	    <sect3><title>Concept: module</title>
		<sect4><title>Module as model with only internal deps or deps to other modules.</title>
		    <simpara>So module can be considered as kind of closure. This allows to move modules simply.</simpara>
		</sect4>
	    </sect3>
	</sect2>
	<sect2 id="ds_mod_selmut"><title>Selective mutation with merge option</title>
	    <sect3><title>Introduction</title>
		<simpara>Applying selective mutation within chromo to module is important part of 
		    approach of deps dynamic resolution, ref <xref linkend="ds_dyn_res"/>. For the approach
		    it is also required to apply mutation only in case if such mutation is not applied yet.
		    The term "selective mutation with merging" will be used for the mutation desctibed.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mod_imp"><title>Introducing mutation "import"</title>
	    <sect3><title>Introduction</title>
		<simpara>Use-case <xref linkend="ds_mod_uc_explimp"/> required mechanism to import some component from modules chromo.
		    It should also create component along with hier as stated by chromo. Currently there is no such mechanism - the
		    only mutation "move" is used to import modules component, but it doesn't support creating hier. One solution here is to
		    introduce new mutation "import" similar to move but supporting creating hier. It makes sense also to disable "move"
		    mutation to create node from the external chromo, so only "import" can do it. So there will be only one way to import 
		    external chromo.</simpara>
	    </sect3>
	    <sect3><title>Import locally or globally?</title>
		<simpara>The solution needs to be verified with use-case <xref linkend="ds_mod_uc_rec"/>. How to secure recursive resolving
		    deps for the module being imported? The approach would be to use explicit "import" within the module. But the question is how to 
		    resolve deps when only some comp is being imported? This was already discussed in <xref linkend="ds_mod_prb_alldeps"/> in scope
		    of automatic resolution approach using specific agents.</simpara>
		<simpara>There also working approach can be proposed in scope of explicit import. Base agent can process all import mutations in 
		    the cromo node imported explicitly and apply the mutation first in order to resolve deps. There are two options of
		    import within module: local and global. Local means that chromo node is imported into the scope of the module. Even if having local
		    deps is convenient, this causes overhead because of duplicating imports in different modules. The second option is global 
		    importing, that means importing to some predefined module in global context (i.e /Modules in model). At the first look global
		    import is ambuguous. This is because local mutation leads to change in global context.</simpara>
		<simpara>This ambiguousness can be partially mitigated by using specific native agent (e.g. "Import") for imports.</simpara>
	    </sect3>
	    <sect3><title>Specific agent or environment?</title>
		<simpara>There are two options of where to implements importing:
		    <itemizedlist>
			<listitem>In specific agent (e.g. AImports)</listitem>
			<listitem>In environment imports manager.</listitem>
		    </itemizedlist>
		</simpara>
		<simpara>The former assumes that the agent will be "point of mounting" of imports, when the latter allows mounting to 
		    different point, to /Modules in owning hier for instance.</simpara>
	    </sect3>
	    <sect3><title>Explicit import in agent run-time </title>
		<simpara>Ref <xref linkend="ds_mod_uc_rm"/> for use-case and discussion. As discussed, one approach to keep explicit imports
		    mutation aligned with models generic principles is to have import representation in agent model.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mod_uc"><title>Use-cases</title>
	    <sect3><title>Getting tree of chromo nodes</title>
	    </sect3>
	    <sect3 id="ds_mod_uc_explimp"><title>Explicitly importing node of modules remote chromo</title>
		<simpara>CLIENT knows that some node of modules remote chromo will be dep for model, so CLIENT explicitly
		    imports node to the module in the model</simpara>
		<simpara>Similar functionality is implemented currently with only limitation that the whole module to be imported. The import
		    itself is implemented via "move" mutation.</simpara>
	    </sect3>
	    <sect3><title>Importing component of module</title>
		<simpara>CLIENT gets MODULE agent and request importing component from remote chromo "attached" to MODULE using specific MODULE method.</simpara>
		<simpara>This is creating component via applying given chromo node from the modules attached chromo. 
		    This case is mostly for support of "automatic" resolution of dep on node of modules chromo, ref <xref linkend="ds_mod_uc_crn"/>.
		    Agent creates all owning hier but not fulfilles owners of created comp.</simpara>
		<simpara>Discussion:</simpara>
		<simpara>Why it is needed to create owning hier? To keep original path to comp witin the module.</simpara>
		<simpara>This "incomplete" applying chromo seems queerly. Right, but we can allow only 
		    compact chromo to be module. So, only add nodes mutations will be there, that will make 
		    partial mutation quite acceptable.</simpara>
	    </sect3>
	    <sect3><title>Disabling mutation "move" for all agents other than "module"</title>
	    </sect3>
	    <sect3 id="ds_mod_uc_crn"><title>Creating requested node from modules chromo if the node still not exists</title>
		<simpara>USER creates node in model with parent from modules - owning agent requests parent from modules 
		    - module agent gets involved in resolving request, agent checks if requested comp exists and 
		    creates it if not.</simpara>
		<simpara>Ref <xref linkend="ds_mod_prb_int"/> for discussion of problems with this use-case.</simpara>
	    </sect3>
	    <sect3><title>Importing modules comp that deps on other comp within this module.</title>
		<sect4><title>Discussion</title>
		    <simpara>Is it really required to import just part of the module but not the whole module? 
			Keeping module monolitic would allow simplify importing. The response argument here
			is that it causes overhead for big modules. To avoid this we can consider implements
			parts of big module also as module.</simpara>
		</sect4>
	    </sect3>
	    <sect3 id="ds_mod_uc_rec"><title>Importing module, thus importing all modules that are deps for initial module </title>
		<simpara>This is recursive importing all the modules required for given module.</simpara>
	    </sect3>
	    <sect3 id="ds_mod_uc_rm"><title>Removing import</title>
		<simpara>Precondition: There is explicit import mutation within some AGENT.</simpara>
		<simpara>Normal: USER decides that the import specified is not required anymore, so USER requested mutation of AGENT
		    in order to remove the import - SYSTEM mutates AGENT to remove import</simpara>
		<sect4><title>Discussion</title>
		    <simpara>This is obviously required but not sure what mutation should be for deleting import. This is because
			"import" mutation doesn't change AGENT actually but request environment for import. This clearly indicates that
			implementing explicit import via mutation doesn't conform to nature of mutation - to change the specified node of model.</simpara>
		    <simpara>To keep this conformed the imports have to be kind of part ot mutated agent, e.g. properties or special node.</simpara>
		</sect4>
	    </sect3>
	</sect2>
	<sect2 id="ds_mod_uc_impl"><title>Implementation</title>
	    <sect3><title>First implemetation: dynamic resolution plus explicit import to import agent. May-2015</title>
		<simpara>Dynamic resolution is used as the main mechanism of resolving ref to modules. Explicit import to dedicated agent
		    is used for initial creating modules model. Potentially even this explicit import can be avoided by generating 
		    correct uri to module within import agent from modules chromo uri.</simpara>
		<simpara>Currently dynamic resolution from model is disabled. Only deps from import agent itself are resolved. So combined
		    approach is implemented.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_mod_uc_sav"><title>Saving model as module</title>
	    <simpara>USER creates model and requests SYSTEM to save some part of model as module - SYSTEM saves the part of model, so 
		this module can be imported in the models.</simpara>
	</sect2>
	<sect2 id="ds_mod_uc_cre"><title>Creating model from module</title>
	    <simpara>USER request SYSTEM to create model directly from module - SYSTEM creates the model.</simpara>
	    <sect4><title>Discussion</title>
		<simpara>Current implementation and imports approach doesn't allow to this scenario. But this use-case is
		    important to see the preferred behaviour. Currently the modules structure differs from the structure of 
		    model. For instance there isn't dedicated import agent in module. The idea is that SYSTEM has to 
		    correctly create modules run-time both inside import agent and inside models body.</simpara>
	    </sect4>
	</sect2>
    </sect1>

    <sect1 id="ds_ecr"><title>Error correction</title>
	<sect2><title>Intro</title>
	    <itemizedlist>
		<listitem>Ref <ulink url="../requirements/index.html#uc_68"/> for use-case.</listitem>
		<listitem>Error correction is tightly connected to model branching, ref <xref linkend="ds_mmc_br"/></listitem>
	    </itemizedlist>
	    <simpara>There are some approaches for early error correction:</simpara>
	    <itemizedlist>
		<listitem>Incremental mutation with special mutations like re-parent to be introduced. Ref <xref linkend="ds_ecr_uim"/></listitem>
		<listitem>Incremental mutation plus model-level branching. Ref <xref linkend="ds_ecr_mlb"/> for details. </listitem>
	    </itemizedlist>
	</sect2>
	<sect2 id="ds_ecr_ure"><title>Recoverable and un-recoverable errors.</title>
	    <sect3><title>Intro</title>
		<simpara>Let's designate the errors that can be fixed via series of incremental mutations as "recoverable" error. Correspondingly the
		    errors that cannot be fixed this way we will call "un-recoverable".</simpara>
	    </sect3>
	    <sect3><title>What are examples of un-recoverable errors?</title>
		<simpara>One example is adding or configuring agent that crashes the whole model. Is this example correct? Shouldn't this bad result of mutation
		be prevented?</simpara>
	    </sect3>
	</sect2>
	<sect2><title>Sketches</title>
	    <sect3><title>Fixing error and re-using the model created</title>
		<simpara>
		    Main challenge in fixing error is that user wants not just fix error but fix it with minimal effort. This is not good enough solution
		    to find the place of error introducing, create branch from that point and evolve this correct branch. The problem here is that the
		    error could be introduced on early stage of model creation. So branching here causes that user need to repeat all the correct
		    mutations that were done on “erroneous” branch. But user wants to reuse all the right steps in model creation but not to repeat them.
		</simpara>
	    </sect3>
	    <sect3><title>What about direct change of chromo? Same problem with context.</title>
		<simpara>What if we don't use incremental mutation but correct wrong mutations directly in the chromo. It is simple to see that
		    there will be same problem with re-using other mutations. The cause is that the change of initial wrong mutations, for instance
		    creation node from wrong parent, will change context for other mutations. So some of these mutations need to be corrected too.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_ecr_uim"><title>Using incremental mutations.</title>
	    <sect3 id="ds_ecr_uim_ctx"><title>Can model errors be fixed in the scope of model’s incremental mutations?</title>
		<sect4>
		    Can model errors be fixed in the scope of model’s incremental mutation or there are some fundamental restriction of fixing errors
		    that way? There are few mutations for changing the model: node creation, name changing, content changing, removal, movement
		    (not elementary). We can consider the chain of mutations as trajectory in the space of all possible variants of the model being created.
		    So the question is: if some earlier movement in the trajectory is erroneous then is it possible to move the final point to right
		    destination point by some set of incremental steps. 
		</sect4>
		<sect4><title>Context to be taken into account.</title>
		    Important thing here is that all mutations are context dependent.
		    It makes sense to consider the erroneous changes that causes massive corruption of the model. Good example is inheritance initial node
		    from wrong parent and then creating big chain of inheritance and deps from this node. User did wrong mutation of creating node from parent A.
		    The correct way would be to create from parent B. But now there are a lot of mutations applied over this wrong initial mutation.
		    Can we fix it via incremental mutation. First of all we need mutation “re-parent”. Assuming we have it. The approach to this “re-parent”
		    mutation is to keep the inheritance chain child_of_A … and apply to child_of_A all mutation from delta of chromos B-A.
		    The problem here is that these mutations are context-dependent: they normally done on A context. But now we need to apply it above
		    all mutations done for child_of_A (these mutations can corrupt the context, for instance they can delay some nodes from A that are
		    to be mutated in the scope of B creation). In this case the attempt to apply delta of chromos B-A will cause errors.
		    This example shows that context dependency leads to the fact that mutation depends on the position in the chromo, i.e. it
		    is position dependent. Again: the mutations done when creating B from A (in the scope of A) are not equivalent to same mutations
		    done in the scope of final (i.e. variously mutated) child_of_A because the context is different.
		    Is there solution for that? Maybe. One of them could be that
		    when the attempt of applying B-A causes errors then user can apply correcting mutations first, for instance undo removal of missing
		    component of A - by this user will transform the context of B-A mutation to near to original one.
		    Then the user can do another attempt to apply B-A. In any case the fundamental problem of this approach is that we
		    try to apply mutation with the wrong context. Again: mutation and its context are inseparable, but probably we can consider mutations
		    as correct even they are done in improper context it the result of mutation is as expected. (NOTE: same problem is in the current
		    solution of mutation of parent – the mutations are propagated to children but the context there differs from that in parent so the
		    mutations are propagated with improper context).
		</sect4>
		<sect4><title>Unrecoverable errors cannot be fixed via incremental mutations</title>
		    <simpara>We can also state that if there is unrecoverable error than the incremental mutation cannot help fixing it.</simpara>
		</sect4>
	    </sect3>
	    <sect3><title>Re-parent. Incremental mutation seems not working.</title>
		<simpara>Re-parent (ref <xref linkend="ds_rpr"/> is a good example of early error. Incremental mutation approach can be used here via
		    introducing new mutation "re-parent" to "move" Child_of_A from parent A to parent B. This mutation should apply delta B-A chromo to the
		    Child_of_A. We alredy discussed the problem with wrong context when applying B-A (ref <xref linkend="ds_ecr_uim_ctx"/>). But there
		    is another problem. Actually this applying B-A is very similar to creating hear of agent, ref Elem::CreateHeir(). This algorithm
		    is based on getting heir of parent of agent and mutating it with agent's chromo. The procedure is recursive. There is important thing -
		    mutation with agents chromo is done in the agent's context (agent intentionally ask parent to re-locate created heir to agent's context.
		</simpara>
		<simpara>This is ok for heir being created. But how can we move existing Child_of_A to the context of ...B? Child_of_A can have established
		    relations so such a movement is impossible. How can we avoid this problem? One way is to transform mutations B-A for context of Child_of_A.
		    This implies transformation of all references in the mutations. Howewer even this trick doesn't help absolutely. The matter is that
		    the Child_of_A owner can handle Child_of_A mutations in different manner than right context in case of inheriting Child_of_A from B.
		    It is the question if this aspect can be ignored.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_ecr_mlb"><title>Incremental mutations via model-level branching</title>
	    <sect3><title>Intro</title>
		<simpara>The idea of this approach is to re-create the erroneous part of model from scratch in another branch. This allows to keep the 
		history and on the other hand to have new implementation.</simpara>
	    </sect3>
	</sect2>

    </sect1>

    <sect1 id="ds_mmc"><title>Review of mechanism of model creation</title>
	<sect2><title>Introduction</title>
	    <simpara>The current implementation includes two models: target model (aka run-time model) and chromo 
		(model of target model creation).  Chromo is just treeish structure of target model mutation,
		so the mutation incrementally change the model step by step. This approach was called 
		"incremental mutations". This approach keeps the "history" of target model creation, so it gets possible to
		"rollback" to any intermediate point of tagret model creation.
		The initial idea was that using incremental mutation approach can cover all the use-cases for 
		model creation. But then some use-cases was discovered that are not covered be this.
		There are some main use-cases: </simpara>
	    <itemizedlist>
		<listitem>Transformation of chromo. It was realized that incremental update of chromo doesn't 
		    allow keeping optimal chromo structure. For instance in many cases it is required to do 
		    transformation of chromo (e.g. optimization), ref <xref linkend="ds_transf"/>. In this case it gets not
		    possible to rollback to the given point of target model creation because the transformation
		    breaks "history".</listitem>
		<listitem>Multi-user creation of model. This is the case when more than one user is working on the 
		    target model. Traditional development uses "branching" paradigm for that. Initiall desing assumes 
		    that inheritance based model can cover this case: each user can create own child of models part 
		    and use this child as the "branch". But seems that the current approach doesn't cover this case 
		    fully. One problem is that the history is for the whole model but not for users, so it is not 
		    possible for the user to rollback his own changes. Another problem is that it's still possible 
		    to mutate model "before branching point", i.e. parent of the "branch" user created.</listitem>
		<listitem>Re-parent of node. This case is quite often when user creates the chain of inheritance and then realized
		    that the initial inheritance was wrong. So it would like to re-parent the initial heir. Potentially this could be done
		    without changing chromo, but direct way is to update chromo itself. 
		    Ref <ulink url="../requirements/index.html#uc_067"/> for the use-case.</listitem>
		<listitem>Roll-back of some mutation. In the scope of incremental mutation it was assumed that rollback should be done via applying
		    "inverse" mutation (add node - remove node etc.). But this "inverse" mutation is not exactly same as avoiding initial mutation.
		    For instance to roll-back change of content in case we don't know the previous value
		    of content. In such case it is not possible to use "inverse" mutation so we need to "remove" the mutation from 
		    the chromo.</listitem>
		<listitem>Rollback to some mutation and continue changing of model. This scenario means that old "rolled back" mutations
		    are still in history (i.e. in the chromo). Note that current incremental mutation approach doesn't support such kind of
		    "branching".</listitem>
	    </itemizedlist>
	    <simpara>All these cases can be generalized: we need to change the chromo itself only in those cases when it is not
		possible (or ineffecive) to change the model via the series of new mutations. For instance we can do re-base just
		removing the current chain and create the new one inherited from the right parent. This will work but be expensive.</simpara>
	    <simpara>So, again, we can consider various mechanisms of model creation:</simpara>
	    <orderedlist>
		<listitem>Current approach – incremental mutation, all changes of previous mutations are prohibited, only mutations adding is enabled.</listitem>
		<listitem>Enabled changing of chromo, not only adding mutations – there is mutation of mutation. It requires re-creation of the model
		    (In fact this approach is wrong, because the history is broken in that case) </listitem>
		<listitem>Inheritance with parents chromo mutation – currently the parent’s chromo is not changed when creating child. The only 
		    incremental mutations are done "above" parent's chromo.
		    With this new approach the parent’s chromo can be changed BEFORE creating the child. This allows to create parent’s “branch”
		    with changed chromo without re-creation the whole model. Ref <xref linkend="ds_mmc_ipcm"/> for the approach analysis.</listitem>
		<listitem>Using meta-chromo, which consists of mutations of chromo. The chromo is generated from meta-chromo and then created the model
		    from the chromo. In that case there is two-stage model creation: 1. chomo is created from meta-chromo 2. model is created from chromo.
		</listitem>
	    </orderedlist>
	</sect2>
	<sect2><title>Keeping 2 level model</title>
	    <simpara>It is still possible to cover many use-cases using initial approach (just chromo as 2nd level model) 
		with applying some limitations. The arguments are:</simpara>
	    <itemizedlist>
		<listitem>Transformation of chromo. To keep current approach we need to avoid unrecoverable transformation 
		    at all. The only transformation are to be allowed that can be recovered. In many cases it is achievable.
		    For instance the chromo optimization can be considered as marking chromo in order to help the models 
		    assembling machine. This marking can be simply removed to recover the chromo. In other words the 
		    optimization is just a mode of the machine that is set on or of before assembling. The argument here could be that
		    technically such kind of optimization is diffucult to implement. For instance there are various versions of some sub-model, then
		    the user wants to keep active only couple of them. He removes unused sub-models and requests optimization of the whole model. Then
		    he decides to optimize remaining sub-models. The problem here that it is not possible to distinct the optimization, so when the
		    user disable optimization of active sub-models the whole model optimization is disabled too. Probably this can be solved with
		    some improved design, but the use-case shows that such "parametrized" optimization is not universal solution.</listitem>
	    </itemizedlist>
	</sect2>
	<sect2 id="ds_mmc_br"><title>Branching</title>
	    <sect3><title>Intro</title>
		<itemizedlist>
		    <listitem>Branching is sensitive feature in model creation mechanism. It plays similar role to versioning tools in source code development.
			I.e it allows to keep in mind and evolve various sub-models.</listitem>
		    <listitem>There is various requirements to the branching. Some of them are:
			<itemizedlist>
			    <listitem>User can select active branch for creating model - all other branches get unused.</listitem>
			    <listitem>User can establish restrictions for its own branch so other users will deal with the branch under these restrictions.</listitem>
			</itemizedlist>
		    </listitem>
		    <listitem>In fact even current incremental mutations approach supports branching - each new inherited agent is the branch of 
			its parent. The specific is that normally all "branches" are used. This can be changed via removing unused "branches" and
			optimizing the whole model but this mechanism needs to be designed yet - there is no obvious design for it.</listitem>
		</itemizedlist>
	    </sect3>
	    <sect3><title>Misc</title>
		<orderedlist>
		    <listitem>
			How can we implement branching in the given model? One way is to select one of the sub-model as “branch”.
			In this case the env should create model with such a parameter – “sub-model selected to be a branch”.
			We need to take into account also the dependencies on other parts of the model. All deps need to be created too.
		    </listitem>
		    <listitem>
			What is the difference between branching on model level and branching on chromo level? Main difference is that branching
			on chromo level  guarantees that there is no dependencies to outside of the branch. It is similar to source code
			versioning control – relations within version control are completely independent (even their nature is different)
			on the model (source code, program).
		    </listitem>
		    <listitem>
			Let’s consider two methods of branching: tree of objects and tree of elements. Multi-agents model is example of tree of objects.
			Object itself here is complex but it is elementary member of tree chain. In multi-agents model it is not possible to branch from
			some intermediate state of object (from some mutations of object). Tree of elements where elements are mutations allows branching
			from any part of change history. So branching on model level has this limitation – we cannot branch from historic version of
			object but from the current version only.
		    </listitem>
		    <listitem>
			Branching is fundamental approach when creating complex models. User just cannot create the model without errors. Creation itself
			is complex so it is impossible to avoid errors. So the creation process includes errors correction: user analyzes the problem,
			finds where the error was introduced and then fix it. To fix it user creates branch from the point where error was introduced
			and creates new error free version. Often the problem is not an error but some week design. Then user creates new branch from
			the point that allows to create new design of model.
		    </listitem>
		</orderedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_mmc_ipcm"><title>Inheritance with parents chromo mutation </title>
	    <sect3><title>Intro</title>
		<itemizedlist>
		    <listitem>The idea of the approach is to implement so called "change of chromo" without introducing of new model creation layer like
			meta-chromo ("chromo of chromo"). Instead of specifying the change of chromo in meta-chromo this approach enables to
			specify parent's chromo change in the chromo of its child.</listitem>
		    <listitem>What gives this approach? First thing is that we get the possibility of chromo changing. Then it keeps the history, like
			meta-chromo approach does. Also it supports kind of "branching" (ref <xref linkend="ds_mmc_br"/>) because the parent
			(i.e. old sub-model, one branch) gets unchanged, instead we get child (new branch) where the chromo is corrected.</listitem>
		    <listitem>The weakness of this approach is that direct mutation (opposing to incremental mutation) can cause actual dramatical
			change of sub-model so it is almost impossible to do smooth verification of the change.</listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_graph"><title>Agents of graph model</title>
	<sect2><title>Intro</title>
	    <simpara>Vertex model provide system in form of graph, i.e as the pair of elements. The agents for modelling graph are Vertex agent and 
		Edge agent. The graph level is the lowest layer of models hierarchy. At the moment (20160311) there are graph layer agents implemented.
		But this implementation is not effective one. Morover it causes extra communication between agent that causes deadlock in distributed 
		environment, ref <ulink url="../../../fap2-srv/doc/design/index.html#ds_pacl_id"/>. So some redesign is required for graph layer.</simpara>
	    <simpara>The proposal for improvement is to avoid vertex interacting to edge.</simpara>
	</sect2>
	<sect2><title>The current implementation</title>
	    <simpara>The idea of the implementation was to have in edge direct refs to the vertexes related. So edge has actually the status "connected/disconnected" basing
		on this ref: if direct ref is not null then the status is "connected". So in order to handle the status properly we need also to have direct ref to edge in 
		vertexes. For instance when vertexes gets removed it notifies edge of that, so edge change the status to "disconnected". Edge also have indirect refs
		to vertexes via URI specified in edge's points ("P1", "P2") properties.</simpara>
	    <simpara>Also Vertex contains the cash of it's pairs (iPairs set). This cashe is used in iface resolution mechanism to quick redirecting the 
		request to vertex pairs.</simpara>
	</sect2>
	<sect2><title>Redesing: lightweight version.</title>
	    <simpara>The initial proposal is to avoid keeping refs to vertexes in edge, but keep only refs to pairs in vertexes. The problem here is
		that these edge's refs to pair are activelly used by studio when creating detail representation of the node. So seems the real way to
		simplify the scheme is to avoid refs from vertex to edges. How to handle vertex removal in this case? It can be done via handling
		removal on vertex owner level. This owner should find the proper edge and disconnect it (or just redirect the notification to all edges). Another
		way is to disable removing vertes until it has some pairs.</simpara>
	</sect2>
	<sect2><title>Use-cases: Vertex being deleted</title>
	    <sect3><title>Intro</title>
		<simpara>Current implementation handles the vertex deletion: edge received notification from the vertex and disconnects from it. What should
		    be the handling in improved implementation? It could be the same, the only difference is that first the notification should go to the
		    vertex owner and then the owner has to redirect it to the proper edge. Do we actually need to handle vertex deletion? One case that
		    points to necessity of that is: there are vertexes V1 and V2 containing V1_1 and V2_1 correspondingly, there is edge E1 connecting
		    V1_1 and V2_1, then V2_1 gets removed, then E1 gets removed - E1 tries to disconnect V2_1 but it is already removed. Seems that the
		    problem here is mostly in deletion design is not quite polished.</simpara>
		<simpara>If we implement edge disconnecting on vertex removed (as it is done currently) it will mean that all edges inside the complex
		    system will be disconnected. It's hard to reason such a behavior. More reasonable would be to keep internal connections as is. 
		    We could disable deleting vertex when its connection is active. But this also will require the necessity of all edges manual disconnecting
		    inside the complex system being removed.</simpara>
		<simpara>Another approach is to not touch connections when delete vertex but improve the behavior of deleted nodes. We need to disable
		    handling all events by them.</simpara>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_daa"><title>Distributed asyncronous agents (DAA)</title>
	<sect2><title>Introduction.</title>
	    <itemizedlist>
		<listitem>Creating of agents in separate execution environment should be supported. Ref TBD for use-case.
		    This assumes several kind of separate execution environment: thread, process, network node. These kinds of 
		    environments differs by interacting agents accessibility level. For separate thread environment the 
		    acess is direct, whereas for separate process there agents are existing in independent memory, so
		    cannot be accessed directly. In case of separate network node, the interaction should be performed
		    via some network protocole.</listitem>
		<listitem>Ref also <xref linkend="ds_irm"/> for discussion regarding using of iface resolution in models parts communication.</listitem>
		<listitem>Ref <xref linkend="ds_mv_local_nm"/> for discussion regarding one of approaches of creating DAA.</listitem>
	    </itemizedlist>
	</sect2>
	<sect2><title>Refs</title>
	    <biblioentry id="ref_crm_drds"> <abbrev>CRM_DRDS</abbrev>
		<productname><ulink url="http://www.sei.cmu.edu/reports/93tr010.pdf"/></productname>
		<title>Craig Meyers. The Use of ASN.1 and XDR for Data Representation in Real-Time Distributed Systems</title> </biblioentry>
	</sect2>
	<sect2><title>Problems to be considered</title>
	    <sect3><title>How native hierarhy can be implemented for DAA?</title>
		<simpara>Currently the native hier is based on direct access to components - each agent has
		    components register where the direct access pointers to the components are stored.</simpara>
		<simpara>In fact the agent-container can store in the register "path" to component instead of
		    direct pointer. The nature of "path" depends on separate exection environment implementation.
		</simpara>
	    </sect3>
	</sect2>
	<sect2><title>Executing environment types.</title>
	    <simpara>There can be several types of remote environment related to the initial environment:</simpara>
	    <itemizedlist>
		<listitem>Separate thread environment</listitem>
		<listitem>Separate process environment</listitem>
		<listitem>Separate network node environment</listitem>
	    </itemizedlist>
	    <simpara>These types of environments differs by interaction mechanism. For the separate thread envoronment it could be named pipes, for
		separate process it could be named pipes or sockets, for separate network node it could be sockets, etc.</simpara>
	    <simpara>There can be some environments on the same nw node. Do we need specific service on nw node that handles request for 
		creating env and serves as proxy for interacting to envs on this node? Or env itself will be responsible to create other envs on the
		local node?</simpara>
	    <simpara>Remote environment identification should be used to specify which env to interact to.</simpara>
	</sect2>
	<sect2 id="ds_daa_iact"><title>Distributed agent interactions mechanism overview</title>
	    <simpara>Currently the agent model is based on direct syncronous communication between agents. 
		DAA communication should be indirect and asyncronous. So the solution of how to update the model in order to support indirect and async
		communication is the key part of DAA design. Let's overview the possible approaches for this: </simpara>
	    <orderedlist>
		<listitem><emphasis role="bold">Using proxy agent for the interactions:</emphasis>
		    Ref <xref linkend="ds_daa_proxy"/> for the approach analysis. In <xref linkend="ds_daa_proxy_us_nav"/> there is outline of 
		    the approach inconsistency, i.e. weakness.
		</listitem>
	    </orderedlist>
	</sect2>
	<sect2 id="ds_daa_proxy"><title>Interactions approach: Async agent proxy</title>
	    <sect3><title>Intro</title>
		<simpara>In <xref linkend="ds_daa_iact"/> the specific proxy was introduced as agent that represents assigned async agent in
		    remote environment. The idea of proxy is to simplify interacting to the remote agent as much as possible. From this point of 
		    view it should be an agent. However proxy doesn't implement base agents APIs directly but just redirects all the request
		    to its proxied agent.  </simpara>
		<simpara> The proxy should also be point of interacting to proxied agent, so the proxy should expose specific APIs
		    for async interaction. Such APIs currently missing in base agent. So there are the following approaches to be considered:
		    <orderedlist>
			<listitem><emphasis role="bold">To extend base agent APIs and functionality in order to support async interactions:</emphasis>
			    Extending APIs seems superfluos because it's not required within single env.  </listitem>
			<listitem><emphasis role="bold">Introduce new APIs in the proxy for async interactions:</emphasis>
			    Ref <xref linkend="ds_daa_proxy_sa"/> for the approach analysis.
			    Using specific APIs for async interactions any case leads to extending behaviour of 
			    base agent. Base agent should be able to work both with "normal" agents and with specific APIs.  </listitem>
			<listitem><emphasis role="bold">To keep current APIs by using blocking async communication</emphasis>
			    This would allow to avoid serios update of base agent behaviour. The real non-blocking interaction in
			    this case will be provided by specific type of agents, e.g. DES, ref <xref linkend="ds_daa_des"/>
			    Ref <xref linkend="ds_daa_proxy_bl"/> for the approach analysis.
			</listitem>
		    </orderedlist>
		</simpara>
	    </sect3>
	    <sect3><title>Should proxy be specific type of agent</title>
		<simpara>On the one hand AA proxy is shown as proxied agent itself within the current env. 
		    So we could assume that it has the same attributes as proxied agent: name, type, etc. On another hand it contradicts to the 
		    generic design of agents, where the type (i.e. URI in native hier inher projection) of agent is unique. So the name of proxy
		    can be the same as proxied agent but the type has to be specific.</simpara>
	    </sect3>
	    <sect3><title>Interaction: customising proxy or env ?</title>
		<simpara>There are two approached of implementing various kinds of interactions: to implement interactions type specifics on 
		    proxy or environment side.</simpara>
	    </sect3>
	    <sect3 id="ds_daa_proxy_sa"><title>Approach: AA proxy specific APIs</title>
		<sect4><title>Use-case - gettng node</title>
		    <simpara>Owner requests proxy to get node by native hier URI.</simpara>
		</sect4>
	    </sect3>
	    <sect3 id="ds_daa_proxy_bl"><title>Approach: to keep current APIs by using blocking async communication</title>
		<simpara></simpara>
	    </sect3>
	    <sect3 id="ds_daa_proxy_us_nav"><title> Use-case: Navigating through native hierarchy </title>
		<simpara>The current sync agents model has the set of APIs for navigating thru native hierarchy:</simpara>
		<programlisting>
		    Elem* GetNode(const GUri&amp; aUri);
		    Elem* GetMan();
		    Elem* GetParent();
		</programlisting>
		<simpara>In sync agents system the navigating results in getting reference to some agent in native hier. This feature
		    is core and should remaing in DAA. The only difference is that the reference to agent is not simple ref but a proxy dedicated
		    for communicating to particular agent. It makes sense that such a proxy is persistent and takes place of agent in local native hier. On
		    the firure below Env_1, Env_2 are executing environment, e.g independent processes on the same machine. Native hier fragment is agent 
		    "owner" containing components "comp_1" and "comp_2". Agent "comp_2" is the child of the agent "parent".
		    Because "comp_2" component is in environment separate from that executing "owner",
		    the agent "owner" places "comp_2" proxy, that communicates to "comp_2" via IPC. On Env_2 side there is proxy "owner" for the agent "comp_2"
		    that allows the agent to request it's owner for navigatng APIs. Similar proxies are for relation parent-child. The relations are bidirectional,
		    so the corresponding proxies are required in Env_2 environment to perform interaction from the agent "comp_2" to its owner and parent.</simpara>
		<figure id="fig_daa_ref"><imageobject> <imagedata fileref="pics/pic_daa_ref.png"/> </imageobject></figure>
		<simpara>The figure shows that this approach is a bit inconsistent because in reality "parent"s proxy "comp_2" register as the child for the
		    agent "parent" whereas the proxies parent is native agent "proxy". This inconsistency indicates logical weakens of the approach.</simpara>
		<simpara>To keep this proxy based model more consistent we could to modify the current base agents implementation so the agents keeps in 
		    its component and children registers not ref to agent itself but to iface of native hier node (MElem). Thus we could create specific class
		    for the proxy and put into the registers the ifaces of real agent in case of the same env and ifaces of proxies in case of remote agent.</simpara>
	    </sect3>
	    <sect3 id="ds_daa_proxy_crh"><title>Use-case: Creating heir</title>
		<simpara>The current sync agents model has the  APIs for creating heir:</simpara>
		<programlisting>
		    Elem* CreateHeir(const string&amp; aName, Elem* aMan);
		</programlisting>
		<simpara>Creating heir is based on some agent (existing in native hier) inheritance, it is performing in the phases:</simpara>
		<itemizedlist>
		    <listitem>Getting the parent in native hier</listitem>
		    <listitem>Requesting the parent to create its hier</listitem>
		    <listitem>Requesting created hier for mutation with the specified chromo.</listitem>
		</itemizedlist>
		<simpara>The first phase is supported in DAA because we keep native hier in the model. So owner gets parent or parents proxy. The second
		    phase assumes that owner can control creation agent within separate executing environment. Obviously this should be the reponsibility
		    of owners environment to provide owner with such capability. So, for instance env can be able to fork the process with separate env
		    ruinning. Actually the second phase is being performed recursivelly: parent searches its own parent and request him to create heir etc. This
		    recursive process end up with finding lowest level parent, i.e. native agent that actially is created by env (to be exact with envs
		    native agents factory). Each level parent mutates the child in parents own context (i.e. child remains in parents native hier).
		    After mutating the parent transit the child to upper layer parent, so the upper layer parent put the child its own context.
		    Note that parents parent can live in separate env. So initial agent initializing the agent creation should ask env 
		    for create new env and return ref to the created new env. Initial agent shoud pass this ref to the new agent parent as a context.
		    So the ref is a context of recursive process of phase two. On the final point of phase two the low level parent finds that its parent
		    doesn't exists in native hier but is a native agent, so low level parent asks env from the context (i.e. separate env) to create
		    this native agent. Remote env creates the agent and returns ref to it. The low level parent requests the newly created agent (via ref)
		    to mutate, so the creation process phase two upstream process starts unwinding.
		    Ref <xref linkend="ds_daa_proxy_crh_icd"/> for detailed interaction diagram.  </simpara>
		<simpara>So agents env should have API for creating new remote env, i.e. there should be proxy to remote env supported.</simpara>
		<simpara>As mentioned above, "initial agent initializing the agent creation should ask env for create new env ...". But how can it be
		    reflect in syntax. There are the following options:</simpara>
		<orderedlist>
		    <listitem id="ds_daa_proxy_crh_stx_attr"><emphasis role="bold">To introduce dedicated attribute "env" for mutation -node-.</emphasis>
			<para>Ref <xref linkend="ds_daa_proxy_crh_stx_attr_alz"/> for the approach analysis.
			</para>
		    </listitem>
		    <listitem id="ds_daa_proxy_crh_stx_agt"><emphasis role="bold">To use specific native agent type for "remote agent" (remote root).</emphasis>
			<para> Ref <xref linkend="ds_daa_proxy_crh_stx_agt_alz"/> for the approach analysis.
			    For instance we can introduce new agent for "separate process remote system", that can cover specifics for "remote". 
			    Actually this agent should be proxy, that also requests env to create proxied agent, so env creates remote env first.</para></listitem>
		    <listitem id="ds_daa_proxy_crh_stx_renv"><emphasis role="bold">To use specific native agent for remote env</emphasis>
			<para> Ref <xref linkend="ds_daa_proxy_crh_stx_renv_alz"/> for the approach analysis.</para>
			<para>In contrast to approach <xref linkend="ds_daa_proxy_crh_stx_agt"/> this agent represent not remote root but remote env. So 
			    the agent serves as client to remote env.</para>
		    </listitem>
		</orderedlist>
		<sect4 id="ds_daa_proxy_crh_stx_attr_alz"><title>Approach "Using dedicated attribute "env" for mutation -node-": analysis</title>
		    <simpara>This section is for analysis of approach <xref linkend="ds_daa_proxy_crh_stx_attr"/></simpara>
		    <orderedlist>
			<listitem>What if we need to change the remote env for the given agent. How to mutate attribute "env"? Normally there is no problem
			    to change the attribute. For instance we can simply change attribute "id" (i.e. rename agent). Bun in case of "env" the problem
			    is that this attr affects agent significantly. So the mutation of changing this will be quite complex operation, that required
			    re-creation of the agent (and actually reloading the model. Potentially we
			    can compact the node to melt the mutation to the original -node- mutation. 
			</listitem>
		    </orderedlist>
		</sect4>
		<sect4 id="ds_daa_proxy_crh_stx_agt_alz"><title>Approach "Using specific agent type for remote root": analysis</title>
		    <simpara>This section is for analysis of approach <xref linkend="ds_daa_proxy_crh_stx_agt"/></simpara>
		    <sect5><title>Sports:</title>
			<orderedlist>
			    <listitem><emphasis role="bold">How to specify remote env</emphasis>
				<para> It was stated that this approach is the way of specifying remote env where the remote agent is to be created. But
				    how particularly can this remote env be specified? We can specify the fact that the agent should be remote: this is 
				    specifyed by the type of the agent. For instance we can have agent of type of "separate thread agent" or "separate process
				    agent". What about another nw node? Normally it can be specified by the nodes URL. This is not directly covered by this approach.
				    A solution would be to specify remote env in specific property of the agent. This will require local env to analyze the chromo
				    of the agent before the agent creation. Another solution is to have this dedicated agent not as remote root but as local
				    agent, whose property is specifyed remote env. Then the component (the only one component is allowed) will be the root in
				    remote env.
				</para>
			    </listitem>
			    <listitem>This approach pecularity is that the remote root is dedicated agent. This agent doesn't need to have relation to 
				local proxy to communicate to agent's owner. Instead the agent embeds the mechanism of communication to its counterpart -
				remote root agent master.
			    </listitem>
			</orderedlist>
		    </sect5>
		    <sect5><title>Use-case: creating root node in remote root</title>
			<itemizedlist><title>Actors:</title>
			    <listitem>Env_server</listitem>
			    <listitem>Current_env</listitem>
			    <listitem>Remote_env</listitem>
			    <listitem>Current_node - node in current env hier</listitem>
			    <listitem>Remote_root_agent_master - agent that created in local env and represents Remote_root</listitem>
			    <listitem>Remote_root_agent_slave - specific agent, counterpart of Remote_root_agent_master root,  node to be created in Remote_env</listitem>
			</itemizedlist>
			<orderedlist><title>Interactions:</title>
			    <listitem>Current_node creates Remote_root_agent_master. Specific property defined in Remote_root_agent chromo specifies remote env the 
				agent is representing. Created Remote_root_agent_master requests Env_server to connect to specified env, or create the env if not 
				exists yet and then connect.</listitem>
			    <listitem>Env_server creates Remote_env and connects Remote_root_agent to Remote_env.</listitem>
			    <listitem>Remote_root_agent_master requests Remote_env to create Remote_root_agent_slave as remote_root - 
				the agent that Remote_root_agent_master will be representing in the initial env.</listitem>
			    <listitem>Remote_env creates Remote_root_agent_slave and mutually connect Remote_root_agent_master and Remote_root_agent_slave. 
				So Remote_root_agent_slave serves as components APIs handler, but Remote_root_agent_master - as owner APIs.</listitem>
			</orderedlist>
			<orderedlist><title>Criticism:</title>
			    <itemizedlist>Remote_root_agent_master acts as proxy for Remote_root_agent_slave. This means that Remote_root_agent shouldn't contains 
				any components locally. But it is stated that Remote_env spec is provided as Remote_root_agent property. It is accepted if property is 
				agents conntent (even that needs to be checked). But property in form of component is not accepted absolutelly.</itemizedlist>
			</orderedlist>
		    </sect5>
		    <sect5><title>Use-case: handling "GetNode" request from remote node</title>
			<itemizedlist><title>Actors:</title>
			    <listitem>Current_node - node in current env hier</listitem>
			    <listitem>Remote_root_agent_slave - root node to be created in Remote_env</listitem>
			    <listitem>Remote_root_agent_master - agent that created in local env and represents Remote_root_agent_master</listitem>
			    <listitem>Target_node - node that is target for GetNode request</listitem>
			    <listitem></listitem>
			</itemizedlist>
			<orderedlist><title>Interactions:</title>
			    <listitem>Current_node requests Remote_root_agent to get node by given URI</listitem>
			    <listitem>Remote_root_agent_master redirects this request to service - Remote_root_agent_slave.</listitem>
			    <listitem>Remote_root_agent_slave implemets this request locally, and returns Target_node ID to Remote_root_agent_master</listitem>
			    <listitem>Remote_root_agent_master get Target_node ID, creates Target_node proxy, register the proxy and returns proxy pointer to
				Current_node</listitem>
			</orderedlist>
		    </sect5>
		</sect4>
		<sect4 id="ds_daa_proxy_crh_icd"><title>Interaction sequence of creating heir.</title>
		    <simpara>This section describes interaction sequence for approach of using dedicated native agent for remote "root", ref
			<xref linkend="ds_daa_proxy_crh_stx_agt"/></simpara>
		    <orderedlist>
			<listitem>Remote agent proxy requests local env for creating root in remote environment.
			    <para>Note that the proxy should specify remote env ID in this request.</para>
			</listitem>
			<listitem></listitem>
		    </orderedlist>
		</sect4>
	    </sect3>
	    <sect3 id="ds_daa_proxy_crh_stx_renv_alz"><title>Approach "Using specific native agent for remote env": analysis</title>
		<sect4><title>Intro</title>
		    <orderedlist>
			<listitem>This approach difference from <xref linkend="ds_daa_proxy_crh_stx_agt"/> is that the regular agent is used for
			    remote root but not specific agent. All specifics of interaction to remote environment is implemented in remote env agent. This 
			    agent doesn't have its specific counterpart in remote env but proxy only.</listitem>
		    </orderedlist>
		</sect4>
		<sect4><title>Should be symmetric ?</title>
		    <simpara>We considered remote env agent on side of initially given local env. But on remote env side the situation is similar: 
			there the local env is "remote" in respect of remote env. So maybe remote env agent is required on both sides ? No, it isn't.
			Remote env agent is just for initiating creation remote env, in this regard the local env is "master" but the remote "slave".
			The envs are symmetric in regards of that both have to have upper level proxies one to another: in local env remote env agent have
			proxy to its remote component, remote root have proxy to its owner (remote env agent) in local env.</simpara>
		</sect4>
		<sect4><title>Will be upper level proxy to local remote env agent root in remote env ?</title>
		</sect4>
		<sect4><title>Use-case: creation remote env root</title>
		    <itemizedlist><title>Actors:</title>
			<listitem>Env_server</listitem>
			<listitem>Current_env</listitem>
			<listitem>Remote_env</listitem>
			<listitem>Remote_env_agent - special agent representing remote env</listitem>
			<listitem>Current_node - node in current env hier</listitem>
			<listitem>Remote_env_root - root node to be created in Remote_env</listitem>
			<listitem>Remote_env_root_proxy - proxy for Remote_env_root</listitem>
		    </itemizedlist>
		    <orderedlist><title>Interactions:</title>
			<listitem>Current_node creates Remote_env_agent. Specific property defined in Remote_env_agent chromo specifies remote env the 
			    agent is representing. Remote_env_agent requests Env_server to connect to specified env, 
			    or create the env if not exists yet and then connect.</listitem>
			<listitem>Env_server creates Remote_env and Remote_env_agent proxy of owner type.</listitem>
			<listitem> Remote_env_agent chromo contains node Remote_env_root. Remote_env_agent requests Remote_env to create Remote_env_root with
			    given Remote_env_root chromo. Remote_env_agent passes its own ID to the request. </listitem>
			<listitem> Remote_env creates Remote_env_root and returns Remote_env_root ID to Remote_env_agent. Remote_env also set Remote_env "owner" proxy
			    as owner for Remote_env_root.  Remote_env_agent creates Remote_env_root_proxy as component.</listitem>
		    </orderedlist>
		</sect4>
		<sect4><title>Use-case: creation model in remote env (separate thread)</title>
		    <itemizedlist><title>Actors:</title>
			<listitem>Current_env - env containing current model</listitem>
			<listitem>Remote_env - env separated from Current_env (separated thread)</listitem>
			<listitem>Current_env_server - server managing current env (and Remote_env also, because Remote_env separated via thread)</listitem>
			<listitem>Remote_env_agent - special agent representing remote env</listitem>
			<listitem>Current_node - node in current env hier</listitem>
			<listitem>Remote_env_root - root node to be created in Remote_env</listitem>
			<listitem>Remote_env_root_proxy - proxy for Remote_env_root</listitem>
		    </itemizedlist>
		    <orderedlist><title>Interactions:</title>
			<listitem>Current_node creates Remote_env_agent. Remote env property of Remote_env specifies remote env as env in the same
			    process but in separate thread.</listitem>
			<listitem>Remote_env_agent requests Current_env to create Remote_env</listitem>
			<listitem>Current_env requests Current_env_server to create Remote_env in new thread</listitem>
		    </orderedlist>
		</sect4>
		<sect4><title>Pros</title>
		    <orderedlist>
			<listitem>The only one specific agent type (Remote env agent) is required. In <xref linkend="ds_daa_proxy_crh_stx_agt"/> 
			    also one agent is required - Remote_root_agent, but actually there are two agents: one for master role and another for slave.</listitem>
			<listitem>The identification of remote env can be done using Remote_root_agent components. In case of 
			    <xref linkend="ds_daa_proxy_crh_stx_agt"/> only agents content is allowed for that.</listitem>
			<listitem>Moving some node of model to remote env is simple: just cover this node by Remote_env_agent, i.e just add Remote_env_agent
			    to the model and move the node to this agent.</listitem>
		    </orderedlist>
		</sect4>
		<sect4><title>Use-case: creating proxy when multiple equivalen requests issued</title>
		    <itemizedlist><title>Actors:</title>
			<listitem>Env_server</listitem>
			<listitem>Current_env</listitem>
			<listitem>Remote_env</listitem>
			<listitem>Remote_env_agent - special agent representing remote env</listitem>
			<listitem>Current_node - node in current env hier</listitem>
			<listitem>Remote_env_node - some Remote_env model</listitem>
			<listitem>Remote_env_node_proxy - proxy for Remote_env_node</listitem>
		    </itemizedlist>
		    <orderedlist><title>Interactions:</title>
			<listitem>Current_node creates Remote_env_agent that contains internal chromo. Remote_env_agent requests Remote_env to create remote model by
			    internal chromo - Remote_env creates remote model.</listitem>
			<listitem>Current_node request Remote_env_agent for getting internal node Remote_env_node by URI - Remote_env_agent request Remote_env for 
			    getting node - Remote_env responses with Remote_env_node identifier - Remote_env_agent creates native node proxy Remote_env_node and
			    set identifier as its cursor.</listitem>
			<listitem>Current_node request Remote_env_agent for getting internal node Remote_env_node again - Remote_env_agent request Remote_env for 
			    getting node - Remote_env responses with Remote_env_node identifier - Remote_env_agent checks if there is already proxy with this
			    identifier set as a cursor (ref <xref linkend="ds_daa_apc_crs"/>) - Remote_env_agent detects that there is already Remote_env_node_proxy 
			    with such identifier - Remote_env_agent returns the current Remote_env_node_proxy to Current_node.  </listitem>
		    </orderedlist>
		    <orderedlist><title>Discussion</title>
			<itemizedlist>The problem here relates to implementation of cursor, ref <xref linkend="ds_daa_apc_crs"/>.</itemizedlist>
		    </orderedlist>
		</sect4>
	    </sect3>
	    <sect3><title>Proxy interacting to the assosiated remote agent.</title>
		<simpara>Base approach of proxy interacting to the proxied agent is implementing interacting on env level. Proxy is this case just
		    keeps references (handle) to target env and proxied agent. Local env has also established connections to the remote envs.
		    Proxy asks local env for sending request to proxied agent passing refs as the context.
		    Local env contains the register of remote envs including initialized transport for them. Env combines the request packet and sends it thru
		    the corresponding transport. The remote env also contains the registers of remotes envs and local agents (mapped via handles). Remote 
		    env receives the message, assosiates it to the corresponsing agent, runs the agent APIs, get the returned data, forms the response and
		    sends the response back.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_apc"><title>Agent - proxy interacting.</title>
	    <sect3><title>Intro</title>
		<simpara>There was approach outlined of using proxies for interacting from local env to remote one, ref <xref linkend="ds_daa_proxy"/>. So proxy 
		    is just "light" implementation of some interface. "Light" means that it is not true implementation but the client of remote agent, that "truly" 
		    implements the interface. So the proxy makes remote procedure call (RPC) to its counterpart. The question is how to implements this RPC.
		    ref <xref linkend="ds_daa_apc_rpc"/> for analysis.</simpara>
		<simpara>Proxy communicates to its remote counterpart thru some communication session established between remote DES server and its local client.
		    Normally the local client is dedicated agent in local environment, for instance remote env agent, ref <xref linkend="ds_daa_proxy_crh_stx_renv"/>.
		    So proxy itself is not a client. It ask assosicate remote env agent to send request to the server. But the server also is not the executor of
		    RPC, it just redirects the request to target agent in remote env. Specification of target remote agent, also called "cursor" is the property
		    of the proxy. The question here is how to specify a cursor, and what would be the mechanism of redirecting the request from server to the 
		    target agent.  </simpara>
		<simpara>One more design aspect is how to implement RPC that base agents implementation is not affected. This means that RPC "layer" has to
		    be isolated from base agents engine. Ref <xref linkend="ds_daa_apc_fbp"/> for the consideration.</simpara>
	    </sect3>
	    <sect3 id="ds_daa_apc_rpc"><title>RPC</title>
		<sect4><title>Refs</title>
		    <biblioentry id="ref_wiki_asn_1"> <abbrev>WIKI_ASN_1</abbrev>
			<productname><ulink url="https://en.wikipedia.org/wiki/Abstract_Syntax_Notation_One"/></productname>
			<title>Abstract Syntax Notation One. Wikipedia.</title> </biblioentry>
		    <biblioentry id="ref_itu_asn_1"> <abbrev>ITU_ASN_1</abbrev>
			<productname><ulink url="http://www.itu.int/en/ITU-T/asn1/Pages/introduction.aspx"/></productname>
			<title>ITU. Introduction to ASN.1</title> </biblioentry>
		    <biblioentry id="ref_cie_rpc"> <abbrev>CIE_RPC</abbrev>
			<productname><ulink url="http://www.freesoft.org/CIE/Topics/86.htm"/></productname>
			<title>An Internet Encyclopedia. RPC Protocol Overview</title> </biblioentry>
		    <biblioentry id="ref_rfc_1831"> <abbrev>RFC_1831</abbrev>
			<productname><ulink url="http://www.freesoft.org/CIE/RFC/1831/index.htm"/></productname>
			<title>RFC 1831. RPC: Remote Procedure Call Protocol Specification Version 2</title> </biblioentry>
		    <biblioentry id="ref_rfc_1832"> <abbrev>RFC_1832</abbrev>
			<productname><ulink url="http://www.freesoft.org/CIE/RFC/1832/index.htm"/></productname>
			<title>RFC 1832. XDR: External Data Representation Standard</title> </biblioentry>
		    <biblioentry id="ref_wiki_dlm"> <abbrev>WIKI_DLM</abbrev>
			<productname><ulink url="https://en.wikipedia.org/wiki/Delimiter"/></productname>
			<title>Delimiter. Wikipedia.</title> </biblioentry>
		</sect4>
	    </sect3>
	    <sect3 id="ds_daa_apc_crs"><title>Cursor</title>
		<sect4><title>Intro</title>
		    <simpara>Remote env proxy creates and uses client to FAP server. So all other proxies just redirect theirs specific requests to remote env to remote
			env proxy. These specific requests relate to proxy counterpart in remote env. Proxy has to have unique identifier of this counterpart.
			This unique identifier can be considered as "cursor" of interactions. Cursor is sent as the argument of proxies specific request.</simpara>
		    <simpara>What can be this identifier. One option is to use counterpart URI. The problem with URI is that it is not unique. Another option is
			to generate UID for each native node and use UID as identifier.</simpara>
		</sect4>
	    </sect3>
	    <sect3 id="ds_daa_apc_fbp"><title>Front and back proxy</title>
		<simpara>One of the solution is to have two proxy instead of one: front and back. Front proxy represent the given interface and send RPC request
		    to remote env.  Remote env server analyses the interface id and cursor in the request, obtains the back proxy corresponding to interface, 
		    resolve cursor and pass the corresponding node pointer to back proxy. Back proxy de-marshals the request and call the proper method from
		    the node.</simpara>
	    </sect3>
	    <sect3><title>Proxies life cycle. Reflecting changes in remote model.</title>
		<simpara>What if there is proxy of some node of remote model and this node has changed in manner that affects proxies cursor (got renamed for instance) ?
		</simpara>
	    </sect3>
	</sect2>
	<sect2><title>RRC request method spec (ABNF)</title>
	    <programlisting>
		sep = "," ; Separator of parts
		method = name sep sigid *(sep arg)
		sigid = DIGIT ; Signature id (in case if there are more than one method with the same name)
	    </programlisting>
	</sect2>
	<sect2 id="ds_daa_px"><title>Proxy design</title>
	    <sect3><title>Proxy ifaces</title>
		<simpara>Proxy should acts as base agent because it should be included into model instead of real agent. For instance
		    it should be included as an owner of the "root" in remote model. So all base agent ifaces should be supported. Not all interfaces
		    are suitable for work in context of proxy. </simpara>
	    </sect3>
	</sect2>
	<sect2><title>Support of DAA</title>
	    <sect3><title>Intro</title>
		<simpara>In <xref linkend="ds_daa_iact"/> it was async agent APIs clarified. But there is another side of DAA implementation:
		    how agent to be modified in order to support this new APIs. This is most complicated part of DAA design because it introduces
		    many problems for agents model. To be exact it required support of asynchronous operation on agent level.</simpara>
	    </sect3>
	    <sect3><title>Outline of approaches</title>
		<orderedlist>
		    <listitem>Introducing new agents-level interface for async agent proxy. <programlisting></programlisting>
			<simpara>We can introduce new iface for the proxy. Base agent is to be modifyed in order to check if the node implements this
			    iface and if so, use specific behaviour communicating to the node.</simpara>
		    </listitem>
		</orderedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_des"><title>DES vs generic agent in DAA.</title>
	    <sect3><title>Intro</title>
		<simpara>DAA assume that all interactions between agents are asyncronous. But we designed DES as target model of async system because
		    multi aganents async model is the problem itself.
		    Agents model was used just as sutable means to implements DES. Does it make sense to focus on async DA or better to focus on
		    async DES only? Focusing on DES only seems problematic: DES is agent, so creating DES in separate async context needs that
		    agent supports at least such operation. It also requires support of generic agents features (native hier etc.) for async case.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_md"><title>Implementation problem: mutations dependencies</title>
	    <sect3><title>Intro</title>
		<simpara>There is mutations safety mechanism implementation, ref <xref linkend="ds_mut"/> that uses dependent chromo nodes registries
		    iMDeps, iCMRelReg	in base agent. It keeps pointers to chromo nodes. But in DAA this will not work.</simpara>
		<simpara>Possible solutions would be:</simpara>
		<itemizedlist>
		    <listitem>To use thread safe chromo node identification, not pointer.</listitem>
		    <listitem>To use chromo independent validation procedure
			<para>Ref also <xref linkend="ds_th_mv"/></para>
		    </listitem>
		    <listitem>To use Original Sequence Mutation (<xref linkend="gls_osm"/>)
			<para>This approach avoids necessity of dependencies tracking. Ref <xref linkend="ds_mut_osm"/> for details.</para>
		    </listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_chrc"><title>Design issue: chromosome continuity</title>
	    <sect3><title>Intro</title>
		<simpara>In current implementation the models chromo is hierarchical structure where the owned nodes are attached to owning node. This 
		    looks like that models nodes have its own chromo, and nodes chromo is attached to the chromo of models nodes owner. So the
		    chromo is continuos. This simplifies saving the chromo and navigating thru it. But in distributed model this doesn't work directly.
		    The problem is that currently there is not mechanism provided for chromo nodes seamless communication as it is done for models 
		    nodes.</simpara>
		<simpara>In model there are thwo interrelated trees: chromo tree and model tree.</simpara>
		<simpara>The possible solutions here are:</simpara>
		<itemizedlist>
		    <listitem>To provide mechanism of chromo nodes communication.</listitem>
		    <listitem>To modify the approach of chromo parts attachment
			<para> to avoid attaching chromo nodes but use models nodes attachments
			    to keep continuity of chromo, i.e use "virtual" attaching. We also will call this "decoupled" chromo approach.
			    Ref <xref linkend="ds_daa_chrc_va"/> for details.
			</para>
		    </listitem>
		</itemizedlist>
	    </sect3>
	    <sect3 id="ds_daa_chrc_va"><title>"Virtual attaching (decoupled chromo): to avoid attaching chromo nodes but use models nodes attachments.</title>
		<simpara>How this approach can be implemeted. We need to keep mutation order in owner to keep supporting dependencies analyis
		    mechanism. So in Elem::AddElem we need to attach the "node" mutation. But it doesn't make sense to attach all the componet
		    tree because in any case we need to assemble chromo from the root. This is because the mutation of local model node causes
		    change on just this node chromo but doesn't affect owners chromo. So in Elem::AddElem we need to attach the "node" mutation
		    (i.e. components chromo) but not recursivelly: only to keep mutations order and supports dependencies.</simpara>
		<simpara>In what cases the nodes chromo isn't attached to owners chromo ? This happens for instance if the node is "inherited" from 
		    parent of owner, look at Elem::CreateHeir. It uses run-time mutation that doesn't attach the chromo. This "not attaching" fact
		    is used within the model to distinguish such nodes from nodes that created via "true" mutation. This means that to keep the 
		    current logic that uses this indication we need to have dedicated sign in models node of chromo isn't attached
		</simpara>
		<simpara>How to save the whole chromo ? Currently is saves by chromo utility. With virtual attaching this will not work. Possible
		    solution here is to create whole chromo from chromo parts in models nodes and then save it.</simpara>
		<simpara>In many cases the nodes chromo is requested and used assuming that the chromo is "whole" chromo. This is for instance when heir is
		    created from the node. But with vitrual approach is will not work. The solution here is to add method "GetChromo" to MElem that
		    creates chromo object and combines it from model owned nodes chromos.</simpara>
		<simpara>The procedure of combinign whole chromo is based on the relation between owners chromo [node] mutation and corresponding owners component.
		    This means that for each [node] mutation the owner can find the corresponding component, request the components chromo, and attach it to
		    [node] mutation.</simpara>
	    </sect3>
	    <sect3 id="ds_daa_chrc_re"><title>Vitrual attaching: is model node rank equivalent to chromo node "node" rank ?</title>
		<simpara>Model tree includes not only nodes created explicitl by the corresponding "node" mutation of chromo but also nodes inherited 
		    from parent. So models rank is not equivalent to chromo rank. We can make it equivalent if we take in account only attached models node.
		</simpara>
	    </sect3>
	    <sect3 id="ds_daa_chrc_rm"><title>Decoupled chromo: attaching chromo of removed component</title>
		<simpara>The whole agents chromo is combined from chromos of attached components, including not direct component in case of 
		    pheno modification. So the procedure is as: the agent iterates thru all its chromo mutation, in case if mutation is [node] then
		    gets the component, requests component full chromo and attaches it to the [node] mutation. This works ok in most cases but not
		    in case of removed node. Agent is not able to get removed comp in this case.</simpara>
		<simpara>The solution here could be improving agent navigation methos GetNode by adding filter to include/exclude removed comps from
		    the lookup. However there is a problem with this solution: multiple choice in case of removing node and create new node with same name.
		</simpara>
		<simpara>The possible solutions are:</simpara>
		<orderedlist>
		    <listitem>To allow multiple choice (i.e. GetNode to return a set of nodes)  and add GetNode method variant that returns iterator.
			<para>Resolving of rigt component can be done via analysis of nodes chromo root UID, ref <xref linkend="ds_mut_uid"/>.</para>
		    </listitem>
		    <listitem>To state the restriction: components name is to be unique, ref <xref linkend="ds_mut_nm"/>.</listitem>
		</orderedlist>
	    </sect3>
	    <sect3 id="ds_daa_chrc_rn"><title>Decoupled chromo: how to get chromo for renamed node ?</title>
		<simpara>There is the problem with implemeting of decoupled chromo in case of renaming node. The problem occurs with combining the 
		    full chromo. As was mentioned above (ref <xref linkend="ds_daa_chrc_va"/> the procedure of combining full chromo is based on relation
		    between owners [node] mutation and corresponding owners component. But this relation gets broken when the component is renamed.</simpara>
	    </sect3>
	    <sect3><title id="ds_daa_chrc_rln">Decoupled chromo: how to relate from owner [node] mut to corresponding model node chromo root</title>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_dec"><title>Design issue: dependency on execution context. Should remote env agent be server itself ?</title>
	    <sect3><title>Intro</title>
		<simpara>Currently the scheme of simple distribution based on dedicated agents (ref <xref linkend="ds_daa_proxy_crh_stx_agt"/>) is as following:
		    In primary model the dedicated remote environment agent is created (ARenv). As soon as content of this agent is set (content is the
		    URL of remote server) the agent connects to the remote server. As soon as some component of agent is specified via mutation, the 
		    agent issues request of creating the remote secondary environment with the component as root. The component is the child of another dedicated agent - 
		    remote environment upper agent, ARenvu. This agent is the point of communication back to the primary model. To establish this back
		    communication ARenv sets the secondary environment variables "primary env URL".</simpara>
		<simpara>The problem here is that ARenvu depends on type of primary env execution context. So if we have more than one type of execution context
		    (for instance INET socket based and pseudo async loop based) it will not be possible to specify the model independently on execution contex. By another
		    words the model has to be created for the particular execution context.</simpara>
		<simpara>So the origin of this problem is that DAA needs two-ways communication between primary and secondary enviroments, so both envs have
		    to be "compatible" with remote env agents. There is the question related to this fact: do we actually need the server above env level? This 
		    approach is used currently, so remote env agent in primary env communicates to server owning secondary env. But what if we "move" the 
		    communications inside remote env agents? This would make the remote env agent on secondary side independent on "nature" of primary env.
		    This secondary Renvu agent will be dependent only on it's counterpart in primary env. According to this approach the remote agents get
		    "active" subjects of communication. Ref <xref linkend="ds_daa_dec_arenv"/> for outline and analysis of this approach.</simpara>
	    </sect3>
	    <sect3 id="ds_daa_dec_arenv"><title>Outline of "active" remote env agents.</title>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_ao"><title>Getting notification from model. Agent observer: </title>
	    <sect3><title>Intro</title>
		<simpara>There is base agent API "SetObserver" to connect observer for pushing notification of agents status. Currently there is a 
		    problem with using this API with unified call. Implementing this
		    API differs from implementation of main part of base agents API: observer itself is the object "outside" the model. For "regular" case
		    the argument of unified call is ID to agent in form of URI. The agent can resolve this ID with using its own mechanism (for instance
		    GetNode in case of URI). For remote agent resolved the agents proxy will be created by dedicated agents supporting distrtibuted modes.
		    But we cannot use URI for identifying "external" agent observer instance. Instead, we need to use ID in form 
		    [back_server_uri, observer uid]. So we need specific mechanism for resolving such kind of "external" objects.</simpara>
		<simpara>There can be two approaches considered:</simpara>
		<orderedlist>
		    <listitem>Using dedicated agent observer proxy creator on server session level (Sesssion leve proxy - SLP). 
			<para>In this there should be session's specific API for creaitin proxy and connect it to given agent: server session creates proxy and
			    runs direct base agent API SetObserver.</para>
		    </listitem>
		    <listitem>Add API to DES env in order to resolve "external" object such as agent observer and create proxy
			(Resolving external objects Env API and create proxy - REOP).</listitem>
		    <listitem>Add API to DES env in order to resolve "external" object such as agent observer
			(Resolving external objects Env API - REO).
			<para>In this approach Env just provides base agent with external object by ID but not creates proxy. This doesn't adapt Env API to
			    DAA but resolve the lack in unified call mechanism.</para>
		    </listitem>
		</orderedlist>
		<simpara>Ref <xref linkend="ds_daa_ao_sper"/> for comparision of this two approaches.</simpara>
	    </sect3>
	    <sect3 id="ds_daa_ao_sper"><title>Session level proxy (SLP)  vs Env resolving external objects API (REO) vs REOP</title>
		<simpara>The simplest use case is just to create model remotely, where some client request server session to create model and want
		    to connect clients own agent observer to some agent of the model. In this case model doesn't contain DAA specific agents at all. So we
		    would like to avoid any DAA specifics here. REOP requires some modification in Env and base agent, that contradicts this wish.</simpara>
		<simpara>On another hand, REO doesn't contradicts. REO isn't alternative at all, it is just enhances SLP, where base element has 
		    convenient way to handle unified call with external object in arguments.</simpara>
		<simpara>DECISION: initially use SLP withot using unified call, then introduce REO and migrate to unified call</simpara>
	    </sect3>
	    <sect3 id="ds_daa_ao_lppp"><title>Long Polling vs Point-to-Point</title>
		<simpara>Distributed model uses two-way interactions to communicate between parts of the model. Currently Point-to-Point approach is used
		    for "back" communication from secondary model to primary model, see also analysis in <xref linkend="ds_daa_dec"/>. Similar design
		    problem is also for communicating from model to "primary" DesObserver. This case clearly correspond common case of "push" type
		    communication from server to its client. Taking this into account in observer case we can see the resonable alternative -
		    Long polling approach.</simpara>
		<simpara>This approach idea is the client uses regular session to make request to the server for notification. Server in this case 
		    not nesessarily response immediately but can defer the response till notification event happens. What approach is to be used?</simpara>
		<simpara>Long poll scheme is outlined on diagram below:</simpara>
		<figure id="fig_daa_lppp"><imageobject> <imagedata fileref="pics/long_poll_observer.png"/> </imageobject></figure>
		<simpara>Point to point scheme is outlined on diagram below:</simpara>
		<figure id="fig_daa_ptp"><imageobject> <imagedata fileref="pics/pic_daa_ptp.png"/> </imageobject></figure>
		<simpara>Currently the decision is to use Point-to-Point approach as more compatible with the DAA philosofy.</simpara>
	    </sect3>
	    <sect3 id="ds_daa_ao_lppp_shr"><title>Agents observer PtP approach: server shared resources</title>
		<simpara>The current scheme of server owned resources is rather inconvenient for Agent observer PTP solution.
		    The scheme is that env is owned not by the server but by the session that created the env. The current
		    solution is based on "attaching" client to the session "owning" env. This solution is ambiguous. More 
		    direct solution would be not attaching the client but allow client access to the env. This can be done by
		    moving env ownership from session to server, where all the session can potentially access it.</simpara>
	    </sect3>
	    <sect3 id="ds_daa_ao_prb"><title>Problem with agent observer on DAA model</title>
		<sect4><title>Intro</title>
		</sect4>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_owr"><title>DAA: server owning resources approach</title>
	    <simpara>Use-cases</simpara>
	    <orderedlist>
		<listitem>Client requests creating Env
		    <para>The question is where the context is keept. Currently the context is owned by session created env.
			Seems this is correct, because context obviously relates to the session: this is context of request.
		    </para>
		</listitem>
		<listitem>Client requests attaching to the existing Env
		    <para>How can we identify the env session to be attached to? Currently within the scope of session
			we use predefined context for the env. But as we stated before the context is local for session so 
			we cannot use env context with new session (the valid context is accessible only from the session that 
			created this env. So dedicated identification of env is required.</para>
		</listitem>
	    </orderedlist>
	    <sect3><title>Design solutions summary</title>
		<orderedlist>
		    <listitem>All server resources (env, observers etc) are shared by server, i.e allowed by all clients.  </listitem>
		    <listitem>Resource is owned by its creator, for instance session created an Env is owning it.</listitem>
		    <listitem>Resources are shared via common MIface registry - there is server resources keyed registry shared to clients
			<para>Resource creator registers created resource in this registry.</para>
		    </listitem>
		    <listitem>There is resources provider iface/impl on server, so resources can be generated via resource type.</listitem>
		    <listitem>There is server API to add resource provider, so server owner can customize resources.</listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>Design items</title>
		<orderedlist>
		    <listitem>We need to extend URI in order to be able to locate agent in particular server and env.
			<para>The matter is that potentially now it gets possible for client to create more than one env. So
			    client should be able to address the agents distinguishly in both env even the agents URLs within the env 
			    are equivalent. Ref <xref linkend="ds_base_03"/> for URI related desing item.</para>
		    </listitem>
		    <listitem>Server resources identification
			<para>Identification can be based on location in hierarchy how it is implemented for agents. The 
			    hierarchy currently is just linear. So we need to give unique name to resorces.</para>
		    </listitem>
		</orderedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_irm"><title>DAA desing: Interface resolution</title>
	    <sect3><title>Intro</title>
		<simpara>Currently (20160629) the iface is resolved by server session with iface Id (or context) received in request. The mechanism
		    of resolution is simple - the session has register of ifaces where the key is Iface Id. This scheme in fact is rather week. 
		    More solid solution would be direct resolution, where Iface Id acts as URI that can be used to find iface impl within the 
		    model.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_log"><title>DAA: logging</title>
	    <sect3><title>Intro</title>
		<simpara>The use-case is: in distributed environment where secondary environments are created by primary env
		    the primary env gets logs from secondary environments and combine the records in single log.</simpara>
	    </sect3>
	    <sect3><title>Solution: remote root in secondary env to redirect log records to the logger in primary env.</title>
		<simpara>Pros of this solution is that it's aligned with the principle where specific remote agents (ARenvu in out case)
		    are responsible for all communications between primary and secondary model parts.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_pxdup"><title>DAA design issue: dupicating of agents via proxy in the same env.</title>
	    <simpara>Currently it is possible that the proxy gets created pointing to agent in the same environment. The case is 
		outliend in the diagram below. Agent "Comp" from secondary env requests getting node Renvu by absolute URI. So it firsly get
		root (this will cause creating proxy Px%Root in env#2) and then requests root to follow the absolute path. On final step
		REnv returns Uid of Px%Renvu to env#2 so proxy Px%Px%Renvu is created that is the dup of real Renv agent. </simpara>
	    <figure id="fig_daa_px_dup"><imageobject> <imagedata fileref="pics/pic_daa_px_dup.png"/> </imageobject></figure>
	    <simpara>This creates the problem in many cases. For instance when we request "Comp" to get relative URI basing from
		Revnu, "Comp" requested the base and gets it in the form of proxy Px%Px%Renvu. There is logic in GetUri:</simpara>
	    <programlisting>if (iMan != aTop) { ...</programlisting>
	    <simpara>Actually iMan and aTop should be the same, but aTop is proxy, so the pointers differ.</simpara>
	    <sect3 id="ds_daa_pxdup_sir"><title>Proposed solution</title>
		<simpara>Possible solution would be to avoid such a duplication when creating proxy  - the proxy creator should
		    check if there is primary UID in the current model and to use this primary UID instead of proxy UID. Checking primary UID can
		    be done with utilizing the fact that the UID is based on ablolute local URI of the agent. Ref <xref linkend="ds_irm"/> for
		    improvement mechanism of iface resolution by UID.</simpara>
	    </sect3>
	    <sect3 id="ds_daa_pxdup_birc"><title>Bug: iface Uid isn't resolved correctly in case of OSM linear chromo of remote part.</title>
		<sect4><title>Intro</title>
		    <simpara>This issue is reproduced on rev d78e076bebd. Iface resolution was implemented already, ref <xref linkend="ds_daa_pxdup_sir"/>.
			The problem is occuring when linera OSM chromo is used for creating remote model (reproduced on studio example daa_syst.xml).</simpara>
		</sect4>
		<sect4><title>Analysis</title>
		    <simpara>The rootcause is that remote root iface Uid is generating incorrectly when remote root is just created but not
			activated (connected) yet (the activation is done via separate cont change mutation). The matter is that for 
			Uid generation is used:</simpara>
		    <programlisting> GetUri(iEnv->Root()->GetMan(), ETrue); </programlisting>
		    <simpara>But just after remote root creation (w/o activation) remote root doesn't have owner so in result the absolute uri is 
			applied as Uid. This causes to error when iface resolution searches the iface with such Uid. For instance we can use
			the algorithm:</simpara>
		    <programlisting> GetUri(iEnv->Root(), ETrue); </programlisting>
		    <simpara>This will not show the name of root in the Uid but will be unified and simple. The according change is needed in 
			the iface checking method of environment iface resolver, ref <xref linkend="ds_irm"/>.</simpara>
		</sect4>
		<sect4><title>Proposed solution</title>
		    <simpara>We need to use Uid generation algorithm independent of the status of remote model. It makes sense to use relative URI from 
			env root node.  This is because the root is as "invariant" within the enviroment's native owning hier.</simpara>
		</sect4>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_ttm"><title>DAA design issue: tree-type mutation as unified call argument</title>
	    <sect3><title>Intro</title>
		<simpara>Currently there is base agent iface MElem method:
		    <programlisting> ChromoNode AppendMutation(const ChromoNode&amp; aMuta) </programlisting>
		    The problem is that serialization of ChromoNode is rather tricky especially in case of three-type node.
		    There is also similar method:
		    <programlisting> void AppendMutation(const TMut&amp; aMut) </programlisting>
		    that uses TMut having convenient serialization. But this method cannot be used to append three-type mutation.
		</simpara>
		<simpara>
		    Where the appending of three-type mutation happens? This happen for instance in Elem::DoMutation():
		    <programlisting>
			if (ftarg != NULL) {
			ChromoNode madd = ftarg->AppendMutation(rno);
			madd.RmAttr(ENa_Targ);
			ftarg->Mutate(...
		    </programlisting>
		    in cases when the chromo includes three-type mutations.
		</simpara>
		<simpara>There was migration done from tree-type chromo to flat chromo implementing <xref linkend="gls_osm"/> approach.
		    In case of true OSM chromo (flat chromo) the only single (not tree-type) mutations are appending via AppendMutation.
		    But we still keep the possibility of treating tree-type mutations for compatibility purpose.</simpara>
		<simpara>Where tree-type mutations are used? The cases are:</simpara>
		<orderedlist>
		    <listitem>In node import</listitem>
		    <listitem>In inserting of saved chromo
			<para>The chromo itself is tree-type even there are only 2-layers in case of OSM chromo: root and other mutations.</para>
		    </listitem>
		</orderedlist>
		<simpara>So there are some options here:</simpara>
		<orderedlist>
		    <listitem>To implement convenient serialization of tree-type ChromoNode</listitem>
		    <listitem>To enable OSM chromo only
			<para>I.e to deny comptibility with hierarchical chromo. In this case all the mutations will be single mutations
			    and the method ppendMutation(const TMut&amp; aMut) can be used in all places.</para>
		    </listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>Proposals</title>
		<simpara>The proposal is to implement serialization of tree-type chromo. This should unblock the further model improvement.
		    But as long term the "OSM chromo only" approach is preferred. We need to re-design importing mechanism in order to allow
		    OSM in modules also, ref <xref linkend="ds_mut_osm_imp"/>.
		    This new mechanism could be based on run-time modules resided in some DES server.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_ina"><title>DAA design issue: native agent cannot get unif call arg by UID</title>
	    <sect3><title>Intro</title>
		<simpara>Iface's UID is used currently for identification of iface. UID itself is based on native hier - it includes iface's node
		    absolute URI in order to navigate to it. But there are some cases where this approach doesn't work. For instance in case of native agents.
		    For native agents absolute URI doesn't work currently, ref. <xref linkend="ds_di_nacgna"/>.
		</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_hunv"><title>DAA desing issue: heir UID is not valid on heir creation phase</title>
	    <sect3><title>Intro</title>
		<simpara>In CreateHeir() method of Elem and MElemPx heir is not really inserted to owning hier, owner just is set for it
		    (but it is not adding comp to owner but one-side relation owned-owner. With this one-side relation it is possble to get heir's URI
		    (i.e. genarate UID), but not possible to get node by this UID. For local model it doesn't cause any problem, but in 
		    distributed model it leads to error in getting proxy by UID, particularly on: </simpara>
		<programlisting>
		    MElem*  MelemPx::CreateHeir(const string&amp; aName, MElem* aMan)
		    ...
		    AppendChild(heir);
		</programlisting>
		<simpara>The situation seems serious for the case if in CreateHeir the new owner is remote node. In this case to append comp to 
		    remote owner we need to make request passing heir's UID, but UID is not resolvable because heir doesn't have owner yet.
		</simpara>
		<simpara>Ref also <xref linkend="ds_daa_hunv_osm"/> for another issue with UID</simpara>
	    </sect3>
	    <sect3 id="ds_daa_hunv_sl"><title>Solutions</title>
		<simpara>Solution <xref linkend="ds_daa_hunv_slr"/> was applied. But it was realized that this solution doesn't solve the problem
		    completely. It fails in case when some agent A is creating and in scope of this is creating inherited comp B of A. AppendChild is 
		    created for parent of B after B gets created but because creation of A in not completed (i.e. A isn't registered in hier solidly)
		    the UID of B cannot be resolved, ref <xref linkend="ds_di_cnfr"/> for details.</simpara>
	    </sect3>
	    <sect3 id="ds_daa_hunv_slr"><title>Solution: "ligth" relations on heir creation phase</title>
		<simpara>The potential solution would be to avoid of using any requests required UID before heir is not finally included into owning hier
		    (the base condition of UID generation). How to avoid? The only such request is AppendChild() in CreateHeir(). But we can avoid
		    this AppendChild() - in fact the "solid" two-ways inheritance relation is not necessary here, just "light" relation is enough. This 
		    approach is already using for owning relation - only one-way relation is set in agent's constructor. Actually it is enough to
		    allow agent request nodes duing mutation.</simpara>
		<simpara>Note: this solution doesn't actually solve the problem, ref <xref linkend="ds_daa_hunv_sl"/>.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_hhb"><title>DAA desing issue: heir hier gets broken in case of distribute inheritance</title>
	    <sect3><title>Intro</title>
		<simpara>In DAA the remote inheritance (i.e. when parent is located in remote env) currently is based on the approach where the parent
		    created heir evolves back the inheritance chain in form of proxies of real nodes in inheritance chain, but the final node of chain
		    (native agent) is obtained from local env provider. Generally it works, but the problem is </simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_powrd"><title>DAA design issue: Proxies one-way relations cannot support safe model deletion.</title>
	    <sect3><title>Intro</title>
		<simpara>There was two-ways relation used in base model env: owner-owned and parent-child. Node's deletion secure proper mechanism 
		    of relations breaking. This mechanism is basing on notifications that are issued by the node playing inferior role: 
		    from child to parent, from component to owner. In case of distributed model the only one-way relations are esatblished
		    between MElem proxy and Elem agent.
		</simpara>
	    </sect3>
	    <sect3><title>Analysis</title>
		<simpara>Please note that proxies are deleted first when secondary env is deleted (ref ARenvu agent).</simpara>
		<simpara>Consider parent-child relation. Let's assume [P] is parent in primary env, [PP] - MEelm proxy of [P] in secondary env,
		    [C] - remote child in secondary env, [CP] child's proxy in primary env. What happens if [PP] gets removed? On one hand we
		    need to notify [C] of parents removal, so [C] can reset relation to parent (please note that this requires two-ways relation
		    between [C] and [PP]. But what happens then if [P] get removed?
		    [P] will notify [C] via [CP] of parent removal, that seems weird, because [C] already got such an notification from [PP].
		    This shows that two-ways relations between Elem and Proxy is wrong way.
		</simpara>
		<simpara>Another way is that [PP] notifies [P] of child deletion (because [PP] is actually child [C] representation in 
		    relation to [P], i.e. direction where [PP] can act via requesting).</simpara>
	    </sect3>
	    <sect3><title>Use-case: MElem proxy - parent removal; child cannot get EType()</title>
		<orderedlist>
		    <listitem>Actors are:
			<programlisting>
			    [P] - parent, MElem proxy
			    [C] - child, Elem
			</programlisting>
		    </listitem>
		    <listitem>[P] is being deleted, [P] notifies [C] on deletion of parent, [C] reset relation to parent</listitem>
		    <listitem>Relation to parent supports some MElem API, for instance EType. Now this API will not work.</listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>Solution</title>
		<simpara>We need to complete deletion the model in a normal way. This means that we need to keep the proxies alive during
		    model destruction process. This can be done via kind of trick - to initiate in Renv/Renvu destructor components removal
		    before deleting proxies manager. This approach required dedicated request of deletion in MElem in order to 
		    distinct MElem C++ destructor (that also works in MElem proxy) and MElem deletion.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_rdo"><title>DAA design issue: root elem double ownership in secondary env</title>
	    <sect3><title>Intro</title>
		<simpara>In distributed env the secondary environment has pecularity, namelly that root agent ownership is shared between env
		    and root owner in primary env. This causes the problem on distributed model destruction: both owners are trying to delete root.</simpara>
	    </sect3>
	    <sect3><title>Solution</title>
		<simpara>Actually the interaction is as: owner in primary env request root deletion first, the secondary env tries to 
		    delete root on the final phase of destruction. So we can add to MEnv the notification of root deletion so the env understand
		    that it shouldn't delete root.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_hunv_osm"><title>DAA desing issue: remote heir UID is not valid on heir creation phase with <xref linkend="gls_osm"/> approach and
		treeish chromo used.</title>
	    <sect3><title>Intro</title>
		<simpara>There was initial problem with heir Uid not valid, ref <xref linkend="ds_daa_hunv"/>.
		    Solution (ref <xref linkend="ds_daa_hunv_slr"/>) was implemented and verified on treesh chromo. But the problem returned
		    again on <xref linkend="gls_osm"/> (ref <xref linkend="ds_mut_osm"/>) implemented (rev 44ef95c5d9c888).</simpara>
		<simpara>One of the scenafios is creating remote agent (REnvu agent based) and activating it (i.e. changing the content that causes
		    connection of the agent), ref (fap2-srv/test/ut_bidir_cre.xml). The treesh form of remote chromo is used (OSM still
		    allows that) than the mutation of changing the content is executed in the scope of creation remote root (REnvu child). The change content
		    mutation sequence is like this: </simpara>
		<itemizedlist>
		    <listitem>Remote root mediator (primary env REnv heir) overloaded mutation handler AddElemRmt is called - creates remote env,
			and requests constructing remote model from the given chromo (actually the treesh form).</listitem>
		    <listitem>Remote env creates the root (REnvu heir), sets its cromo to root and initiates root mutation.</listitem>
		    <listitem>The first mutation is changing content of root - it is for activating the root. The base agent mutation handler is used.</listitem>
		    <listitem>REnvu ChangeCont virtual method is called first - this causes remote root (REnvu) connection to primary env, so remote
			root gets its owner (remote root mediator) assigned.</listitem>
		    <listitem>Base agent cont change mutation handler calls notification OnCompMutated to the owner. </listitem>
		    <listitem>Remote root mediator gets notification, it starts handling it and tries to get the comp (actually its proxy) by UID. But
			note the mediator doesn't register remote root as the comp yet.</listitem>
		    <listitem>Remote root mediator AddElemRmt waits until the remote model full creation and only after that creates the proxy
			of remote root and registers it as component.</listitem>
		</itemizedlist>
		<simpara>The mediator's attempt of getting the comp fails because the comp is not registered yet - this causes the model's crash.</simpara>
	    </sect3>
	    <sect3><title>Analysis</title>
		<simpara>It's seen from the sequence above that the problem origin is incorrect design of DAA implementation in case of using treeish chromo
		    for remote env.</simpara>
	    </sect3>
	    <sect3><title>Solutions review</title>
		<simpara>There are the following solutions to be considered:</simpara>
		<orderedlist>
		    <listitem>To notify the mediator of remote root creation as soon as connection is established.
			<programlisting>This would establish two-ways relation between primary env remote root mediator and secondary env remote root as early
			as possible so remote root will be accessible via UID.</programlisting>
		    </listitem>
		    <listitem>To avoid establishing any relations between mediator and remote root until remote model construction complete.
			<programlisting>This will isolate construction of remote model from the primary env, so no one request from remote model will
			    be recieved by the primary env. Ref <xref linkend="ds_daa_hunv_osm_nas"/> for details.</programlisting>
		    </listitem>
		    <listitem>To avoid using treeish chromo in distributed models, ref <xref linkend="ds_daa_hunv_osm_aut"/> for details.</listitem>
		</orderedlist>
	    </sect3>
	    <sect3 id="ds_daa_hunv_osm_nas"><title>Proposed solution: to notify the mediator of remote root creation as soon as connection is established.</title>
	    </sect3>
	    <sect3 id="ds_daa_hunv_osm_aer"><title>To avoid establishing any relations between mediator and remote root until remote model construction complete</title>
		<sect4><title>Disadvantages</title>
		    <simpara>There are some use-cases below</simpara>
		    <itemizedlist>
			<listitem>Creating agents from the parents located in primary model. This required at least one-way (sec-to-pri) relation. This
			use-case is quite valuable for creating DAA models.</listitem>
		    </itemizedlist>
		</sect4>
	    </sect3>
	    <sect3 id="ds_daa_hunv_osm_aut"><title>To avoid using treeish chromo in distributed models.</title>
		<sect4><title>Disadvantages</title>
		    <itemizedlist>
			<listitem>Using OSM chromo requires interaction between model parts for each mutation. Threeish chromo allows partially isolate the 
			    creation process within secondary env, that speeds up the process.</listitem>
		    </itemizedlist>
		</sect4>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_itn"><title>DAA design: Identification of temporary nodes (generating/resolving UID for them)</title>
	    <sect3><title>Intro</title>
		<simpara>There is specific kind of nodes - temporal. They ara those nodes that are in the process of creation so not attached to native hier.
		    This means that UID of such nodes are not valid - it cannot be resolved properly.
		    In monolitic model there are no problems with such agents - all interactions involved such agents use direct ref to the agents. But
		    in distributed model many problems are discovered regarding temporary agents. There were already some discusson regarding the similar
		    scenario/issues, ref <xref linkend="ds_daa_hunv_osm"/>,
		    <xref linkend="ds_daa_hunv"/>, <xref linkend="ds_di_cnfr"/> (note that they are partially overlap one another).</simpara>
		<simpara>There are a number of solution proposed and tried. At the moment it seems that the only apprach <xref linkend="ds_di_cnfr_siurm"/>
		    is solid one.
		</simpara>
	    </sect3>
	    <sect3><title>Analysis</title>
		<simpara>The root-cause of the project is that we try to use to treate the temporary node as the regular node. But temp node is not identified.
		    Without initial identification we cannot even attach the node in distributed model because it can be that the temp node from one part of
		    distributed model is to be attached to the node from anoter part - this required "long" request using node UID.</simpara>
		<simpara>So, we need to support temp nodes in procedure like getting nodes etc. Impotrant use-case is getting node that is comp of temp node.
		    Such support means that we need to identify temp node and support this identification is UID scheme (because all the methods of getting
		    node used UID).
		</simpara>
		<simpara>There are two options for identifying temp node:</simpara>
		<itemizedlist>
		    <listitem>To use real UID, it will be changes with node movement.</listitem>
		    <listitem>To use final UID i.e. UID that heir will have on creation process completed, ref <xref linkend=""/></listitem>
		</itemizedlist>
	    </sect3>
	    <sect3 id="ds_daa_itn_sfu"><title>Solution: To use final UID i.e. UID that heir will have on creation process completed.</title>
		<simpara>Ref also <xref linkend="ds_di_cnfr_siurm"/>. Note, that this UID is actually incorrect during the node movement.
		    This incorrectness can be worked around with specific mechanism of resolving such UID. For instance provider or env can keep such temp nodes
		    register. So the last node in UID (this will be the node future owner) will get error on attempt of resolving the nodes - in that case the 
		    last node can check with env (or whoever keeps the register) if this is UID of temp node registered. Advantage of this approach is that
		    it effectively support the heir node transition to context of parents from parent's chain.</simpara>
	    </sect3>
	    <sect3 id="ds_daa_itn_sfo"><title> Solution: to use final owner in base agent. The final owner is the agent that initiates creation of new agent.</title>
		<simpara>
		    The created agent is immediately registered in this final owner. The created agent also sets it's own attribute "Mutation Context" as pointer to
		    owner used on the current stage of heir creation. This attribute is used when getting the nodes in the scope of the mutations.
		    GetNode() method needs to be updated in order to check if mutation context is defined for the node and using it if so.
		    So the node beeing created has persistent relation to final owner. The node
		    will seem regular node - it can be identified by persistent Uir and can be  get by this Uri. The same time the temp node will attach the
		    contexts of parents as owner. This allows the node to be within the context when being created - this means all the request from inside the
		    node will go thru the context, but not thru final owner.	
		</simpara>
		<simpara>This solution doesn't solve some special cases, ref <xref linkend="ds_di_ndnac"/></simpara>
		<simpara>Ref also <xref linkend="ds_mv_local_wkc"/> for mutation context using when moving node.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_daa_iss"><title>DAA Design issues to be considered</title>
	    <orderedlist>
		<listitem><xref linkend="ds_daa_md"/></listitem>
		<listitem><xref linkend="ds_daa_chrc"/></listitem>
		<listitem><xref linkend="ds_daa_irm"/></listitem>
	    </orderedlist>
	</sect2>
	<sect2 id="ds_daa_umm"><title>[DS_P] Using Unified messaging mechanism in DAA</title>
	    <sect3><title>Intro</title>
		<simpara>Two kinds of agents interaction are used currently: CPP native and messaging. CPP native is just CPP interface (set of functions assosiated
		    to specified object-interface). Messaging is set of text-based messages assosiated to specified object-interface. Both of the methods use native 
		    access to the native objects - one agent uses pointer to another agent (CPP object) to interact. So agents currently are CPP objects.</simpara>
		<simpara>In DAA this approach leads to necessity of using of agents proxy in order to provide the model with "normal" agent representing remote
		    agent that is not accessible from local environment.</simpara>
		<simpara>We can consider another approach that uses dedicated messaging mechanism in the environment for agents interactions. It this case
		    agent "nature" is not important - the agents don't use direct native access one to another. Messaging mechanism also "hides" the way of 
		delivering message, so there is no diffrence between agents interaction within local environment and in distributed model.</simpara>
	    </sect3>
	    <sect3><title>Why we don't use messaging approach?</title>
		<simpara>The main problem of multi-agents models is how the model is run on interpretating environment. The mechanism of interpretation has to be
		    effective in order to apply the models in real applications. Thats why we use agents model projection to native language (CPP) model - this
		    minimise the agents interactions.</simpara>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_nas"><title>Natively asynchronous model.</title>
	<sect3><title>Intro</title>
	    <simpara>Current DAA approach actually isn't asyncronous. On native layer it is still sync. Asynchrony in DAA can be implemented on 
		DES layer, this is specific kind of asyncrony - cooperative one. It would be more interesting to have asynchrony on native level.</simpara>
	</sect3>
    </sect1>

    <sect1 id="ds_chr"><title>Chromo language. Representation, serialization etc.</title>
	<sect2><title>Refs</title>
	    <biblioentry id="ref_fi"> <abbrev>FI</abbrev>
		<productname><ulink url="https://en.wikipedia.org/wiki/Fast_Infoset"/></productname>
		<title>Fast Infoset</title> </biblioentry>
	</sect2>
	<sect2 id="ds_chr_nc"><title>New compact chromo language</title>
	    <sect3><title>Intro</title>
		<simpara>The current chromo language is the result of straightforward approach to chromo as spec of system mutations. So
		    we didn't much care of such chromo language capabilities as compactness, expressivenes etc. In result the chromo itself can hardly
		    be used as object of system design - the only visual representation is enough suitable for the design.</simpara>
		<simpara>The aim of chromo languge enchancement is making it more "readable" in terms of understanding the system from it's chromo.</simpara>
	    </sect3>
	    <sect3><title>Main points</title>
		<orderedlist>
		    <listitem>To introduce relation as element of base model
			<simpara>At the moment the only element is an atom of the system. Thus any relations are just specific elements. On one hand this makes
			    the model very simple. On another hand it makes chromo (system spec) pleonastic. So the proposal is to extend the base model by 
			    relations of nodes.</simpara>
		    </listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>Relations tree notation</title>
		<simpara>The problem here is what would be notation for relations tree. For instance is transition function. It can be described by hierarchy of 
		related functions. What would be compact notation for it?</simpara>
	    <simpara>On variant is to use the scoping notation. Lets state that the scope is denoted by "{" "}" then the hier
		<programlisting>
		    a - a1
		    a - a2
		    a1 - a11
		    a1 - a12
		    a2 - a21
		    a2 - a22
		</programlisting>
		can be denoted as:
		<programlisting> a { a1 {a11 a12}  a2 {a21 a22} } </programlisting>
	    </simpara>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_irm"><title>How to improve iface resolution mechanism</title>
	<sect2 id="ds_irm_intro"><title>Intro</title>
	    <simpara>Currently we have two ifaces design and three resolution mechanism:</simpara>
	    <orderedlist>
		<listitem id="ds_irm_intro_im">Initail mechanism - local iface resolution
		    <para>It was initially introduce in multiagents model: the "Base" CPP iface was introduced that assumes that Base implementation
			can implement any ifaces also and embed theirs resolution by iface name (i.e. iface type, static prop of iface).
			The abstract method "DoGetObj" was added to "Base" iface for that. There was not dedicated CPP iface for iface introduced on
			initial stage. DoGetObj just returns ptr to void so the Base cient is responsible to do proper cast the returned value to
			iface requested.</para>
		</listitem>
		<listitem>Topology specified resolution
		    <para>This mechanism is used to resolve iface globally depending on context (topology) of requested agent. This is key part
			of multiagent system.</para>
		</listitem>
		<listitem>Mechanism introduced in the scope of <xref linkend="gls_daa"/> implementation.
		    <para>In the scope <xref linkend="gls_daa"/> the elementary CPP iface "MIface" was introduced for agents ifaces. This MIface
			exposes method "Call" for unified request to iface and methods "Uid" and "Mid" for identifying. In fact all agents ifaces should
			inherit this core "MIface" iface. This elementary iface was introduce in order to enable agents communication within distributed
			environment. This idea was to implement the communication between distributed parts as remote procedure, that greatly simplifies the
			overall <xref linkend="gls_daa"/> implementation. To do that we need to have thus object of remote call - this is elementary iface
			that supports unified remote call method "Call". Then we need to uniquely identify the remote call object - this is done vis 
			introducing elementary iface method "Uid". Finally we need to provide the communincation layer (currently des server session) with
			simple mechanism of resolution of remote call object. This resolution mechanism currently (20160501) is implemented on server
			session vis map with iface UID as key. But this solution seems not good. The better would be to implement iface resolution mechanism
			on env or even base agent level. Because we already have initial mechanism of resolution implemented (ref <xref linkend="ds_irm_intro_im"/>)
			it makes sense to improve the mechanism in order to support full iface resolution.</para>
		</listitem>
	    </orderedlist>
	    <simpara>Full iface resolution mechanism is required for instance to avoid creation of proxies duplicating original local iface,
		ref <xref linkend="ds_daa_pxdup"/></simpara>
	</sect2>
	<sect2 id="ds_irm_fil"><title>Global iface resolution</title>
	    <simpara>The iface resolution required for <xref linkend="gls_daa"/> is similar to existing local iface resoluton implemented in base agent
		(ref <xref linkend="ds_irm_intro_im"/>. The only difference is that the former should resolve iface in native hier tree. Why
		we need such "extension" of local iface resolution? This is because this mechanism is used for remote call but the remote call mechanism
		is implemented "above" the model. So to specify the object of remote call we need to specify the agent first and then the iface of agent (local
		iface). We will call iface resolution using for <xref linkend="gls_daa"/> as "global resolution" in contrast of local iface resulution.
		Correspoidingly we will say that MIface UID is iface "global" identifier in contrast of iface type - identifier using for local iface
		resolution. So global iface identifier currently is combined from agent URI (ogent identifier in the current env) and local iface identifier
		(iface type). To be exact this global identifier is not global in scope of the whole distributed model but only in the scope of environments that
		combine the whole model. Do MIface UID is the identifier that allows iface resolution in the scope of environment. Potentially we can
		introduce "true" global identifier (GUID) that allows to resolve iface in global scope (in the scope of the whole distributed model).</simpara>
	    <simpara>What should be UID in case of proxy? For proxy it gets a bit complicated to create UID. The first part of UID is clear - it should be
		URI to the proxy manager. What next? In fact proxy manager can have more that one proxy with the same local iface. So the second part would
		be proxy UID in the scope of proxy manager. It can be proxy context for instance. The context is unique within proxy manager scope so
		can be used for proxy identifier. It is clear that with this approach we have to specifically implement proxy manager local iface
		resolution because the UID actually gets not truly local but needs look up to the owned proxies too.</simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_mi"><title>Model representing to the client: effective interface of multi-agent model.</title>
	<sect2><title>Intro</title>
	    <simpara>Currently the model publish to the client a series of native and unified (via MIface::Call) interfaces
		in order to allow client to interact to the mode. But the main iface for communication is MElem allowing to browse
		into the agent components and inheritance chain. In fact the client, i.e. Studio uses MElem for understanding if 
		the agent is sutable for UI representation. Studio performs that via analysis of agents inheritance chain. But this
		approach is not solid and doesn't work.</simpara>
	    <simpara>The example is SockErp embedded representation. The representation declares support of :Elem:Vert:Socket agent,
		so it doesn't support of :Elem:Vert:SocketMc (counterpart of Socket, but armed with multicontent supported agent
		ASocketMc.</simpara>
	    <simpara>This examples shows that the idea of using inheritance chain as the criteria of compatibility is not correct.
		What would be correct approach? This section is dedicated for discussion of effective approach of model representing to
		the client.</simpara>
	</sect2>
	<sect2><title>Set of native interfaces as model representation to the client.</title>
	    <simpara>Anycase the interface shall be declared and publish set of ways of interaction to the model. Currently there
		are native (C++) and unified (of text form) interfaces used. Seems this is enough at the moment. The only improvement
		that we need is to cover by ifaces all the model behaviour. This will allow us to use ifaces exposes by the agent as
		criteria of compatibility for the client.</simpara>
	    <simpara>The idea is that agent exposes a set of ifcases. There is assumption that ifaces are kind of elementary, so 
		each iface doesn't cross to others or depend on others. So the whole agent iface is combined from thiese elementary
		ifaces like the big pazzle is combined from many small peaces. We can say that elemenary ifase is "orthogonal" to other
		elementary ifaces. We can call this approach poly-iface.
		The question is if it's possible to create such full ifase from a set of elementary ifaces.</simpara>
	</sect2>
	<sect2 id="ds_mi_rm"><title>Poly-iface approach and iface resolution mechanism.</title>
	    <simpara>With poly-iface approach the key role plays the mechanism of iface resolution. Currently two mechanism are
		implemented:</simpara>
	    <orderedlist>
		<listitem>Local iface resolution</listitem>
		<listitem>Global iface resolution</listitem>
	    </orderedlist>
	    <simpara>Local method cannot be used because often the iface implementor is embedded agent (placed in Agents node).
		Global method is also not acceptable for relolution because it can obtain remote iface. Actually we need the method being
		near to global but limited only by local context, i.e. looking at the iface just in agent itself locally or 
		in agent embedded agents.
	    </simpara>
	    <simpara>Decision: to update local iface method in order to also look up in embedded agent.</simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_rpr"><title>Re-parent of node</title>
	<sect2><title>Intro</title>
	    <simpara>Ref <ulink url="../requirements/index.html#uc_067"/> for the use-case.</simpara>
	</sect2>
	<sect2><title>Mutation vs transformation</title>
	    <simpara>Re-parent causes the series of mutation (or modifications) made to the node re-parented. So the question is if this should
		be transformation instead of mutation.</simpara>
	    <simpara>Ref <xref linkend="ds_transf"/> for design item outlining transformation.</simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_di"><title>Desing issues</title>
	<sect2 id="ds_di_nacgna"><title>Native agents cannot get node by absolute URI</title>
	    <simpara>The origin of this behaviour it that native agents are not included into model's main native hier.
		They have theirs own hier instead.
		To be clearer, they don't have native hier (i.e. root) at all, so the rule of UID for native agent is just the agent name.
		They have only inheritance hier.  Actually there is kind of careless design in native agents.</simpara>
	    <simpara>Originally this fact didn't cause any problem, but with <xref linkend="gls_daa"/> this lack in design
		can lead to problems, ref.  <xref linkend="ds_daa_ina"/> for instance.</simpara>
	    <simpara>The possible solution would be to check in agents GetNode() if the agent is native, and if so,
		use iEnv-&gt;Root()-&gt;GetRoot()
		to get root. Or we can use this approach persistently for getting root.</simpara>
	</sect2>
	<sect2 id="ds_di_wsucv"><title>Wrong scheme of using content "Value" in DataBase</title>
	    <simpara>The current scheme of using "Value" content in DataBase (data.cpp) is wrong. The example is update
		of data: on the update of data (using Set()) also the update of property is initiated, but this causes FromString(),
		that in turn calls Set. The only thing that prevents the scheme from full mess is checking in Set that new data is
		the same as old and stopping of proceeding. See the stack below:
	    </simpara>
	    <programlisting>
		#0  DVar::HInt::Set (this=0x7b531a0, aData=1) at data.cpp:725
		#1  DVar::HInt::FromString (this=0x7b531a0, aString="I 1") at data.cpp:705
		#2  DVar::FromString (this=0x8635d90, aData="I 1") at data.cpp:517
		#3  DataBase::FromString (this=0x8635d90, aType="", aData="I 1") at data.cpp:181
		#4  DataBase::HandleCompChanged (this=0x8635d90, aContext=..., aComp=..., aContName="Value") at data.cpp:63
		#5  DVar::HandleCompChanged (this=0x8635d90, aContext=..., aComp=..., aContName="Value") at data.cpp:601
		#6  Elem::OnCompChanged (this=0x7c1cf30, aComp=..., aContName="Value") at elem.cpp:2264
		#7  Syst::OnCompChanged (this=0x7c1cf30, aComp=..., aContName="Value") at syst.cpp:1261
		#8  Elem::ChangeCont (this=0x7c1cf30, aVal="I 1", aRtOnly=true, aName="Value") at elem.cpp:1496
		#9  DataBase::UpdateProp (this=0x8635d90) at data.cpp:156
		#10 DVar::HInt::Set (this=0x7b531a0, aData=1) at data.cpp:727
		#11 DVar::HInt::Set (this=0x7b531a0, aInp=0x77a4380) at data.cpp:738
		#12 DVar::Update (this=0x8635d90) at data.cpp:572
		#13 StateAgent::Confirm (this=0x7c9aa60) at des.cpp:888
	    </programlisting>
	    <simpara>The solution can be having two contents instead on single: one is read-write, for setting data, second is 
		read-only just for checking of data only. Then DVar should ignore the change of second content in HandleCompChanged.</simpara>
	</sect2>
	<sect2 id="ds_di_cnfr"><title>Component notifies to Component Observers chain while the component isn't fully registered in native hier yet.</title>
	    <sect3><title>Intro</title>
		<itemizedlist>
		    <listitem>Ref <xref linkend="ds_daa_hunv"/> for related issue</listitem>
		    <listitem>This happens for instance when creating heir from parent that contains components. In that case the newly created heir is
			not fully included to hier (but just set owner) so all mutations of adding inherited comps generate notifs that are propagated
			thru created heir but it is not in the hier. It can get URI but upper nodes cannot get comp by this uri.</listitem>
		    <listitem>There is even more serious case - if heir mutation includes creation of more than one layer of inherited comps then we need to
			add created comp to it's parent. This request seems to be not avoidable. But this comps upper owner is not attached to hier
			(because there is not full attachment in Elem::CreateHeir())</listitem>
		    <listitem>The problem is always there but it doesn't affect much because in monolitic model observers get ref to comp in notificatio.
			The problem become apparent in DAA models where the ref is serialized to UID. But with this problem observer cannot get comp by UID
			because the comp has "week" (one-way) inclusion to the hier.</listitem>
		    <listitem>The problem can be simulated by attempting to get comp via it's UID in nofifier.</listitem>
		</itemizedlist>
	    </sect3>
	    <sect3><title>Analysis</title>
		<itemizedlist>
		    <listitem>Looking at Elem::AddElem(). Approach used in this method differs from that in Elem::CreateHeir(). In AddElem the
			full inclusion is done before applying the mutations. Why don't use such approach in CreateHeir()? The rationale is that
			creating heir is isolated process. The model shouldn't know of heir until it gets created. Another reason of not using
			full attachment is that CreateHeir is called recursively, so we will need to re-register heir for each parent in the
			parent's chain.</listitem>
		    <listitem>So in general the root cause of the problem is that currently UID is based on persits characteristic of the node
			(in terms of UID generation and resolution) but some nodes requesting handling are kind of temporary (for instance the node just
			being created).</listitem>
		</itemizedlist>
	    </sect3>
	    <sect3 id="ds_di_cnfr_snpn"><title>Solution: to not proparate notification in case if the node propagating is not fully included into hier.</title>
		<itemizedlist>
		    <listitem>Criticizm: This solution doesn't work in DAA: if upper owner is unattached then lower owner received notification
			will not be able to resolve component's UID. This is because UID is resolved as URI related to root but the unattached owner
			just breaks the chaing of URI.</listitem>
		    <listitem>To avoid the problem above we need to use just agent's local status when checking if the agent is included in the hier.
			This can be done by using the agent's mutation context introduced in the scope of solution <xref linkend="ds_daa_itn_sfo"/>.
		    We can consider the node is included in hier only if owner exuals mutation context or mutation context is not set at all.</listitem>
		</itemizedlist>
	    </sect3>
	    <sect3 id="ds_di_cnfr_susl"><title>Solution: to use solid relations during the process of creatin heir</title>
		<sect4><title>Intro</title>
		    <simpara>The idea is to establish heir solid relation to the hier when creatng heir. The only specific would be to not notify owners of
		    that. </simpara>
		</sect4>
		<sect4><title>Analysis</title>
		    <itemizedlist>
			<listitem>"Light" relation approach is not just for minimizing interactions. It aslo allows to avoid serious problem with
			    name duplication, ref <xref linkend="ds_di_cnfr_susl_pnae"/></listitem>
		    </itemizedlist>
		</sect4>
		<sect4><title>Problem: Missing notification brakes URI safety</title>
		    <para>
			The important aspect of multi-agent env is the assosiation URI to the agent. So URI can be used as reference to agent.
			In this aspect the notification plays important role of keeping URI safe - any changes of agent is reflected in notif so the owners can
			react on the change and update URI accordingly. If we avoid issuing notifications (even on heir creation phase) we will miss
			guarantee that agent URI is actual. Especially in case of creating heir where we need to constantly move heir from one 
			parent to another. So this approach requires assumption that URI of agent notifying of changes is not persistent.
		    </para>
		    <para>On the other hand there will be very limited requests keeping reference to such "temporary" agent, probably just AppendChild.
			We can combine the current solution with <xref linkend="ds_di_cnfr_snpn"/>. In this case there will not be notifs to owners so
			the problem with temporary nature of URI will be not actual.</para>
		</sect4>
		<sect4><title>Problem: making agents interaction more tough</title>
		    <simpara>One of the aim of avoiding full inclusion heir into hier on heir creation phase was to minimize agents interaction.
			This is especially important in case of distributed env. If parent is remote (quite often case, i.e. parent is represented by proxy)
			then full inclusion will leads to inter environments request. Currently this communication is avoided. The only heir (that is
			always local) is requested to add owner and parent - this doesn't require "long" interactions at all.</simpara>
		    <simpara>This is incorrect. Currently the notification from agents being created (including inherited agents) are proparated. This
			is because "light" one-way relation comp-owner is established - it enables the notifications sending upwords.</simpara>
		    <simpara>But indeed it needs to be considered if such notifications have to be blocked. Are they actually needed?</simpara>
		</sect4>
		<sect4><title>Problem: nodes that are parent's context are affected by creatin parent's heir</title>
		    <simpara>This is important and propably dangerous effect. Currently the node that is parent's owner (i.e. parent's context) is
			not affected when parent creates its heir. The context plays "passive" role here - it just is used for ensuring acces to model from
			heir. One-way relation allows that.</simpara>
		    <simpara>Using full comp-owner relation for created heir to parent's context causes to conext real change - its comps register will be
			changed.</simpara>
		</sect4>
		<sect4 id="ds_di_cnfr_susl_pnae"><title>Problem: "Name already exists" error on mutations of type "move"</title>
		    <simpara>"Move" mutation is performed by creating within the given target new heir from agent being moved. The name of created heir is
			same as of node being moved. So the node being moved tries to created "copy" of itself within its owner. Obviously this causes error of
			name duplicating when registernig new heir.</simpara>
		    <simpara>This case evolves more general problem: it is possible that heir name will get duplicated to the name of some comps within
			parents context chain. Note that this problem gets possible only if comp name uniquiness rule is applied,
			ref <xref linkend="ds_mut_nm"/>.</simpara>
		</sect4>
		<sect4 id="ds_di_cnfr_susl_pfl"><title>Problem: tried, seems the limitation is fundamental</title>
		    <simpara>The problem is that in case of remote parent the first remote call is AppendComp(). Before AppendComp() there is no
		    valid UID in heir, but AppendComp remote call requires valid UID.</simpara>
		</sect4>
	    </sect3>
	    <sect3 id="ds_di_cnfr_siurm"><title>Solution: to improve UID resolution mechanism for "temporal" nodes</title>
		<sect4><title>Intro</title>
		    <simpara>The idea is to remain the mechanism of creating heir as is but allow "temporal" nodes
			(i.e. nodes having only "light" attachment to the hier, heir when creating for instance)
			be the subject of UID resolution. This can be done via introducing specific resolution mechanism for such kind of nodes. This
			mechanism could be based on registering in scecific register owned by env.</simpara>
		</sect4>
	    </sect3>
	    <sect3><title>Diary</title>
		<itemizedlist>
		    <listitem>20170122 Tried solution <xref linkend="ds_di_cnfr_susl"/> plus rolled-back name uniquiness, ref <xref linkend="ds_mut_nm"/>
			to avoid problem <xref linkend="ds_di_cnfr_susl_pnae"/></listitem>
		    <listitem>20170123 Tried some small fixes to move forward after name uniquiness rolled-back. Realized that there is 
			fundamental limitation of the approach, ref <xref linkend="ds_di_cnfr_susl_pfl"/>. So this approach cannot be applied.</listitem>
		    <listitem>20170218 Tried solution <xref linkend="ds_di_cnfr_snpn"/> (using  just local checking owner and mutation context of agent).
		    </listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_di_ndnac"><title>Modifications during native agent construction - agent cannot be found.</title>
	    <sect3><title>Intro</title>
		<simpara>Testing solution for having nodes attached on any phases of mutations, ref <xref linkend="ds_daa_itn_sfo"/>. Even the solution
		    "legalize" the agents during creation there is still one special case where the solution doesn't help - when agent applies modifications
		    during native constructor. The notification is propagated but the handler actually see not completed agent passed in notification. This
		    agent even is not attached to the hier. So in distributed system it cannot be accessed via URI.</simpara>
	    </sect3>
	    <sect3><title>Solution: adding dedicated phase for native object modifications, like "Construct". It has to be called after adding created node
		to hier.</title>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_va"><title>Visualization agent</title>
	<sect2><title>Refs</title>
	    <biblioentry id="ref_j_gdk"> <abbrev>J_GDK</abbrev>
		<productname><ulink url="http://james.id.au/tech/doc/gdk/"/></productname>
		<title>Introduction to GDK - James</title> </biblioentry>
	</sect2>
	<sect2><title>APIs</title>
	</sect2>
    </sect1>

    <sect1 id="ds_nmm"><title>How to implement notification of mutation or modification</title>
	<sect2><title>Intro</title>
	    <itemizedlist>
		<listitem>Ref <ulink url="../requirements/index.html#uc_066"/> for use-case</listitem>
	    </itemizedlist>
	</sect2>
	<sect2><title>Current implementation: extra parameter in notification</title>
	    <simpara>Currently (9767f9de) the mut/mod notification is implemented via additional argument (run-time or modif) of notifications. The rationale was
	    </simpara>
	    <itemizedlist>
		<listitem>There are already notification of change so there is no sense to introduce one more new.  </listitem>
		<listitem>Adding new notification "OnChromoChanged" causes to increasing the notifications almost twice. In distribured model each
		    notification can cause "long" request (via IPC), so this increase of notificaction could downgrade the model's benchmark siginificantly.</listitem>
	    </itemizedlist>
	    <simpara>But there is still doubts regarding appropriateness of this approach.  The argument is that no one agent doesn't use this
		parameter but the only observer (studio application).</simpara>
	    <simpara>Also the trigger of this doubts was the bug in Elem::AddElem():</simpara>
	    <programlisting>
		TBool persist = !aRunTime &amp;&amp; aCtx != NULL &amp;&amp; (aCtx == root || root->IsCompAttached(this));
		res = node->AppendComp(elem, !persist);
	    </programlisting>
	    <simpara>Here IsCompAttached() is called, that causes the problem in case of "this" is the node newly created and not inserted into owner. In this
		case the node Uid cannot be resolved in distributed mode (ref <xref linkend="ds_daa_hunv"/>). The idea of solving <xref linkend="ds_daa_hunv"/>
		was to avoid any "long" requests while created node is under weak one-side relation to owner. But the approach of using notification parameter for 
		mut/modif requires calculation mut/modif before AppendComp, that leads to "long" call IsCompAttached().</simpara>
	    <simpara>
		The drawback of "mut/moduf arg" solution is that in fact the argument needs to be calculated (i.e. this is not a fact but a prediction) each
		time the mutation occurs. This arg is not the sign of node's chromo changed but the sign of model's chromo changed. So node issuing the
		notification that is not in its scope of responsibility. So this is architectural gap. To keep this "mut/modif arg" architecturally clear
		this arg should have the meaning "this is mutation/modificatio" of the notifying node (component)". Then the owner can analyze this arg,
		calculate its own arg and propagate the notification. This seems not to be elegant solution because it requires passing to the notification
		some parameters required for the calculation: context of mutation for instance.  </simpara>
	</sect2>
	<sect2><title>Solution: dedicated observer for agent's chromo change</title>
	    <sect3><title>Intro</title>
		<simpara>Assuming that the observer is registered for root node only. The idea is to minimize the number of notification events.
		    With this solution the number of notifications within the model remains same as in case of mut/modif argument. The only notifications number to
		    model's client (studio application for instance) will be increased.</simpara>
	    </sect3>
	</sect2>
	<sect2><title>Solution: to add specific notification of chromo changed in agent observer.</title>
	    <simpara>Note that there is already such a notification MElem::OnNodeMutated() that proparates to the upper node. So in any case the notification is issued.
		The idea is to add such a notification (without mutation context in args) into agent's observer. Base agent should issue this notification from
		its own handler OnNodeMutated in case if there is agents observer registered.  </simpara>
	    <simpara>It makes sense to consider moving MElem::OnNodeMutated() to comp observer. In that case the correspondance between comp observer and
		agent observer will exists for all notifications.</simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_ifrd"><title>How to re-desing interface mechanism</title>
	<sect2><title>Intro</title>
	    <simpara>In current implementation of multi-agent model interface is the key part of the model. Each agent is represented in multi-agent 
		environment as set of interfaces. An interface is elementary behavioural entity. At the moment (20170423) interface mechanism is 
		implemented with definition of meta-inerface interface "miface" that states common behaviour of an interface itself.</simpara>
	    <simpara>So, yes. We still use behavioural model for multi-agents. This was considered as simplest way of mapping multi-agent to
		extising processors core computing model.</simpara>
	    <simpara>The important aspect of interface concept is the mechanism of unified call of interfaces methods. This mechanism is 
		implemented as text formed request, the format of requests is specified. Agent as interface implementor is responsible for handling
		unified call request. In order to simplify handling the helper class "ifu" is used. It provides utilities simplifying of dealing with
		unified call request: parsing, seriaizing/deserializing, etc. However the current implemetation is rather ineffective, so agent needs
	    quite lot of code to handle the request. We need to re-desing the interface mechanism in order to make it more effective.</simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_prfopt"><title>Performance optimization</title>
	<sect2><title>Intro</title>
	    <itemizedlist>
		<listitem>Ref <xref linkend="sec_img"/> for design solution for creating system from image.</listitem>
		<listitem>Ref <xref linkend="ds_mae"/> for optimization approach of using monolitic native agents.</listitem>
	    </itemizedlist>
	</sect2>
	<sect2 id="ds_prfopt_un"><title>Migrating to unique name</title>
	    <sect3><title>Intro</title>
		<simpara>Ref <xref linkend="ds_mut_nm"/> for the design consideration regarding unique naming.</simpara>
		<simpara>Non-unique names causes performance degradation. An example is component resolution when searching node by URI. Look at 
		    Elem::GetNode():</simpara>
		<programlisting>
		    MElem* Elem::GetNode(const GUri&amp; aUri, GUri::const_elem_iter&amp; aPathBase, TBool aAnywhere, TBool aInclRm)
		    ...
		    |||             Iterator it = NodesLoc_Begin(elem, aInclRm); 
		    |||             Iterator itend = NodesLoc_End(elem, aInclRm);
		    45-                     for (; it != itend; it++) {
		    456                         MElem* node = *it;
		    456                         MElem* res1 = node->GetNode(aUri, uripos, EFalse, aInclRm);
		</programlisting>
		<simpara>It is seen from this chunk that for URI each unit: </simpara>
		<itemizedlist>
		    <listitem>We look up all components, not just selecting one. Look at Elem::Iterator mechanism.</listitem>
		    <listitem>We try to find next unit for all nodes we found for current unit. So having two same names we do remaining search twice.
			If next units also have say 2 same names then we have sarch branch again.
		    </listitem>
		</itemizedlist>
		<simpara>Actually the implementation itself doesn't produce performance degradation. In case if there are not duplicated names the
		    internal iterator works fast.</simpara>
	    </sect3>
	    <sect3><title>We also need to disable "any" name in URI unit</title>
		<simpara>If we keep "any" name we will need to have complex Elem::IterImplBase with using iterators range. If we disable "any" then the 
		local name iterator gets trivial so can be removed at all.</simpara>
	    </sect3>
	    <sect3><title>What are the use-cases preventing unique name</title>
		<itemizedlist>
		    <listitem>Moving node - there can be same name node in the destination. No problem - we just need to request new name.</listitem>
		</itemizedlist>
	    </sect3>
	    <sect3><title>Uri but not query</title>
		<simpara>The current implementation is the result of attempt to implement kind of query to the tree. But URI is not query.
		    URI main purpose is to unambiguesly identificate the node in the tree. Query purpose is to find set of nodes.</simpara>
		<simpara>This relates also to "Anywhere" and "Any" pattern in URI. It is clear that using "Anywhere" is very ambiguous approach.
		    This is because for URI /**/some_name if there are two nodes some_name in the system then we don't know what node is specified
		    exactly, i.e. this URI actualy specifies set of nodes, so is query. Same is for "Any".</simpara>
	    </sect3>
	    <sect3><title>Unique name approach works for owning tree not for inheritance.</title>
		<simpara>For inheritance it is not possible to meet uniqueness of name because if a1 = { Elem:a2} then
		    a1:a1_child will also contain Elem:a2 but it is another a2.</simpara>
	    </sect3>
	    <sect3><title>Solution: unique name for owning hier, not unique for inheritance. URI only based on owning.</title>
		<simpara>Taking into account that only owning hier supports unique name we can use only this hier for 
		URI.</simpara>
	    </sect3>
	    <sect3 id="ds_prfopt_un_icr"><title>iComps register can be removed now</title>
	    </sect3>
	</sect2>
	<sect2><title>To get rid of Agents special container.</title>
	    <simpara>Ref <xref linkend="ds_dla"/></simpara>
	</sect2>
	<sect2><title>TODO</title>
	    <orderedlist>
		<listitem>To avoid handling notifs from comp on all levels. Maybe direct owner handling is enough</listitem>
		<listitem>To reimplement content as tree</listitem>
	    </orderedlist>
	</sect2>
	<sect2 id="ds_prfopt_ahn"><title>To avoid handling notifs from comp on all levels</title>
	    <sect3><title>Intro</title>
		<simpara>Ref <xref linkend="ds_hsc"/> for observers design.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_prfopt_osmlp"><title>OSM mutation approach causes long chain of propagations.</title>
	    <sect3><title>Intro</title>
		<simpara>Ref <xref linkend="ds_mut_osm"/> for OSM mutation approach.</simpara>
		<simpara>20180421 Look at Elem::NotifyNodeMutated(). It is seen that the mutation causes propagation upwards to root.
		    Comparing to hiearchical chromosome approach in OSM any node contains it's full chromo whereas in hier chromo the node contains only
		local chromo - the full node's chromo can be combined from chromos of its components.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_prfopt_mnn"><title>Attempt of optimization: Minimize the number of nodes.</title>
	    <sect3><title>Performing reference optimization of model "rock_al_vis_phd" from studio eamples.</title>
		<simpara>Currently, before opt the model is not using multi-content.
		    There are 12081 nodes, creation time is 2102105 microseconds.</simpara>
		<simpara>After optimization (using multicontent agents): 6244 nodes, creation time 1271800 microsecond.</simpara>
		<simpara>Further optimization requires re-design to deep using of content instead of embedded agents,
		    ref <xref linkend="ds_pia"/>.
		    This can significantly reduce the number of nodes. As I see from root dump, the major number of nodes is
		    from socket connpoints - states inputs/outputs.</simpara>
	    </sect3>
	</sect2>
	<sect2><title>Checking with command line monitor app</title>
	    <simpara>I have added simple command line app - monitor to test the performance in simple environment. Checking the
		model des_var_vect_1: same time in Studio and in monitor: 508 nodes at 99405 us - 196 us/node. So Studio 
		env doesn't affect model creating performance.</simpara>
	</sect2>
	<sect2 id="ds_prfopt_gperf"><title>Profiling using gperf</title>
	    <sect3><title>Intro</title>
		<simpara>Ref <ulink url="https://en.wikipedia.org/wiki/Gprof"/> for gperf WiKi.</simpara>
		<simpara>Ref <ulink url="https://www.thegeekstuff.com/2012/08/gprof-tutorial/"/> for gperf tutorial.</simpara>
	    </sect3>
	    <sect3><title>Log</title>
		<itemizedlist>
		    <listitem>Added -gp to compiler and linker options in grayb and fapm CLI monitor. Run monitor
			<programlisting>
			    ~/projects/fap/grayb/clm$ ./fapm ../../fap2-studio-gtk/examples/des_var_vect_1.xml
			 </programlisting>
			 and see gmon.out file generated
		    </listitem>
		    <listitem>Run gprof
			<programlisting> ~/projects/fap/grayb/clm$ gprof .libs/fapm gmon.out > gprof_out.txt </programlisting>
			and see output file gprof_out.txt. The problem is that I cannot see profiling info for grayb so.
		    </listitem>
		    <listitem>To profile shared lib we need another tool - sprof. Ref 
			<ulink url="http://greg-n-blog.blogspot.com/2010/01/profiling-shared-library-on-linux-using.html"/>:
			<programlisting>
			     Profiling shared library on Linux using sprof
			     It's not as easy as one would/should expect. (Read here about valgrind if you don't want to use sprof.)

			     First - FORGET ABOUT gprof. gprof is used for the applications but will NOT WORK for shared libraries.
			     Sorry about that. I learned about it the hard way. What you need to use is sprof.
			</programlisting>
			Also ref <ulink url="https://stackoverflow.com/questions/1838989/gprof-how-to-generate-call-graph-for-functions-in-shared-library-that-is-linke"/>
		    </listitem>
		    <listitem>So I followed the last link:
			<programlisting>
			    1. Compiled libgrayb.so w/o -pg but just with -g.
			    *  cd ~/projects/fap/grayb/clm
			    2. export LD_PROFILE_OUTPUT=`pwd`
			    3. export LD_PROFILE=libgrayb.so.0
			    4. rm -f $LD_PROFILE.profile
			    5. execute ./fapm ../../fap2-studio-gtk/examples/des_var_vect_1.x
			    6. sprof ../src/.libs/$LD_PROFILE $LD_PROFILE.profile -p >log
			</programlisting>
			I see the error on #6: "Inconsistency detected by ld.so: dl-open.c: 718: _dl_open:
			Assertion `_dl_debug_initialize (0, args.nsid)->r_state == RT_CONSISTENT' failed!".
			I couldnt find any solution for that. Trying to use google pprof instead, ref
			<xref linkend="ds_prfopt_gpprof"/>.
		    </listitem>
		    <listitem>google pprof doesn't work for me, ref <xref linend="ds_prfopt_gpprof"/> log -
			I couldn't see any events. So returnign to gprof but for fap monitor statically linked to grayb lib.
			Linker option for fapm is as:
			<programlisting>
			    fapm_LDFLAGS=-L../src/.libs/ -l:/usr/lib/gcc/x86_64-linux-gnu/5/libgcc.a -l:libgrayb.a -ldl -pg
			</programlisting>	
			Then I run the monitor:
			<programlisting>
			    ~/projects/fap/grayb/clm$ ./fapm ../../fap2-studio-gtk/examples/des_var_vect_1.xml
			</programlisting>
			and parse the profile data
			<programlisting>gprof -b ./fapm gmon.out > perf_out.txt</programlisting>
		    </listitem>
		    <listitem>Summary: gprof profiling is not useful for me, the information is too scanty to be base for
			relevant analysis.
		    </listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_prfopt_gpprof"><title>Profiling using google pprof</title>
	    <sect3><title>Intro</title>
		<simpara>Looking at google pprof because of attempt of gperf profiling was not successful for me,
		    ref <xref linkend="ds_prfopt_gperf"/></simpara>
		<simpara>Ref <ulink url="https://stat.ethz.ch/pipermail/r-sig-debian/2009-June/000795.html"/> for initial point.
		    Ref <ulink url="http://dirk.eddelbuettel.com/papers/bocDec2008introHPCwithR.pdf"/> for "Introduction to
		    High-Performance Computing with R" from Dirk Eddelbuette</simpara>.
		<simpara>The packages are google-perftools and libgoogle-perftools* on Ubuntu.</simpara>
		<simpara>Ref <ulink url="http://goog-perftools.sourceforge.net/doc/cpu_profiler.html"/> for the manual.</simpara>
	    </sect3>
	    <sect3><title>Log</title>
		<itemizedlist>
		    <listitem>Installed packages: libgoogle-perftools-dev, libgoogle-perftools4, google-perftools</listitem>
		    <listitem>Foolowing profiler manual, ref above.</listitem>
		    <listitem>1. Linking in the Library. Added -lprofiler to build config. Aslo needed to create symlink to 
			<programlisting>libprofiler.so -> libprofiler.so.0.3.2</programlisting>
		    </listitem>
		    <listitem>2. Running the Code. Added envvar 
			<programlisting>export CPUPROFILE=google_perf.profile</programlisting>
			but it doesn't work. Added to app code:
			<programlisting>
			    #include "gperftools/profiler.h"
			    ...
			    ProfilerStart("./google.profile");
			    mnt.initEnv();
			</programlisting>
			Now I can see profiler log and file (the file name is acc to evvar not ProfilerStart argument).
		    </listitem>
		    <listitem>Analyzing the Output
			<programlisting>
			    google-pprof --text ../src/.libs/libgrayb.so google_perf.profile

			    Using local file ../src/.libs/libgrayb.so.
			    Using local file google_perf.profile.
			</programlisting>
			So I cannot see any events profiled.
		    </listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_prfopt_oprofile"><title>Profiling using oprofile</title>
	    <sect3><title>Intro</title>
		<simpara>Ref <ulink url="https://en.wikipedia.org/wiki/OProfile"/> for WiKi</simpara>
		<simpara>Ref <ulink url="http://people.redhat.com/wcohen/Oprofile.pdf"/> for manual.</simpara>
	    </sect3>
	    <sect3><title>Log</title>
		<itemizedlist>
		    <listitem>Installe pkg oprofile </listitem>
		    <listitem>Stopped atm</listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_prfopt_eprof"><title>Using embedded profiler</title>
	    <simpara>Ref <xref linkend="sec_prof"/> for details.</simpara>
	</sect2>
	<sect2 id="ds_prfopt_prp01"><title>20181001 Proposals for optimization</title>
	    <sect3><title>To avoid using observers on agent level - to have observer in env (Env API extension required) </title>
	    </sect3>
	    <sect3 id="ds_prfopt_prp01_dpe"><title>To disable propagating events by default.</title>
		<simpara> Agent can have API to change this behavior in order to allow owner to force propagating </simpara>
		<simpara>Ref <xref linkend="ds_elem_iact_unl"/> for discussion regarding design of native hier events propagation.</simpara>
		<simpara>I measured cumulative duration of OnCompAdding handler on example des_1:</simpara>
		<programlisting>
		    6       Env constructor duration                44300859

		    11      Elem OnCompAdding handling      331774  261     1271
		    12      Elem OnCompChanged handling     7157076 77      92949 
		</programlisting>
		<simpara>So two handler takes about 25% of workload.</simpara>
		<simpara>After disabling propagation:</simpara>
		<programlisting>
		    6       Env constructor duration                49065353        

		    11      Elem OnCompAdding handling      103458  261     396     
		    12      Elem OnCompChanged handling     4822625 77      62631   
		</programlisting>
		<simpara>So the part of handlers decreased to about 10%</simpara>
		<simpara>This design proposal was implemented in [326f9dfdf9b5] and caused the issue <xref linkend="ds_i_dpe_wb"/></simpara>
	    </sect3>
	    <sect3><title>Optimization point: Import</title>
		<simpara>Tracing importing process. I see that operation of reducing module's chromo to selection takes
		    too much time, about 20%:</simpara>
		<programlisting>
		    6       Env constructor duration                112200342
		    ...
		    17      Creating native agent   13275798        470     28246
		    18      Content changing mutation       20858270        151     138134
		    19      Transform mut to OSM    11313569        825     13713
		    20      Importing mutation      78922024        10      7892202
		    21      Importing, reduce to sel        22480111        17      1322359
		</programlisting>
	    </sect3>
	    <sect3><title>Optimization point: changing content</title>
		<simpara>It takes around 20% of model creation time:</simpara>
		<programlisting>
		    6       Env constructor duration                112200342
		    ...
		    17      Creating native agent   13275798        470     28246
		    18      Content changing mutation       20858270        151     138134
		    19      Transform mut to OSM    11313569        825     13713
		    20      Importing mutation      78922024        10      7892202
		    21      Importing, reduce to sel        22480111        17      1322359
		</programlisting>
	    </sect3>
	    <sect3 id="ds_prfopt_pepe"><title>To handle pre-event and post-event notifications. Currently the only post-events are handled.</title>
	    </sect3>
	    <sect3 id="ds_prfopt_prp01_ipind"><title>Profiling: to introduce ifaces for Pind recorders</title>
		<simpara>To introduce ifaces for Pind recorders and extend Profiler iface to return the recorderd. 
		    In order to mininise recording overhead we can cache refs to recorders in profiler so recorder getters be inline.
		    Recodred ifaces can be functors with operator () intended for creating a record. We need also to disable creating
		    more that one recorder same time (at least at the moment)
		</simpara>
		<simpara>20181001 <xref linkend="sts_done"/></simpara>
	    </sect3>
	    <sect3><title>To simplify second constructor </title>
		<sect4><title>Proposal</title>
		    <simpara>To simplify second constructor (that creates genuine native agents) via delegating constructor or using
			aName for constructor variation. Just check in the constructor if name is passed to it. Why second
			constructor sets type as empty? This because second constructor creates origin agent but first constructor
			creates the child of origin agent.  </simpara>
		</sect4>
		<sect4><title>Status</title>
		    <simpara><xref linkend="sts_done"/> in 78d5434a0968</simpara>
		</sect4>
	    </sect3>
	    <sect3><title>To simplify default provider</title>
		<sect4><title>Proposal</title>
		    <simpara>To simplify default provider: Add private method for creation of bare agent and use it within
			CreateNode and GetNode. Also probably virtual method is required for getting type. It is required
			to avoid branching by type in GetNode when getting parent. There is EType method but seems it is not we need,
			what we need if to get staticly assosiated parent name. Look also at PName.  </simpara>
		</sect4>
		<sect4><title>Status</title>
		    <simpara><xref linkend="sts_done"/> in 78d5434a0</simpara>
		</sect4>
	    </sect3>
	    <sect3><title>To get rid of mut </title>
		<simpara> To get rid of mut. Just pass it as agrument of mut method. The case of async mut needs to be considered.
		    With this case mut needs to be stored as the context of mut sequence. Also look at AppendMutation, it is used still.
		</simpara>
	    </sect3>
	    <sect3><title> What to prof: GetNode, UpdateIfi, GetUri, muts </title> </sect3>
	    <sect3><title>Prof: Needs to support prof in the case when the func is recursive </title>
		<simpara>Prof: Needs to support prof in the case when the func is recursive. For Pindurstat we can just
		    check if the measure for given event is completed or not. For clock pind we can postpone the
		    filtering to processing stage. There we can filter out all method recursive calls.
		</simpara>
	    </sect3>
	    <sect3><title>To optimize cont.</title> </sect3>
	    <sect3><title>Migrate to unordered containers.</title> </sect3>
	</sect2>
	<sect2 id="ds_prfopt_log"><title>Optimization log</title>
	    <sect3><title>20181017 Measured duration statistic.</title>
		<simpara>Defined duration statistic measurement so that the intervals are not intersected:</simpara>
		<programlisting>
		    grayb/clm$ ./fapm -lclm.log -pprof -s'../../fap2-studio-gtk/examples/des_var_vect_1.xml' -a


		    prof~durstat.csv:

		    15      Elem NotifyNodeMutated                  8932406         329     27150
		    17      Creating native agent                   14191721        470     30195
		    18      Content changing mutation               20760228        151     137484
		    19      Attr changing mutation                  81230           1       81231
		    20      Transform mut to OSM                    11500538        825     13940
		    21      Import mgr ImportToNode, excl Mutate    76970           1       76970
		    22      Import mgr DoImport, excl ImportToNode  39393378        18      2188521

		    prof~dur.csv:

		    8       Profiler duration measure time          1465
		    6       Env constructor duration                108322225
		</programlisting>
		<simpara>These results shows that the sum of measured intervals are 94 936 472 us, this is near to 
		    "Env constructor duration" - 108 322 225. Most time consuming operation seems to be DoImport. Also
		    transform mut to OSM takes a time, same for Content changing mutation. We need to focus optimization
		    process on that targets.</simpara>
		<simpara>The operation related to <xref linkend="gls_osm"/> are time consuming also: "Elem NotifyNodeMutated",
		    "Transform mut to OSM" takes about 20% of total time. Needs to look at OSM design.
		</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_prfopt_mse"><title>Optimization of socket and extender: avoid embedding agents and useing monolitic agent instead</title>
	    <sect3><title>Intro</title>
		<simpara>Currently [644e5f6d21] extender and socket are agents resided within wrapping Vert agent. The optimization can be to
		use monolite extender and socket.</simpara>
	    </sect3>
	    <sect3 id="ds_prfopt_mse_metr"><title>Metrics of current implementation</title>
		<sect4><title>Initial version</title>
		    <programlisting> grayb/clm$ ./fapm -lclm.log -pprof -s'../../fap2-studio-gtk/examples/des_var_1.xml' -a </programlisting>
		    <simpara>clm.log:</simpara>
		    <programlisting>INF; ; /Root; Completed of creating system, nodes: 354, imported: 226, time, us: 56537</programlisting>
		    <simpara>prof~durstat.csv:</simpara>
		    <programlisting>
			9       Elem constructor duration       0       0       n/a
			10      Elem constructor: chromo creation duration      1716994 382     4494
			11      Elem OnCompAdding handling      120181  333     360
			12      Elem OnCompChanged handling     4797839 110     43616   
			13      Elem GetNode    2674492 1004    2663
			14      Elem GetIfi     2843885 183     15540
			15      Elem NotifyNodeMutated  3509364 187     18766
			16      Elem CreateHeir 17095184        85      201119
			17      Creating native agent   6212249 336     18488   
			18      Content changing mutation       7192714 79      91047   
			19      Attr changing mutation  0       0       n/a  
			20      Transform mut to OSM    11612718        526     22077
			21      Import mgr ImportToNode, excl Mutate    13531   1       13531
			22      Import mgr DoImport, excl ImportToNode  26833747        24      111807
		    </programlisting>
		</sect4>
		<sect4><title>Optimized for multi-content</title>
		    <programlisting> grayb/clm$ ./fapm -lclm.log -pprof -s'../../fap2-studio-gtk/examples/des_var_1mc.xml' -a </programlisting>
		    <simpara>clm.log:</simpara>
		    <programlisting> INF; ; /Root; Completed of creating system, nodes: 184, imported: 121, time, us: 50936</programlisting>
		    <simpara>prof~durstat.csv:</simpara>
		    <programlisting>
			9       Elem constructor duration       0       0       n/a
			10      Elem constructor: chromo creation duration      937754  203     4619
			11      Elem OnCompAdding handling      85475   182     469
			12      Elem OnCompChanged handling     6838507 385     17762   
			13      Elem GetNode    1616552 472     3424
			14      Elem GetIfi     4730923 394     12007
			15      Elem NotifyNodeMutated  3303836 193     17118
			16      Elem CreateHeir 16254743        69      235575
			17      Creating native agent   6701947 184     36423   
			18      Content changing mutation       7249771 194     37369   
			19      Attr changing mutation  0       0       n/a  
			20      Transform mut to OSM    10926474        460     23753
			21      Import mgr ImportToNode, excl Mutate    19129   2       9564 
			22      Import mgr DoImport, excl ImportToNode  24835791        22      1128899
		    </programlisting>
		    <simpara>It is seen that the multicontent approach doesn't give us valuable optimization - the agents number is reduced from 
			354 to 184 (almost twice) but the model creation time isn't reduced significantly. The possible cause of that is that the native
		    agent creation time has been increased (because of content is changing in constructor).</simpara>
		</sect4>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="sec_prof"><title>Embedded profiler</title>
	<sect2 id="sec_prof_cs"><title>What clock system to use?</title>
	    <sect3 id="sec_prof_cs_ctime"><title>ctime clock</title>
		<simpara>Ref <ulink url="http://www.cplusplus.com/reference/ctime/clock/"/>. The dencity of the clock can
		    be retrieved via CLOCKS_PER_SEC. On my Ubuntu it gives 32767 ticks per second. Given into account that 
		    currently average time of agent creation is about 200us (ref <xref linkend="ds_prfopt_mnn"/>) this value
		    (~30us) cannot be considered as suitable).</simpara>
	    </sect3>
	    <sect3 id="sec_prof_cs_pclock"><title>Linux time.h clock_gettime()</title>
		<simpara>Ref <ulink url="http://man7.org/linux/man-pages/man3/pthread_getcpuclockid.3.html"/></simpara>
		<simpara>I checked resolution of the clock, ref
		    <ulink url="http://man7.org/linux/man-pages/man2/clock_gettime.2.html"/>:</simpara>
		<programlisting>
		    #include &lt;time.h&gt;
		    ...
		    -       clockid_t cid;
		    |       struct timespec ts;
		    |       int s = pthread_getcpuclockid(pthread_self(), &amp;cid);
		    |       if (s == 0) {
		    |-          s = clock_getres(cid, &amp;ts);
		    |       }
		</programlisting>
		<simpara>with result</simpara>
		<programlisting>
		    (gdb) p ts
		    $3 = {tv_sec = 0, tv_nsec = 1}
		</programlisting>
		where tv_nsec is resolution in nanoseconds. So seems this API can be used.
	    </sect3>
	</sect2>
	<sect2><title>Verification</title>
	    <programlisting>
		cd ~/projects/fap/grayb/clm
		./fapm -a -lclm.log -pprof -s../../fap2-studio-gtk/examples/des_var_vect_1.xm
	    </programlisting>
	</sect2>
    </sect1>

    <sect1 id="sec_img"><title>Using "image" for constructing system</title>
	<sect2><title>Intro</title>
	    <simpara>Creating model from spec takes a lot of time. This is because each mutation causes many actions not local only.
		Creation time can be reduced if system is created from system "image". System image is serialized sytem so the creation from
		image is just de-serialization of the image.
	    </simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_pia"><title>Re-design: using properties instead of embedded auxiliary agents (<xref linkend="gls_pia"/>)</title>
	<sect2><title>Intro</title>
	    <simpara>Ref <xref linkend="ds_prfopt_mnn"/> for example of one model optimization - it shows that the major part of nodes is of 
		complex connection points. It also shows that the currently developed set of multicontent agents doesn't allow
		to properly optimize the complexity of the model.</simpara>
	    <simpara>Ref <xref linkend="ds_uac"/> for alternative solution.</simpara>
	</sect2>
	<sect2><title>Connection redesign</title>
	    <sect3><title>Intro</title>
		<simpara>Concept items:</simpara>
		<itemizedlist>
		    <listitem>Get rid of edges - using direct connections vertex-to-vertex</listitem>
		    <listitem>Vertex pair are registered via URI in content</listitem>
		    <listitem>Pre-defined content node for pair URIs</listitem>
		    <listitem>Vertex pair registry as map {pair pointer, content (URI) id}</listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_pia_ifr"><title>Iface resolution in <xref linkend="gls_pia"/> system Systp</title>
	    <sect3><title>Iface routing by direct request (empty request context).</title>
		<simpara>On the one hand it is reasonable that having connection thru connpoint requesing Iface_A Systp routes the direct request to that pair.</simpara>
		<simpara>On the other hand the Systp itself is designed as agent that exposes itself via connpoints so shouldnt handle direct request other
		    that superclass (Vertp) does. However we can ignore the last argument thinkin it the followng manner: yes, Systp exposes via CPs but it exposes
		    all it's complex behaviour, so if some one get direct access then Systp shall behave some way as if the request was thru CP. </simpara>
	    </sect3>
	    <sect3 id="ds_pia_ifr_ap"><title>How can we implement routing in Systp: problem - ambiguos paths</title>
		<simpara>In Syst the routing key part is agents-connpoints. Exactly conn points are requested by system internal
		    agents to get iface. For instance function-agent asked input connpont for iface MData to get input data.
		    The context in that case is unique "path" from requestor to responser.  </simpara>
		<simpara> How can we implement this with <xref linkend="gls_pia"/> approach? In this case the agents in context doesn't create
		    unambigues path from requestor to responser. Ref <xref linkend="fig_pia_ifr_ac"/> for example, S1, S2, S1a, S2a are systems.
		    The example of routing is as following:</simpara>
		<itemizedlist>
		    <listitem>Embedded agent S2aa requests iface from its owner S2a conn point CP2aa1.</listitem>
		    <listitem>S2a redirects the request to S2 because S2A connects to S2 via CP2aa.</listitem>
		    <listitem>S2 resirects the request to S1 because CP2aa connnects via Int of E21 and S2 connects to S1 via E21</listitem>
		    <listitem>S1 gets the request with context {S2aa, S2a, S2}. S1 needs to analyze the context to understant via what internal point of
			socket E11 to route next. But S1 cannot make unambiguos path back usign just context. There are 2 paths:
			<programlisting>
			    1: S1(E11) - S2(E21) - S2a(CP2aa1) - S2aa
			    2: S1(E21) - S2(E22) - S2a(CP2aa2) - S2aa
			</programlisting>
			<simpara>As it is seen, the context is same for thath 2 paths</simpara>
		    </listitem>
		</itemizedlist>
		<figure id="fig_pia_ifr_ac"><title>Example of interface resolution problem</title>
		    <imageobject> <imagedata fileref="pics/pia_iface_rsl.png"/> </imageobject></figure>
		<simpara>What would be possible solution here?</simpara>
		<itemizedlist>
		    <listitem>Specific iface resolution API for system, ref <xref linkend="ds_pia_ifr_ap_sira"/></listitem>
		</itemizedlist>
		<sect4 id="ds_pia_ifr_ap_sira"><title>Specific iface resolution API for system</title>
		    <simpara>Current iface resolution mechanism and API was introduced on base agent (MElem) level. This means it knows nothing
			of agents connecting via contracts (connection points). So for <xref linkend="gls_pia"/> system it is resonable to
			introduce specific iface resolution API. This API needs to consider the fact that contracts (connection points) are required 
			for finding correct path back.</simpara>
		    <simpara>There are two approaches regarding context:</simpara>
		    <itemizedlist>
			<listitem>This specific API needs to have extended context. This context has to include connection contracts info,
			    ref <xref linkend="ds_pia_ifr_ap_sira_ex"/>
			</listitem>
			<listitem>No need to have extended context. The only additional argument in iface requesting method is enough, ref
			    <xref linkend="ds_pia_ifr_ap_sira_aa"/></listitem>
		    </itemizedlist>
		    <sect5 id="ds_pia_ifr_ap_sira_aa"><title>Approach: additional argument in iface requesting method </title>
			<simpara>Analyzing the example above we can see that in this case the additonal argument can be used. Indeed, the ambiguity in this example
			    cand be avoided if we specify connection point S1.E11 witin the request iface from S2. In that case S1 can understand that the request
			    is coming from S2.E21 and then create unambiguos path. This seems to be generic rule. The ambiguty happens if we don's specify the 
			    connection point on requesting system. Specifying connection point solves this problem. The sequence of requests for
			    example <xref linkend="fig_pia_ifr_ac"/> will be as:</simpara>
			<programlisting>
			    S2aa -->
			    S2a.CP2a1
			    S2.E21
			    S1.E11.P1
			    S1a.CP1a1 
			    --> S1aa
			</programlisting>
			<simpara>Another design point is to how implement the extended request. Currently an agent has single ifaces cache, the key
			    is request context (requestors) and iface provider. If we add new parameter of request - conn point then we need to 
			    extend the cache. It can be done either extending the key (for instance combining the context with connpoint) or having separate
			    cache for each connpoint.  </simpara>
			<simpara>This design is incredibly similar to the iface cache design for <xref linkend="gls_cpa"/> approach:
			    <itemizedlist>
				<listitem> If we use conn points speciifc caches then it is as if connection point is just agent and system just do iface resolution
				    task in place of this agent.  </listitem>
				<listitem>If we use conn point URI as addendum to context it is as the the request path goes first to connpoint and then to system
				    (for connpoint is not able for resolving)</listitem>
			    </itemizedlist>
			</simpara>
			<simpara>Hmm, seems there is a gap in the consideration above. We are not going to extend the context. But in some cases
			    the context is required for system to build path-back and understand how to rout forward. Let's look how S1 can route forward
			    on the request coming from S2aa ... S2 - S1.E11. S1 needs to understand via what pin of E11 it shold route forward. So it looks
			    back first to S2.E21. Then S1 gets S2a from context but it is not possible to resolve pin in S2.E21 because S2a connects to two pins
			    of E21. This example shows that this approach of using only additional argument in request is not working.</simpara>
		    </sect5>
		    <sect5 id="ds_pia_ifr_ap_sira_ex"><title>Using extended context</title>
			<simpara>This solution seems simpler that <xref linkend="ds_pia_ifr_ap_sira_aa"/> in the sense that system doesn't need some
			    special iface cache.</simpara>
			<simpara>For example on <xref linkend="fig_pia_ifr_ac"/> the request from S2aa the final context is as:</simpara>
			<programlisting>
			    S2aa
			    S2a.CP2a1
			    S2.E21
			    S1.E11.P1
			    S1a.CP1a1 
			    --> S1aa
			</programlisting>
			<simpara>What would be solutions here?</simpara>
			<itemizedlist>
			    <listitem>Extending of context element. Currently it is pointer to an agent. We can add connection point to the element.</listitem>
			    <listitem>To introduce "context element" - special wrapper of connection point
				<simpara>It is almost same as solution above, just small design modification.
				    This element is the class that contains both pointer to element and "hint" (it can be conn point UID) for instance.
				    We can introduce specific cast operator to smoothly get pointer to agent from the element in order to keep
				    compatibility with the current code.</simpara>
			    </listitem>
			    <listitem>To support polymorphic context element we can introduce context element's interface. It has to include casting to base
				agents pointer.
				<simpara> For <xref linkend="gls_pia"/> system we need the context element that represents agents conn point. This 
				    representation can be created for each active conn points of system.
				    There is design option to use connection record in Vertp as context element iface implementation: it contains 
				    conn point URI, so we just add ref to the system itself.  </simpara>
				<simpara>In fact the current context element is pointer to MElem. It can be simply migrated to Base that contains local
				    iface resolution API. In that case the context element can be any derivation from Base. For instance it can be
				    "PIA connection point" - wrapper of Vertp connection register record including the Vertp agent itself. 
				</simpara>
				<simpara>
				    Note that this approach is similar somehow to passive "units" approach, ref <xref linkend="ds_uac"/></simpara>
			    </listitem>
			</itemizedlist>
		    </sect5>
		</sect4>
	    </sect3>
	</sect2>
	<sect2 id="ds_pia_cp"><title>Connection points</title>
	    <sect3><title>Intro</title>
		<simpara>The current approach (<xref linkend="gls_cpa"/>) assumes that the whole model is built from elementary
		    agents. Connection mechaninsm is also built from such agents. This makes the approach unified and clear. The reasoning of 
		    usage of this approach is the complexity of connection mechanism (we need extentions, sockets etc.).</simpara>
		<simpara>With <xref linkend="gls_pia"/> approach the connection point of agent is not an embedded sub-agent - proxy
		    but simply property of agent - the "contract" of connection. This requires redesign of the current
		    "distributed" mechanism of iface resolution, ref <xref linkend="ds_pia_crit_mri"/>. So this approach assumes
		    dedicated mechanism of connection.</simpara>
		<simpara>What is important here - the structure of <xref linkend="gls_pia"/> connection points should
		    help the agent to resolve ifaces.</simpara>
	    </sect3>
	    <sect3 id="ds_pia_cp_sc"><title>Scheme of connection</title>
		<simpara>In the current apporach (<xref linkend="gls_cpa"/>) each connection is recorded in Vert register in form
		    of pointer to pair.  With <xref linkend="gls_pia"/> approach we also need to record each connection.
		    For vertex it can be also in form of pointer to pair. But looking forward we could introduce 
		    the full scheme of connection directly on vertex level - using connection point spec. In this case the record needs to be in form:</simpara>
		<programlisting>
		    Record ::= Pair_conn_point_spec, Vertex_conn_point_spec
		    Pair_conn_point_spec ::= &lt;pointer_to_pair, conn_point_spec&gt;
		    Vertex_conn_point_spec ::= conn_point_spec
		</programlisting>
		<simpara>Where conn_point_spec is the conn point description in the vertex content.</simpara>
	    </sect3>
	    <sect3><title>How to implement extentions? Internal and external part of extender.</title>
		<simpara>The key feature of connection points is extension the connection points of agents components.
		    For instance connection point of type "Extender" or "Socket", ref <xref linkend="ds_conn"/>.
		</simpara>
		<simpara> In <xref linkend="gls_cpa"/> solution the extension mechanism is implemented almost "natively":
		    there are dedicated connection points for connecting both inner component and external agent. For instance
		    in Extender the extender itself is the point to connect external agent but "Int" component of 
		    extender is intended for connecting internal component.  </simpara>
		<simpara>In case of <xref linkend="gls_pia"/> ther is only agent itself but not proxy. So both internal
		    and external connecting agents shall be connected to agent itself. So the extending connection point
		    "contract" should specify what "part" of connection point is for external usage and what for internal.</simpara>
		<simpara>Note: Actually even for <xref linkend="gls_cpa"/> there was the problem that
		    external agent potentially be allowed to connect to the extender part intended for inner connection.
		    Even this problems isn't addressed yet the solution can be simple = owning agent can disable connecting
		    to extender internal part for external agents. This requires that the owning agent knows the type of
		    extender. Or the extenders should be unified in terms of that the extender itself if for external connection
		    only. There could be another problem here that the extender potentially can be "reverted". For instance
		    the "root" part of socket can be directed for inner connection but "detailed" part - to outer. In that
		    case the owning agent cannot understand what restriction needs to be applied. Again the solution here 
		    could be to have specific type for such "reverted" extenders so that the owning agent can apply the
		    specific restrictions.
		</simpara>
		<simpara>Why don't use the same approach as for <xref linkend=""/>. Mostly because of the problem 
		    desctibed above that owning agent needs to clearly understand what part of extender is for external and 
		    what for internal connection. We need to consider what solution is more effective: specific 
		    type for reverted extender of explicit specifying what part of extender is for exteranl usage.</simpara>
	    </sect3>
	    <sect3><title>How to re-use connection points spec?</title>
		<simpara>In <xref linkend="gls_cpa"/> we can simply re-use connection point - we just create child in given place of 
		    model. For instance if there is connection point CP1 defined as output of system S1, and CP1p defined as compatible to CP1, then
		    heir of CP1 can be used both in extender of CP1 and final pair of CP1. Ref <ulink url="../../test/ut_conn_systp_2.xml"/>: there
		    are two same CPs defined for ext and final pair: 
		    <programlisting> {ConnPoint:{Provided:'MTestIface2' Required:'MTestIface1'}} </programlisting>
		    There needs solution to avoid such duplicating of CP spec. One solution would be to support references to conn points, i.e.
		    references to content.
		</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_pia_crit"><title>Criticism</title>
	    <sect3 id="ds_pia_crit_mri"><title>Loosing mechanism of resolving iface via connpoints.</title>
		<simpara>There is one activelly used mechanism when creating models - system request the ifaces from selected
		    connpoint. This is core feature, it creates the mechanism of effective support of connections in the whole model.
		    With <xref linkend="gls_pia"/> approach it will be system itself duty to resolve the ifaces.</simpara>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_uac"><title>Re-design approach: <xref linkend="gls_uac"/> - chusing Units as auxiliary components.</title>
	<sect2><title>Intro</title>
	    <simpara>There was re-desing approach <xref inkend="gls_pia"/> that allows reduce the number of agents when creating model. According
		to this model the agent shall not use auxiliary agents-components to distribute the functionality. For instance system agent
		shall not use connection points agents.
		Howewer this approach causes overcomplicating the agents. For instance system agent has to get responsibility for connecting (including 
		connpoints compatibility verification), commutating iface resolution requests etc.</simpara>
	    <simpara>There is another that <xref linkend="gls_pia"/> and not so radical approach - just to use "units" instead of agent for 
		auxiliary components. Unit is like agent but doesn't have chromo, so don't need to propagate mutations. </simpara>
	    <simpara>We come to this solution when designing <xref linkend="gls_pia"/> system agent. It evolves that implementing many
		connections related functions in the scope of system agent inself causes to messy code. It is more simple to isolate connection point
		functinality is dedicated class. The class is in fact kind of unit.</simpara>
	    <simpara>Note, that with this approach we can return to early "non-multi-content" design. If unit implementation is simple then unit can
		keep the particular content so we can get rid of mulitcontent - content hierarchy can be supported by hier of units.</simpara>
	</sect2>
	<sect2 id="ds_uac_snmc"><title>Support of non-mutatign changes</title>
	    <simpara>Unit shouldn't support mutation but changes instead. This means we need to restore the feature when agent can change
		its component but keep these changes 'record' in its own mutation. Seems this functionality was modified in the scope of <xref linkend="gls_osm"/>
		implementation.
	    </simpara>
	    <simpara>In the current implementation (26f2b0a1040316ab) the mutation target agent is calculated using both ENa_Targ and ENa_MutNode attrs
		in DoMutation: </simpara>
	    <programlisting>
		|-         if (rno.AttrExists(ENa_MutNode)) {
		|||             // Transform DHC mutation to OSM mutation
		|||             // Transform ENa_Targ: enlarge to ENa_MutNode
		...
	    </programlisting>
	    <simpara>So ENa_MutNode doesn't work here and is used just to keep back compatibility to old hierarchical chromo.</simpara>
	</sect2>
	<sect2 id="ds_uac_hte"><title>How to extend units?</title>
	    <simpara>Unit doesn't keep its chromo, so how can it be extended via inheritance? This can be done only by using its related mutation of
	    unit's owning agent.</simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_mae"><title>Optimization: using monolitic agents instead of embedded (<xref linkend="gls_mae"/>)</title>
	<sect2><title>Intro</title>
	    <simpara>To optimize the model it make sense to make frequently used agents simpler. This agents - common "building blocks" are
		system, incaps, connpoint, extender, socket, state, des. Some of these agents are simple, for instance connpoint is just simple native agent.
	   But some of the agents are rather complex. For instance extender is implemented as Vert with embedded agent (MAgent).</simpara>
       <simpara>So we can propose simplification of these building block as an approach of optimization.</simpara>
	</sect2>
	<sect2 id="ds_mae_scm"><title>Monolitic DES state compatible with current modelled state</title>
	    <sect3><title>Intro</title>
		<simpara>Currently the modelled state is used, ref StateVarMcmu in des module. The controlling agent StateAgent is used inside.</simpara>
		<simpara>We can propose optimization in the scope of <xref linkend="gls_mae"/> approach. The scope of this optimization is:</simpara>
		<orderedlist>
		    <listitem>Remove prepared and confirmed data units. To implement variable data class and embed prepared and confirmed data into
			state agent based on this class. So the controlling agent has to implement data getter iface MDVarGet.</listitem>
		    <listitem>Keep all the interfaces of state agent: inputs and output with state socket (pin for data and pin for observing)</listitem>
		    <listitem>State output data pin can be connected to controlling agent directly. </listitem>
		    <listitem>Getting data from transition function can be implemented in various ways. For instance we can introduce dedicated
		    CP for connecting. Controlling agent can use this CP as MDVarGet provider.</listitem>
		</orderedlist>
	    </sect3>
	    <sect3><title>Status</title>
		<simpara>Implemented in 83ae69315d35. </simpara>
		<simpara>Comparing with modelled agent on simple incrementor test</simpara>
		<simpara>Monolitic, ut_des_cre1vmcmau.xml:</simpara>
		<programlisting>
		    /testroot; Completed of creating system, nodes: 89, imported: 54, time, us: 32369
		</programlisting>
		<simpara>Modelled, ut_des_cre1vmcmu.xml:</simpara>
		<programlisting>
		    /testroot; Completed of creating system, nodes: 143, imported: 94, time, us: 41400
		</programlisting>
	    </sect3>
	</sect2>
	<sect2 id="ds_mae_scc"><title>Monolitic DES state with combined data-observing chain</title>
	    <sect3><title>Into</title>
		<simpara>The current implementation of DES state include separate data chain (MDVarGet iface for instanse) and observing chain
		    (MDesObserver iface). Data chain is formed by
		    tree of nodes of transition function. Observing chain is actually not a chain but just pin in each input of state. This pin expose 
		    controlling agent observing interface to other states connected to the current state inputs. Transition function and controlling
		    agent are enveloped by incaps containing agent. Lets use the abbreviation <xref linkend="gls_ssc"/> for this design.</simpara>
		<simpara>This solution seems resonable but it has some drawbacks. One of them is that we need covering agent for that state to have
		    proper routing observing interface from controlling agent to input connecting agents. Actually this is not a big limitation, but
		    it makes the whole solution less effective - we need to separate the whole DES to the states with states own transition. But there are
		    the cases when some part of transition can be shared between the states. Morover there are additional extension between the state and
		    input of next transition function.</simpara>
		<simpara>We can consider another design solution that partially solves the drawbacks of the current design. This new design is based on using
		    data chain for routing observing iface. Indeed the data chain form the connections chain from input state to the current state. So
		    this data chanin can be used to route. To do that we need transition function to support routing MDesObserver from the controlling agent
		    to input states. Let's use the abbreviation <xref linkend="gls_scc"/> for this solution. There are some benefits of this approach comparing
		    to <xref linkend="gls_ssc"/>. The first one is that the envelop container agent is not required so the output of state can be
		    connected directly to next state transition function input.</simpara>
		<simpara>The disadvantage of <xref linkend="gls_scc"/> is that we need functions specific agents.</simpara>
	    </sect3>
	    <sect3><title>First step of optimization</title>
		<simpara>Version fb3d88a54a8494: added AStatec with SCC support and transition func Add. UT CreStatec with ut_des_cre_statec.xml passed.</simpara>
		<simpara>Comparing with modelled agent on simple incrementor test</simpara>
		<simpara>Modelled, ut_des_cre1vmcmu.xml:</simpara>
		<programlisting>
		    /testroot; Completed of creating system, nodes: 143, imported: 94, time, us: 41400
		</programlisting>
		<simpara><xref linkend="gls_scc"/> phase#1, ut_des_cre_statec.xml:</simpara>
		<programlisting>
		    /testroot; Started of creating system, spec [ut_des_cre_statec.xml]
		    /testroot; Completed of creating system, nodes: 12, imported: 0, time, us: 2397
		</programlisting>
	    </sect3>
	</sect2>
    </sect1>

    <sect1 id="ds_hsc"><title>Handling of system change. Observers</title>
	<sect2><title>Intro</title>
	    <simpara>Ref <xref linkend="ds_prfopt_ahn"/> for handling the changes discussion in the scope of performance optimization.</simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_dla"><title>Directly located agents instead of using Agents special container </title>
	<sect2><title>Intro</title>
	</sect2>
    </sect1>

    <sect1 id="ds_vers"><title>Versioning</title>
	<sect2><title>Intro</title>
	    <simpara>Ref <ulink url="../requirements/index.html#us_069"/> for root use-case for versioning</simpara>
	    <simpara>This section outlines design of support of versions of agents. The versioning is very important because in the agent
	    lifecycle there are some different versions of agent used in the models. So we need mechanism that helps to resolve right version</simpara>
	</sect2>
	<sect2><title>How to specify version</title>
	    <simpara>The standard approach for specifying version is to keep version spec in agent's metadata. Currently there is no metadata in 
	    native agents.</simpara>
	</sect2>
	<sect2><title>Versions compatibility</title>
	</sect2>
    </sect1>

    <sect1><title>Mutli-purpose optimization</title>
    </sect1>

    <sect1 id="ds_th"><title>To handle</title>
	<orderedlist>
	    <listitem>Using mut order to ensure original sequence of muts, ref <xref linkend="ds_mut_dis_pheno"/> </listitem>
	    <listitem>References: rules and limitations, ref <xref linkend="ds_mut_refs"/> </listitem>
	</orderedlist>
	<sect2><title>Speed up of model creation</title>
	    <simpara>To revise the approach of creating child. Currently the full historical creation approach is used: all ancestors are created
		subsequently. To consider direct inheritance.</simpara>
	</sect2>
	<sect2><title>"Embedded" connections</title>
	    <simpara>To embed connection to lower layer. This mean that the base layer to be graph but not just set. Native hier to be created with usage of
		the base connection mechanism. Multiple content to be used ?</simpara>
	</sect2>
	<sect2><title>Simplification: to avoid "Agents" container.</title>
	    <simpara>To consider all components as agents.</simpara>
	</sect2>
	<sect2><title>New chromo language</title>
	    <itemizedlist>
		<listitem>Created sect <xref linkend="ds_chr"/></listitem>
	    </itemizedlist>
	</sect2>
	<sect2><title>Support of Multi-content</title>
	    <simpara>To add support of multi-content: named content. This would simplify many cases where embedded "property" agents are used now.</simpara>
	    <simpara>Ref discussion in <xref linkend="ds_cplx_cont"/></simpara>
	</sect2>
	<sect2><title>Support of connection by agent.</title>
	    <simpara>The idea is to avoid using separate agenent for the connection. Instead the owner can specify the property in the agent which input are 
		to be connected to some outputs. The name of property would be the input name, the value of the property would be URI of the output 
		to be connected to.  </simpara>
	    <simpara>This approach could simplify creation systems with many interconnected components. Transition functions for instance.</simpara>
	</sect2>
	<sect2><title>To avoid explicit connections: use implicit them</title>
	    <simpara>Using explicit connectins makes the complicated systems (transition functions for instance) very messy, there are a lot of 
		connection agents. Is it possible to specify connections by another way. For instance we have transition Fa(Fb, Fc) where Fb, Fc are 
		some functions also. We can just add Fb, Fc as comptents into Fa, naming them with predefinced names (Arg1, Arg2 for instance). So we 
		will avoid explicit connections here.</simpara>
	</sect2>
	<sect2 id="ds_th_mv"><title>To revise mutation validation mechanism.</title>
	    <simpara>Currently the complicate mechanism is used to ensure mutation safety. To consider other mutation model that allows avoid this 
		complication and simplify the mutation scheme.</simpara>
	    <simpara>On of the solution here is to use native safety mechanism: all deps should be registered as run-time deps, mutated node notifies all deps
		about particular mutation, so the deps can adapt to the mutation or refuse it.</simpara>
	</sect2>
	<sect2><title>To improve navigation policy</title>
	    <simpara>Currently there are not restriction navigating thru model using MElem method GetNode. But this is wrong behavior. The access policies are
		to be introduced. Namelly, the access to upper layers has to be denied, the only exception would be access from embedded agent to the container agent.
		But here dedecated mechanism could be used.</simpara>
	</sect2>
	<sect2><title>Mutation for re-parent</title>
	    <simpara>Ref <xref linkend="ds_mut_pmf"/></simpara>
	</sect2>
	<sect2><title>To create solid design for roll-back of propagated mutations.</title>
	    <simpara>Ref <xref linkend="ds_mut_osmlc_pm_vpf"/></simpara>
	</sect2>
	<sect2><title>OSM linear chromo: chromo compacting</title>
	    <simpara>Ref <xref linkend="ds_mut_osmlc_cmp"/></simpara>
	</sect2>
	<sect2><title>Async agents model</title>
	    <simpara>Currently the nature of agent is synchronous, i.e. agent sends signal to another agent and waits for response. Needs to 
		consider async agent, where agent sents signal (message) and doesn't wait for it immediately. We can use same dynamic system approach to 
		implement agent internal state machine is this case. The only specific of DES here will be that it will be "limited", i.e. 
		not extending via mutation, because agent is an "atom" in such a model.</simpara>
	    <simpara>We will need our own specific envionment for such a model to get and deliever messages from/to agents (somethig like
		glib events loop etc.)</simpara>
	    <simpara>Ref aslo <xref linkend="ds_nas"/></simpara>
	</sect2>
	<sect2><title>To implement improved iface resolution mechanism</title>
	    <simpara>Ref <xref linkend="ds_irm"/></simpara>
	</sect2>
	<sect2><title>To implement remote logging</title>
	    <simpara>Currently remote env logs records locally. This is inconvenient - needs to look at multiple logs located in different places.
		Needs to implement receining logs from secondary envs.</simpara>
	    <simpara>Ref <xref linkend="ds_daa_log"/> - initially implemented.</simpara>
	</sect2>
	<sect2><title>To replace MElem comps APIs with generic nodes APIs</title>
	    <simpara>Base agents API includes comps APIs: CompsCount(), GetComp(). This APIs is quite primitive and dont support filtering, i.e. by
		removed sign. This cause overhead when implementing distributed models because client needs to request status of "removed" for each
		comp. So we need to implement filtering when getting comps. There are some options here:</simpara>
	    <orderedlist>
		<listitem>To introduce MElem "comps iterator" and corresponding APIs (begin, end)
		    <para>This APIs should allow to pass filtering parameters. Note that there is already such APIs in Elem:
			NodesLoc_Begin, NodesLoc_End. So we just need to slighly redesign it and move to MElem iface level.</para>
		</listitem>
		<listitem>To implement iterator for generic nodes query API (GetNode).
		    <para>Currently there is just restricted nodes APIs - only single node query is allowed. We can extend
			APIs using nodes iterator. In that case nodes API will be suitable for getting components using uri "./*"</para>
		</listitem>
	    </orderedlist>
	</sect2>
	<sect2><title>Enhanced ifaces of the model</title>
	    <simpara>Ref <xref linkend="ds_mi"/></simpara>
	</sect2>
	<sect2><title>Visual debugging</title>
	    <simpara>Ref <xref linkend="ds_visdbg"/></simpara>
	</sect2>
	<sect2><title>Issue "Modifications during native agent construction - agent cannot be found"</title>
	    <simpara>Ref <xref linkend="ds_di_ndnac"/> </simpara>
	</sect2>
	<sect2><title>Reimplement moving node using mutation contexts.</title>
	    <simpara>Ref <xref linkend="ds_mv_local_wkc"/></simpara>
	</sect2>
    </sect1>

    <sect1 id="ds_i"><title>Issues</title>
	<sect2><title>Intro</title>
	    <sect3><title>Status of issue</title>
		<simpara>Issue status prefix is IS_. The following values of status are defined:</simpara>
		<itemizedlist>
		    <listitem>O - Open</listitem>
		    <listitem>C - Closed</listitem>
		</itemizedlist>
	    </sect3>
	</sect2>
	<sect2 id="ds_i_cpssr"><title>I_CPSSR [IS_O] DAA clent-server messaging protocol supports simple response only.</title>
	    <sect3><title>Description</title>
		<simpara>The protocol (ref fap2-srv/client/bclient.h: BaseClient::Request()) supports simple response only:</simpara>
		<programlisting> bool Request(const string&amp; aRequest, string&amp; aResponse); </programlisting>
		<simpara>I.e. responce is just one serialized paremeter. But in some cases we need to return more than one parameter. So
		    we need protocol to be more generic and to support package in the response.</simpara>
		<simpara>For example ref fap2-srv/dmas/melempx.cpp: MelemPx::GetCont()
		    <programlisting> TBool MelemPx::GetCont(string&amp; aCont, const string&amp; aName) const </programlisting>
		</simpara>
	    </sect3>
	    <sect3><title>Analysis</title>
		<simpara>Alternative solution would be just to restrict responce to contains only one parameter.</simpara>
	    </sect3>
	</sect2>
	<sect2><title>Agent-provider</title>
	    <simpara>At the moment an agent requests env for new agents provider. The provider impelements iface "MProvider". Plugin system is supported in
		order to add new provider into the providers list.  </simpara>
	    <simpara>Needs to consider another solution - when some agents serve as providers, i.e implement "MProvider" iface. In that case env can
		use standard iface resolution mechanism to get the list of all providers.</simpara>
	    <simpara>Please note that this approach is already used in fap2-srv (distributed multi-agents) for provider of proxies:
		specific agent ADaaPxProv acts as provider of proxies (implements iface MIpxProv.)</simpara>
	</sect2>
	<sect2><title>Generated proxy</title>
	    <simpara>Currently in distributed agents models, the specific proxies are created in order to represent "real" agents. Needs to consider the approaches
		of generating such proxies. In fact any proxy acts as some service (offers iface for service). This service is used by some clients. 
		Obviously this clients has to know of this service iface. So if the current env doesn't have provider for service and clients proxies, thebn
		both service and clients should be in their "native" environment. This means that the border between current env and env with "foreign"
		iface servece/clints has to be only "passed" by ifaces known by both current and remote env. This creates limitations in designing of
		distributed system.</simpara>
	    <simpara>Another solution would be having clients that automatically generates requests to service APIs. But how to do it? Is it
		realistic at all?</simpara>
	</sect2>
	<sect2><title>New chromo language</title>
	    <simpara>Ref <xref linkend="ds_chr_nc"/></simpara>
	</sect2>
	<sect2><title>Current implementatin of content is inefficient</title>
	    <sect3><title>Description</title>
		<simpara>Currently (9fd314b78e1) the content is implemented that the content tree is simulated by map. This seems rather ineffective.
		    Needs to redesign.</simpara>
	    </sect3>
	</sect2>
	<sect2 id="ds_i_dpe_wb"><title>Propagation disabling caused wrong behavior</title>
	    <simpara>There was the change made in [326f9dfdf9b5] according to design proposal <xref linkend="ds_prfopt_prp01_dpe"/>:
		propagation was disabled. But this change caused incorrect 
		behavior - changing point of edge isn't propagated to owning incaps so the connection is not established.</simpara>
	    <simpara>Redesign proposal <xref linkend="ds_elem_iact_rdins"/> was created for solve this issue.</simpara>
	</sect2>
    </sect1>

    <sect1><title>Status items</title>
	<simpara><glossterm id="sts_done">DONE</glossterm></simpara>
	<simpara><glossterm id="sts_progr">IN_PROGRESS</glossterm></simpara>
    </sect1>

</article>
